{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_gnzDpalsj2",
        "outputId": "521b0eda-3911-4615-bdb4-a4d2185ebf28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-+.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WjLqF9AHXrf",
        "outputId": "c9049cd4-335a-4e56-947a-3d6dbf7c09eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-+.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.14)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKnGsN2HlvOJ",
        "outputId": "74ef01e7-eb97-4170-9092-8a0bee09f328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.6.15)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "id": "x4ExpkAVHdQt"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaConfig, RobertaTokenizer, RobertaForMaskedLM, pipeline\n",
        "\n",
        "CBmodel = RobertaForMaskedLM.from_pretrained(\"microsoft/codebert-base-mlm\", output_hidden_states = True)\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base-mlm\")\n",
        "# https://huggingface.co/docs/transformers/model_doc/roberta#transformers.RobertaForMaskedLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhWJf8yybgSR"
      },
      "source": [
        "TODO: CREATE A GENERATOR(FILES) METHOD FOR graph_dump.txt FILES GENERATED BY THE PDG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "GCNwq5l1q6xH"
      },
      "outputs": [],
      "source": [
        "files = [\"/content/sample_data/example1_graph_dump.txt\", \"/content/sample_data/example2_graph_dump.txt\", \"/content/sample_data/AnishaSample_graph_dump.txt\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6i240-pWApi",
        "outputId": "6337b3bc-de5a-423d-926b-9efadaea8fe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.0+cu113\n",
            "11.3\n",
            "3.7.13\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "!python -c \"import torch; print(torch.__version__)\"\n",
        "!python -c \"import torch; print(torch.version.cuda)\"\n",
        "import platform\n",
        "print(platform.python_version())\n",
        "from typing import Callable, List, Optional, Dict\n",
        "import numpy as np\n",
        "import scipy.sparse as sp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xke8L8gFbHRc"
      },
      "source": [
        "DOUBT!!!!! SHOULD WE COUNT NODES PER GRAPH OR ACROSS ALL GRAPHS??CURRENTLY COUNTING PER GRAPH."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "OFgi-A9XqsLc"
      },
      "outputs": [],
      "source": [
        "# nodes_to_graph_id = []\n",
        "def get_nodes_edges(inTextFile):\n",
        "  # FD = 0, CD = 1\n",
        "  # to support the hetero data object as suggested by the documentation \n",
        "  nodes_dict = {}\n",
        "  edge_indices_CD = []\n",
        "  edge_indices_FD = []\n",
        "\n",
        "  #to support the Data object as used by the Entities dat object as used in RGAT source code\n",
        "  edge_indices = []\n",
        "  edge_type = []\n",
        "  \n",
        "  \n",
        "  # nodes_dict is an index_map\n",
        "  node_count=0;\n",
        "  with open(inTextFile) as fp:\n",
        "\n",
        "    Lines = fp.readlines()\n",
        "\n",
        "    for line in Lines:\n",
        "\n",
        "      N = line.split('-->')\n",
        "        \n",
        "      t1 = N[0].split('$$')   \n",
        "      src = t1[1].strip()   \n",
        "      if src not in nodes_dict.keys():\n",
        "        nodes_dict[src] = node_count\n",
        "        # nodes_to_graph_id.append(graph_id)\n",
        "        node_count+=1\n",
        "        \n",
        "      t2 = N[1].split('$$')\n",
        "      idx = t2[1].rfind('[')\n",
        "      dst = t2[1][:idx].strip()\n",
        "      if dst not in nodes_dict.keys():\n",
        "        nodes_dict[dst] = i\n",
        "        # nodes_to_graph_id.append(graph_id)\n",
        "        node_count+=1\n",
        "\n",
        "      x = t2[1][idx+2:-3]\n",
        "      if(x=='FD'):\n",
        "        y=0\n",
        "        edge_indices.append([nodes_dict[src], nodes_dict[dst]])\n",
        "        edge_type.append(y)\n",
        "        edge_indices_FD.append([nodes_dict[src], nodes_dict[dst]])\n",
        "      else: \n",
        "        y=1\n",
        "        edge_type.append(y)\n",
        "        edge_indices.append([nodes_dict[src], nodes_dict[dst]])\n",
        "        edge_indices_CD.append([nodes_dict[src], nodes_dict[dst]])\n",
        "     \n",
        "  # return nodes_to_graph_id, j, nodes_dict, edge_indices_FD, edge_indices_CD\n",
        "  return nodes_dict, edge_indices_FD, edge_indices_CD, edge_indices, edge_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "0W1zYS1dHfZr"
      },
      "outputs": [],
      "source": [
        "def get_nodes_feat_CodeBert(nodes_dict , graph_id, i):\n",
        "  # Stores the token vectors, with shape [22 x 768]\n",
        "  CodeEmbedding = []\n",
        "  for text in nodes_dict.keys():\n",
        "    # print(text)\n",
        "    i = nodes_dict[text]\n",
        "    T=30\n",
        "    tokens=tokenizer.tokenize(str(text))\n",
        "    tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "    padded_tokens=tokens +['[PAD]' for _ in range(T-len(tokens))]\n",
        "    attn_mask=[ 1 if token != '[PAD]' else 0 for token in padded_tokens  ]\n",
        "    seg_ids=[0 for _ in range(len(padded_tokens))]\n",
        "    sent_ids=tokenizer.convert_tokens_to_ids(padded_tokens)\n",
        "    token_ids = torch.tensor(sent_ids).unsqueeze(0) \n",
        "    attn_mask = torch.tensor(attn_mask).unsqueeze(0) \n",
        "    seg_ids   = torch.tensor(seg_ids).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "      output = CBmodel(token_ids, attention_mask = attn_mask, token_type_ids = seg_ids)\n",
        "      hid_state = output.hidden_states[-1][0]\n",
        "      cls_embedd = hid_state[0]\n",
        "      # print(tf.shape(cls_embedd))\n",
        "      # print(cls_embedd)\n",
        "      m = nn.Linear(768, 64)\n",
        "      se = m(cls_embedd)\n",
        "      # print(tf.shape(se))\n",
        "      CodeEmbedding.append(se.tolist())\n",
        "      # token_vecs_sum = torch.cat((token_vecs_sum, token_vecs))\n",
        "      \n",
        "      # print(i, str(CodeEmbedding[i]))\n",
        "  return CodeEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "id": "_-Qvu9CeMtqN"
      },
      "outputs": [],
      "source": [
        "batchsize = 3\n",
        "\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import RGATConv, to_hetero\n",
        "# from torch_geometric.nn import global_add_pool\n",
        "# from torch_geometric.nn import global_sort_pool\n",
        "from torch_geometric.nn import global_max_pool\n",
        "\n",
        "class RGAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels,\n",
        "                 num_relations):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = RGATConv(in_channels, hidden_channels, num_relations)\n",
        "        self.conv2 = RGATConv(hidden_channels, hidden_channels, num_relations)\n",
        "        self.lin = torch.nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_type, batch):\n",
        "        x = self.conv1(x, edge_index, edge_type).relu()\n",
        "        x = self.conv2(x, edge_index, edge_type)\n",
        "\n",
        "        # 2. Readout layer\n",
        "        x = global_max_pool(x, batch)  # [batch_size, hidden_channels]\n",
        "\n",
        "        # 3. Apply a final classifier\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        \n",
        "        return x\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "ydJuqfR4lare"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import (\n",
        "    HeteroData,\n",
        "    Data,\n",
        "    InMemoryDataset,\n",
        "    Batch\n",
        "    )\n",
        "# from torch_geometric.typing import EdgeType, EdgeTensorType\n",
        "from torch_geometric.data.storage import EdgeStorage\n",
        "import torch_geometric.datasets as datasets\n",
        "import torch_geometric.transforms as transforms\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJVeWnpMlId8",
        "outputId": "59a0e7ff-fdaf-4ae2-98a0-e83a27e00991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "# Hetero data\n",
        "data_list = []\n",
        "# Data\n",
        "d_list =[]\n",
        "for i, file in enumerate(files):\n",
        "  j=0;\n",
        "  # GET DATA\n",
        "  # nodes_dict = {}\n",
        "  # nodes_to_graph_id = []\n",
        "  nodes_dict, edge_indices_FD, edge_indices_CD, edge_indices, edge_type = get_nodes_edges(file)\n",
        "  # print(nodes_dict)\n",
        "  # print(edge_indices_CD)\n",
        "  # print(edge_indices_FD)\n",
        "\n",
        "  # Node feature matrix with shape [num_nodes, num_node_features]=(6,64).\n",
        "  CodeEmbedding = get_nodes_feat_CodeBert(nodes_dict, 0, 0)\n",
        "   # print(CodeEmbedding)\n",
        "\n",
        "  # FIXING DATA FOTMATS AND SHAPE\n",
        "  x = torch.tensor(CodeEmbedding)\n",
        "  # print(x.shape)\n",
        "  # -[6,64]\n",
        "  \n",
        "  # data.y: Target to train against (may have arbitrary shape),\n",
        "  # graph-level targets of shape [1, *]\n",
        "  y=torch.tensor([0.0,0.0,1.0]).reshape([1, 3])\n",
        "  print(type(y))\n",
        "\n",
        " # edge_index (LongTensor, optional) â€“ Graph connectivity in COO format with shape [2, num_edges]\n",
        "  edge_index_CD = torch.tensor(edge_indices_CD, dtype=torch.long).t().contiguous()\n",
        "  # print(edge_index_CD)\n",
        "  edge_index_FD = torch.tensor(edge_indices_FD, dtype=torch.long).t().contiguous()\n",
        "  # print(edge_index_FD)\n",
        "  edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
        "  edge_type = torch.tensor(edge_type, dtype=torch.long).t().contiguous()\n",
        "  # INITIALIZING A Hetero DATA POINT - documentation based\n",
        "  hdata = HeteroData(node={ 'x': x })\n",
        "  hdata['node', 'CD', 'node'].edge_index = edge_index_CD\n",
        "  hdata['node', 'FD', 'node'].edge_index = edge_index_FD\n",
        "  hdata.y = y\n",
        "  hdata['node'].num_nodes = len(nodes_dict)\n",
        "  hdata['node'].num_node_features = len(CodeEmbedding[0])\n",
        "  node_types, edge_types = hdata.metadata()\n",
        "  # print(edge_types)\n",
        "  # MAKE A DATALIST\n",
        "  data_list.append(hdata)\n",
        "\n",
        "  data = Data(edge_index=edge_index, edge_type=edge_type, x=x)\n",
        "  data.y = y;\n",
        "  data.num_nodes = len(nodes_dict)\n",
        "  d_list.append(data)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "MtzQywRpPQ0_"
      },
      "outputs": [],
      "source": [
        "loader = DataLoader(data_list, batch_size=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader2 = DataLoader(d_list, batch_size=2)"
      ],
      "metadata": {
        "id": "En1maaRkr0NA"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR0zv9h1PV98",
        "outputId": "169f4c3a-64d6-4581-81f2-9e91e75de615"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_DataLoader__initialized': True,\n",
              " '_DataLoader__multiprocessing_context': None,\n",
              " '_IterableDataset_len_called': None,\n",
              " '_dataset_kind': 0,\n",
              " '_iterator': None,\n",
              " 'batch_sampler': <torch.utils.data.sampler.BatchSampler at 0x7f1aed740110>,\n",
              " 'batch_size': 2,\n",
              " 'collate_fn': <torch_geometric.loader.dataloader.Collater at 0x7f1aed740310>,\n",
              " 'dataset': [HeteroData(\n",
              "    y=[1, 3],\n",
              "    \u001b[1mnode\u001b[0m={\n",
              "      x=[6, 64],\n",
              "      num_nodes=6,\n",
              "      num_node_features=64\n",
              "    },\n",
              "    \u001b[1m(node, CD, node)\u001b[0m={ edge_index=[2, 5] },\n",
              "    \u001b[1m(node, FD, node)\u001b[0m={ edge_index=[2, 5] }\n",
              "  ), HeteroData(\n",
              "    y=[1, 3],\n",
              "    \u001b[1mnode\u001b[0m={\n",
              "      x=[6, 64],\n",
              "      num_nodes=6,\n",
              "      num_node_features=64\n",
              "    },\n",
              "    \u001b[1m(node, CD, node)\u001b[0m={ edge_index=[2, 4] },\n",
              "    \u001b[1m(node, FD, node)\u001b[0m={ edge_index=[2, 6] }\n",
              "  ), HeteroData(\n",
              "    y=[1, 3],\n",
              "    \u001b[1mnode\u001b[0m={\n",
              "      x=[6, 64],\n",
              "      num_nodes=6,\n",
              "      num_node_features=64\n",
              "    },\n",
              "    \u001b[1m(node, CD, node)\u001b[0m={ edge_index=[2, 5] },\n",
              "    \u001b[1m(node, FD, node)\u001b[0m={ edge_index=[2, 2] }\n",
              "  )],\n",
              " 'drop_last': False,\n",
              " 'exclude_keys': None,\n",
              " 'follow_batch': None,\n",
              " 'generator': None,\n",
              " 'num_workers': 0,\n",
              " 'persistent_workers': False,\n",
              " 'pin_memory': False,\n",
              " 'pin_memory_device': '',\n",
              " 'prefetch_factor': 2,\n",
              " 'sampler': <torch.utils.data.sampler.SequentialSampler at 0x7f1aed740790>,\n",
              " 'timeout': 0,\n",
              " 'worker_init_fn': None}"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ],
      "source": [
        "vars(loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vars(loader2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyOim1a_sGGS",
        "outputId": "59faa76c-ee9b-4139-a0bc-f0e2bb471af6"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_DataLoader__initialized': True,\n",
              " '_DataLoader__multiprocessing_context': None,\n",
              " '_IterableDataset_len_called': None,\n",
              " '_dataset_kind': 0,\n",
              " '_iterator': None,\n",
              " 'batch_sampler': <torch.utils.data.sampler.BatchSampler at 0x7f1aed7be350>,\n",
              " 'batch_size': 2,\n",
              " 'collate_fn': <torch_geometric.loader.dataloader.Collater at 0x7f1aed7bed50>,\n",
              " 'dataset': [Data(x=[6, 64], edge_index=[2, 10], edge_type=[10], y=[1, 3], num_nodes=6),\n",
              "  Data(x=[6, 64], edge_index=[2, 10], edge_type=[10], y=[1, 3], num_nodes=6),\n",
              "  Data(x=[6, 64], edge_index=[2, 7], edge_type=[7], y=[1, 3], num_nodes=6)],\n",
              " 'drop_last': False,\n",
              " 'exclude_keys': None,\n",
              " 'follow_batch': None,\n",
              " 'generator': None,\n",
              " 'num_workers': 0,\n",
              " 'persistent_workers': False,\n",
              " 'pin_memory': False,\n",
              " 'pin_memory_device': '',\n",
              " 'prefetch_factor': 2,\n",
              " 'sampler': <torch.utils.data.sampler.SequentialSampler at 0x7f1aed7be1d0>,\n",
              " 'timeout': 0,\n",
              " 'worker_init_fn': None}"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "NRqP1_VePkoS"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  #num_classes??3 for now\n",
        "  #num_relations?? 2 for now\n",
        "model = RGAT(64, 16, 3, 2).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0005)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# model = to_hetero(model, data.metadata(), aggr='sum')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx-NFJDj4LeO",
        "outputId": "02263ff5-294b-4ba0-a12b-78dc0c37fe82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RGAT(\n",
              "  (conv1): RGATConv(64, 16, heads=1)\n",
              "  (conv2): RGATConv(16, 16, heads=1)\n",
              "  (lin): Linear(in_features=16, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVKXtd-hjRh3",
        "outputId": "ac607047-1446-4df6-fb78-aa0b1c916e1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_global_store': {'y': tensor([[0., 0., 1.],\n",
            "        [0., 0., 1.]])}, '_node_store_dict': {'node': {'x': tensor([[ 2.9443e-01,  2.4020e-01, -3.5007e-02, -5.3109e-01,  6.1027e-03,\n",
            "         -1.6022e-01, -3.8866e-01,  2.0816e-01,  3.0737e-01,  7.0874e-02,\n",
            "         -3.3227e-01,  1.6522e-01,  3.9254e-01, -9.6531e-02, -1.2251e-01,\n",
            "          2.7382e-01, -4.3338e-01, -2.6536e-01, -3.2666e-01, -1.2912e-01,\n",
            "         -1.4889e-01, -1.8789e-01,  3.2412e-01, -4.8672e-01,  4.2398e-01,\n",
            "         -2.0261e-01,  1.1859e-01, -1.8840e-01, -3.6493e-01,  4.5412e-01,\n",
            "          8.1351e-02, -4.3888e-01, -2.8010e-01,  1.9178e-01,  4.0664e-01,\n",
            "         -1.9875e-01, -2.1171e-02, -3.4211e-01,  8.3194e-02,  7.9346e-02,\n",
            "         -1.6098e-02, -3.1080e-01, -5.3192e-01,  5.1327e-01, -4.0966e-01,\n",
            "          1.0375e-01, -2.8884e-01,  2.5118e-02,  1.7064e-01,  1.1391e-01,\n",
            "          3.4254e-01,  1.1217e-01, -5.7126e-01,  2.9078e-01, -1.6091e-01,\n",
            "          2.4829e-02, -5.0029e-01, -2.8908e-02, -1.7337e-01,  1.7868e-01,\n",
            "         -1.5459e-02,  3.1262e-01,  2.0956e-01, -2.5593e-01],\n",
            "        [ 1.7770e-01, -2.3009e-01,  4.5689e-01,  1.0094e-01, -2.8150e-01,\n",
            "         -4.2215e-01,  1.2061e-01, -2.5298e-01, -5.3690e-02, -4.5519e-03,\n",
            "          7.3074e-02,  2.7766e-01,  3.9536e-01, -2.4420e-01, -2.7086e-01,\n",
            "          2.8016e-01, -4.3293e-01,  1.7864e-01, -2.6929e-01, -5.1057e-01,\n",
            "          4.9183e-01, -2.5671e-01,  8.0775e-04, -8.1969e-02, -5.2619e-02,\n",
            "         -3.9195e-01, -3.3255e-01, -5.6745e-01,  7.9548e-02,  2.1620e-01,\n",
            "          3.5657e-01, -1.8659e-01, -5.6710e-01, -7.1607e-02,  2.4431e-01,\n",
            "         -2.5407e-01,  2.0474e-01, -5.4094e-01, -2.7053e-01, -1.3981e-01,\n",
            "         -7.4948e-02, -2.9377e-01,  1.8423e-01, -1.7833e-01,  5.0370e-02,\n",
            "         -3.6759e-01,  1.5601e-01,  2.5072e-01, -5.2125e-01, -1.3615e-01,\n",
            "         -4.4381e-01,  8.0419e-02,  3.8014e-01,  2.4570e-02,  4.2053e-01,\n",
            "          3.3400e-01, -5.7145e-02,  1.1518e-01,  2.5186e-01, -5.7882e-01,\n",
            "          3.5421e-01, -3.5838e-02, -9.0272e-02,  2.6345e-01],\n",
            "        [ 4.8777e-01,  2.7161e-01,  4.7382e-03, -3.4038e-01, -4.7300e-01,\n",
            "          6.0694e-01, -4.2306e-01,  4.3846e-01, -4.3730e-01, -1.4178e-01,\n",
            "          1.9863e-01, -2.6091e-01, -2.4979e-01,  2.4218e-01,  4.0476e-01,\n",
            "          2.1090e-03,  4.2535e-01,  5.5792e-01, -5.0635e-01,  1.1964e-01,\n",
            "         -9.1677e-04,  1.1196e-01, -4.9272e-01,  2.8013e-01, -3.4190e-01,\n",
            "          1.4254e-01, -1.0622e-01, -3.0979e-01, -2.8535e-01, -4.2420e-01,\n",
            "          6.1094e-02, -1.7029e-01, -2.9858e-01,  3.1577e-01,  4.1027e-01,\n",
            "         -2.5143e-01,  2.5193e-01, -3.4415e-01,  1.2899e-01,  3.9611e-01,\n",
            "         -3.8233e-01, -1.8182e-01, -1.4528e-02,  2.1883e-01, -3.8970e-01,\n",
            "          3.1556e-01, -4.8400e-01, -2.4615e-02, -2.1895e-01, -1.1946e-01,\n",
            "         -3.5972e-01, -2.7663e-01,  1.8108e-01, -4.5821e-01, -3.3740e-01,\n",
            "         -1.7525e-01, -3.5009e-01, -2.8179e-01, -4.4059e-01, -6.6023e-02,\n",
            "         -6.0092e-02,  9.1427e-02,  8.7923e-02,  1.9497e-01],\n",
            "        [-5.0587e-01,  5.6039e-01, -4.8974e-01, -5.3816e-02, -3.4694e-01,\n",
            "         -2.4207e-01,  3.3092e-01, -2.7769e-01,  2.9510e-01, -4.7216e-01,\n",
            "          4.2415e-01, -2.7692e-01,  4.2993e-01,  1.9047e-01, -4.3891e-01,\n",
            "          4.6834e-01,  4.8203e-01, -3.3334e-01, -1.1645e-01, -2.6487e-01,\n",
            "          9.5159e-02, -1.0721e-01, -7.9359e-02,  5.3533e-01,  2.5151e-01,\n",
            "         -3.6953e-01, -4.5523e-01,  4.6022e-01, -4.1541e-01, -5.1390e-02,\n",
            "         -4.4389e-01, -2.8876e-01, -1.0258e-01,  2.4498e-02,  7.0613e-02,\n",
            "          1.3817e-01,  1.6249e-01,  3.6900e-01, -4.7161e-01,  6.2956e-02,\n",
            "         -4.7652e-01, -2.4537e-01,  3.8694e-01, -1.6667e-01, -6.8921e-02,\n",
            "          3.2098e-01, -2.4683e-01, -3.0128e-01, -1.1418e-01,  4.4599e-01,\n",
            "         -3.1147e-01,  4.9754e-01, -2.6422e-01,  3.1439e-01,  2.6787e-01,\n",
            "         -8.4138e-02,  6.6825e-02, -5.1772e-01,  1.9693e-01, -2.0418e-01,\n",
            "         -2.8821e-01,  2.2320e-01,  4.5607e-01,  2.1529e-01],\n",
            "        [-7.5184e-02, -3.1646e-01, -1.3922e-01,  3.2484e-01,  1.1714e-02,\n",
            "          1.7715e-02, -1.3688e-01, -9.9273e-02,  3.7864e-01, -9.8457e-02,\n",
            "         -2.1247e-01, -2.3844e-01, -5.5708e-01, -2.8508e-01, -5.2007e-02,\n",
            "         -2.7886e-01,  3.6193e-01,  4.3418e-01,  3.0078e-02, -3.7312e-02,\n",
            "          3.2477e-01, -5.1555e-01, -3.2751e-01, -1.8038e-01, -3.1068e-01,\n",
            "          2.6249e-01, -4.9655e-01,  4.9659e-01,  3.6707e-01,  3.6954e-01,\n",
            "         -1.7966e-01, -1.4382e-01, -3.6395e-01, -5.3453e-01, -3.0224e-02,\n",
            "          6.1476e-05,  3.3707e-01,  4.2897e-01,  1.7774e-01, -1.1132e-02,\n",
            "         -4.6030e-01,  3.6889e-01,  2.7127e-01, -3.6692e-01,  4.1122e-01,\n",
            "          2.1559e-01,  2.5799e-01, -2.0675e-01,  4.8900e-01, -2.3623e-02,\n",
            "          1.7534e-01,  1.7801e-01, -4.1555e-01,  2.6550e-01, -7.1864e-02,\n",
            "         -1.3740e-01,  6.2497e-02, -7.4074e-02,  2.0186e-01,  3.2666e-01,\n",
            "          4.0106e-01,  4.3195e-01,  4.8914e-01, -8.5218e-02],\n",
            "        [-1.6295e-01,  5.4341e-01,  1.8002e-01, -2.7558e-01,  2.0765e-01,\n",
            "         -4.7952e-01,  1.7182e-02, -3.9623e-01, -1.9659e-01, -6.7397e-01,\n",
            "          2.6171e-01, -2.0211e-02,  4.7134e-01,  2.3072e-01, -3.4641e-01,\n",
            "         -5.1547e-01,  3.0685e-01,  1.8742e-01, -5.6439e-01, -1.0256e-01,\n",
            "          3.0630e-01, -2.8304e-01,  1.9917e-01,  4.1822e-01, -1.0335e-01,\n",
            "          2.3061e-01, -9.2453e-02, -1.5354e-01, -1.0898e-02,  1.2815e-01,\n",
            "          3.5190e-01,  2.1255e-01, -1.0696e-01,  4.6104e-01, -1.5019e-01,\n",
            "          2.0255e-02, -1.4867e-01,  1.6845e-01,  3.1246e-01,  4.4367e-01,\n",
            "          2.6453e-01, -2.0991e-01, -3.3357e-01,  4.0514e-02,  2.9127e-01,\n",
            "          3.9863e-01, -2.1284e-01,  3.6842e-01,  6.7295e-02,  1.9745e-01,\n",
            "          4.6634e-02,  8.0407e-02,  1.7949e-01, -4.3314e-03, -4.9930e-01,\n",
            "         -3.4889e-01,  3.1721e-01,  4.3418e-01,  1.8255e-01,  6.6883e-02,\n",
            "         -2.2133e-02, -2.2941e-01,  2.7484e-01,  3.5313e-02],\n",
            "        [-1.6965e-03,  4.1815e-01,  2.3695e-01,  4.5044e-01,  3.8478e-01,\n",
            "          7.5692e-02, -4.4112e-01, -2.4210e-01,  1.6479e-01, -3.4364e-01,\n",
            "         -5.3430e-01, -3.9185e-02, -4.4625e-02, -3.5618e-01,  1.6090e-01,\n",
            "         -8.9444e-02, -9.7509e-02, -1.1142e-01, -2.1282e-02,  5.0590e-01,\n",
            "          2.0685e-01,  6.4264e-01,  1.2080e-01, -3.6301e-01, -9.4240e-02,\n",
            "          2.6062e-01, -3.7572e-01, -4.6222e-01,  2.7940e-02,  2.9970e-01,\n",
            "         -5.1826e-01,  2.5681e-01,  3.1571e-01, -3.1959e-01, -2.3713e-01,\n",
            "         -3.9801e-02,  5.7085e-01,  3.0368e-01, -1.7566e-01, -5.5471e-01,\n",
            "         -4.1144e-01,  4.3922e-02, -2.0792e-01, -3.0493e-01,  2.1020e-01,\n",
            "         -2.8494e-01,  2.7256e-01, -1.4883e-02,  8.1984e-02, -2.0212e-01,\n",
            "          2.0692e-01,  2.7645e-01,  2.2291e-01, -3.2714e-01, -5.4224e-03,\n",
            "         -2.4555e-01,  5.0170e-01, -1.6703e-01, -5.5531e-04, -5.0613e-02,\n",
            "          6.9050e-03, -4.4529e-01,  3.1954e-02,  4.5596e-01],\n",
            "        [ 4.2967e-01, -1.7668e-01,  4.4497e-01, -6.6255e-02,  2.8526e-01,\n",
            "          2.3307e-01,  2.1988e-01, -3.4524e-01,  3.1513e-01,  1.4660e-01,\n",
            "         -3.1111e-01, -2.0904e-01, -4.5973e-01, -2.4059e-02,  4.3938e-01,\n",
            "          1.3524e-01, -3.2237e-01, -4.9100e-01,  4.7710e-02, -3.3337e-01,\n",
            "          3.2446e-01, -3.0649e-01, -2.4198e-01,  4.7776e-02,  3.1759e-01,\n",
            "          3.4821e-01, -4.3871e-01, -2.1977e-02,  2.8074e-01, -3.6511e-01,\n",
            "         -2.4598e-01, -1.0788e-01, -2.7688e-01, -2.9747e-02, -4.5003e-01,\n",
            "         -3.9471e-01, -3.5545e-01, -1.0777e-01,  3.4453e-01,  5.9166e-02,\n",
            "          3.8358e-01, -4.3514e-01,  4.0858e-01, -3.8324e-02, -4.3232e-01,\n",
            "          4.9553e-01,  2.1442e-01,  1.7107e-01,  2.8733e-01,  3.4957e-01,\n",
            "          3.6921e-01, -3.6882e-01, -3.0125e-01, -2.8976e-01, -4.6522e-01,\n",
            "         -3.6242e-01, -2.3915e-01, -5.4283e-03,  2.1762e-01,  3.8712e-01,\n",
            "         -1.6681e-01,  3.1029e-01,  2.9415e-01, -1.3352e-01],\n",
            "        [ 2.1060e-01, -2.8763e-01, -3.4052e-01,  2.8882e-01, -4.3288e-01,\n",
            "         -3.7122e-01,  5.0360e-01, -2.8117e-01,  3.8774e-01,  1.0704e-01,\n",
            "         -1.4586e-02, -3.9321e-02, -3.3351e-01,  4.7562e-01, -1.7641e-01,\n",
            "          1.0089e-01, -5.2658e-02,  4.6453e-01,  8.7285e-02, -2.7073e-01,\n",
            "          2.1790e-01, -5.6495e-01,  4.1967e-01, -2.6074e-01,  1.3662e-01,\n",
            "         -3.4449e-01, -1.6030e-04,  4.0013e-01,  1.1299e-01,  7.5611e-02,\n",
            "         -2.7383e-01, -2.1492e-01,  2.1772e-02, -1.2551e-01,  1.5349e-01,\n",
            "         -2.1680e-01, -4.3692e-01,  3.3205e-01, -3.2679e-01, -4.4146e-01,\n",
            "          4.9950e-01,  3.0813e-01, -7.7946e-02, -3.1638e-01,  1.4997e-01,\n",
            "         -1.6539e-01, -1.9834e-01, -2.8196e-01,  1.7658e-01, -1.3021e-04,\n",
            "         -4.2929e-01,  1.4016e-01, -9.6505e-02, -3.3792e-01, -1.1204e-01,\n",
            "          4.7436e-01,  9.1546e-02, -2.5717e-01,  3.7672e-01,  2.8204e-02,\n",
            "         -1.1113e-01, -4.0520e-01,  5.5472e-01, -2.4749e-01],\n",
            "        [ 3.7146e-01, -2.4193e-01, -3.2995e-01, -3.5705e-01, -3.5603e-01,\n",
            "         -2.8366e-01,  1.3212e-01,  5.5947e-02, -3.6467e-01, -1.5718e-01,\n",
            "         -4.5169e-01, -5.1850e-01,  8.5571e-02,  9.1580e-02,  3.6476e-01,\n",
            "          1.0827e-02, -2.7458e-01, -2.9223e-01, -4.2275e-01,  2.4894e-01,\n",
            "         -2.7921e-01, -2.7068e-01,  2.0845e-01,  2.0572e-01, -3.8617e-02,\n",
            "          4.6667e-01,  4.4596e-01,  4.6134e-02,  4.0902e-01,  1.5213e-01,\n",
            "          4.0628e-01, -7.8878e-02,  4.3719e-01,  4.0467e-02,  4.1432e-01,\n",
            "          2.1988e-01, -4.6529e-01, -4.2236e-01,  1.7599e-01, -2.2378e-02,\n",
            "         -4.3121e-01,  3.0813e-01,  1.8547e-01,  3.1668e-01, -1.8582e-01,\n",
            "          1.6303e-01,  2.4759e-01, -5.7322e-02,  3.5467e-01, -1.9710e-01,\n",
            "         -3.1371e-01, -4.0319e-01,  4.6170e-01,  2.8482e-01, -7.2999e-02,\n",
            "         -3.7440e-01,  4.6278e-01, -3.5013e-02,  5.3443e-01,  2.8034e-01,\n",
            "          2.0876e-01, -3.4044e-01,  3.9429e-01, -1.8728e-01],\n",
            "        [-3.8688e-01, -3.4540e-01,  3.3025e-02,  3.1577e-01, -2.2469e-01,\n",
            "         -2.1002e-01, -4.9464e-03,  3.9412e-01, -2.9980e-01,  3.0216e-01,\n",
            "          2.5909e-01,  5.8003e-01,  3.4712e-02,  3.8863e-01, -2.4669e-01,\n",
            "          1.6298e-01,  1.9696e-02,  4.4556e-01, -3.7756e-01,  3.5037e-01,\n",
            "          1.0213e-01,  1.8383e-01,  4.7854e-01,  4.5473e-02,  4.7297e-01,\n",
            "         -3.2955e-01, -5.4529e-01, -8.1455e-02,  2.7800e-01, -2.0943e-01,\n",
            "         -4.3471e-01, -2.3967e-01,  1.4236e-01, -4.8717e-01,  5.8243e-02,\n",
            "         -1.1832e-01,  6.5113e-02,  1.1108e-01,  2.3251e-02,  3.2330e-01,\n",
            "          3.0074e-01, -1.9632e-01,  2.7619e-01, -2.2028e-01,  2.8093e-01,\n",
            "         -2.0981e-01,  3.7235e-01, -4.7591e-01, -1.7470e-01,  1.1637e-01,\n",
            "         -3.2703e-01,  1.8774e-01, -2.8153e-01,  2.8637e-01,  3.4758e-01,\n",
            "          4.3403e-01, -1.1568e-01,  2.0266e-01, -3.2388e-01,  3.5193e-01,\n",
            "         -2.8526e-01, -5.9750e-01,  8.3482e-02, -4.1516e-01],\n",
            "        [-4.0823e-01,  4.7973e-01,  2.2877e-01, -1.8444e-01, -2.4290e-01,\n",
            "         -2.0850e-01, -4.1636e-01,  5.1378e-01,  2.8651e-01, -4.6101e-01,\n",
            "          3.2758e-01, -4.5851e-01,  4.5156e-01,  3.9472e-01, -1.8447e-01,\n",
            "         -3.7420e-01, -1.8616e-01, -5.6283e-02, -1.8378e-01, -7.2778e-02,\n",
            "         -2.0458e-01,  6.3440e-02, -2.2062e-01, -2.4068e-01,  4.8843e-01,\n",
            "          2.2425e-01,  5.1602e-01,  1.6423e-01, -2.7833e-02, -4.9412e-02,\n",
            "          8.4959e-02,  3.2736e-01, -4.0366e-01,  4.2470e-01,  2.4179e-01,\n",
            "         -5.2157e-01, -2.0029e-01, -8.2707e-02, -3.5050e-01, -2.3030e-01,\n",
            "         -4.6659e-01, -8.3355e-02,  1.4565e-01, -3.1176e-01,  1.9227e-02,\n",
            "         -5.6992e-03,  2.0588e-01, -2.9231e-01,  2.9820e-01, -4.0199e-01,\n",
            "         -1.5850e-01,  1.7367e-01,  5.2307e-01,  1.8689e-01,  4.4287e-01,\n",
            "         -4.0552e-01,  4.1332e-01, -1.5896e-01, -2.7818e-01, -3.6736e-01,\n",
            "         -3.5464e-01, -3.6775e-02,  1.5397e-01,  3.1856e-02]]), 'num_nodes': 12, 'num_node_features': tensor([64, 64]), 'batch': tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]), 'ptr': tensor([ 0,  6, 12])}}, '_edge_store_dict': {('node', 'CD', 'node'): {'edge_index': tensor([[0, 0, 0, 0, 0, 6, 6, 6, 6],\n",
            "        [0, 0, 0, 0, 0, 7, 7, 7, 7]])}, ('node', 'FD', 'node'): {'edge_index': tensor([[0, 0, 0, 0, 0, 7, 9, 7, 9, 7, 9],\n",
            "        [0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7]])}}}\n",
            "\n",
            "{('node', 'CD', 'node'): {'edge_index': tensor([[0, 0, 0, 0, 0, 6, 6, 6, 6],\n",
            "        [0, 0, 0, 0, 0, 7, 7, 7, 7]])}, ('node', 'FD', 'node'): {'edge_index': tensor([[0, 0, 0, 0, 0, 7, 9, 7, 9, 7, 9],\n",
            "        [0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7]])}}\n",
            "{'_global_store': {'y': tensor([[0., 0., 1.]])}, '_node_store_dict': {'node': {'x': tensor([[ 0.1456, -0.3664, -0.1389, -0.3097, -0.2541, -0.4008,  0.4145,  0.3043,\n",
            "          0.3654,  0.0013,  0.2876, -0.4718, -0.4152,  0.4094,  0.2399, -0.4900,\n",
            "         -0.4600,  0.4566, -0.4910,  0.2632,  0.3687, -0.2352, -0.1895, -0.0964,\n",
            "         -0.0120,  0.4097, -0.0477, -0.2001, -0.3826,  0.5298,  0.5086,  0.1128,\n",
            "         -0.5435, -0.1753, -0.3084,  0.4191, -0.1288, -0.2903,  0.3143, -0.5139,\n",
            "         -0.1392, -0.4412, -0.3825, -0.4452,  0.4280, -0.1966, -0.3084,  0.1565,\n",
            "         -0.0757,  0.3106, -0.2919, -0.0538,  0.4041,  0.2458,  0.2066, -0.0800,\n",
            "         -0.3679,  0.2820,  0.0248, -0.4164, -0.0609,  0.1966, -0.3539,  0.5427],\n",
            "        [-0.2540, -0.4848,  0.0433,  0.1408,  0.2253,  0.0394,  0.3577, -0.1115,\n",
            "         -0.0129,  0.3216,  0.0769, -0.2294, -0.1812, -0.3127,  0.1179,  0.0714,\n",
            "          0.1572,  0.3949, -0.2610,  0.2634,  0.1940, -0.3969,  0.2122, -0.4521,\n",
            "          0.4091, -0.3378, -0.3415,  0.4216,  0.2251,  0.4155, -0.5380, -0.0750,\n",
            "          0.1296, -0.2907, -0.1060, -0.2580,  0.6248,  0.0448,  0.4242,  0.2426,\n",
            "          0.5679, -0.4362,  0.0228, -0.1314, -0.4253, -0.2159, -0.3535, -0.3309,\n",
            "         -0.1562,  0.2688,  0.2007,  0.0307,  0.2456, -0.1981, -0.5506, -0.0749,\n",
            "          0.3574, -0.0827, -0.2388,  0.3051, -0.2469,  0.0606,  0.1583,  0.4083],\n",
            "        [ 0.0798, -0.4743,  0.0072,  0.5535,  0.3759, -0.5134,  0.3284,  0.5694,\n",
            "         -0.2030,  0.0979,  0.0661,  0.1967, -0.3703,  0.1588,  0.1666,  0.2465,\n",
            "          0.1714,  0.0129, -0.1525, -0.1290,  0.5388, -0.4020, -0.4172, -0.0120,\n",
            "         -0.3621, -0.1616, -0.2046,  0.3707,  0.2743, -0.3517,  0.0919,  0.0649,\n",
            "          0.0766, -0.2709,  0.0546,  0.2740,  0.5040, -0.2771,  0.3195, -0.4502,\n",
            "          0.3233,  0.4823,  0.2367,  0.3987,  0.4334,  0.2193, -0.2057, -0.1434,\n",
            "         -0.3436, -0.0010, -0.0560, -0.3180, -0.1817,  0.4792, -0.3680, -0.3506,\n",
            "          0.3278,  0.1772, -0.4804, -0.1774, -0.2564,  0.2704,  0.3528,  0.1487],\n",
            "        [-0.1042,  0.2380, -0.2351, -0.2912, -0.4517,  0.2344,  0.5195,  0.0465,\n",
            "          0.3876,  0.0863,  0.3760,  0.2096, -0.3923,  0.2774, -0.3302,  0.1202,\n",
            "         -0.2038,  0.4427, -0.3352, -0.1830, -0.5139, -0.5946,  0.4701,  0.5739,\n",
            "          0.2991, -0.1301,  0.2645, -0.1230, -0.2572,  0.4364, -0.3554,  0.3683,\n",
            "         -0.3094,  0.2691,  0.4048,  0.2822,  0.3080, -0.0745,  0.2332, -0.3628,\n",
            "          0.0845,  0.2454,  0.3087, -0.1068, -0.1758, -0.3928, -0.2783, -0.0120,\n",
            "         -0.0695, -0.3481,  0.2734,  0.0712, -0.2566, -0.0995, -0.1655,  0.0804,\n",
            "          0.1426,  0.1286, -0.1513,  0.1519,  0.2518, -0.3281,  0.3926,  0.5226],\n",
            "        [ 0.1215,  0.3101, -0.3400, -0.3717, -0.3394,  0.1297, -0.2103, -0.1353,\n",
            "          0.3776, -0.4941,  0.0127,  0.4460, -0.3592,  0.1652, -0.3444, -0.4618,\n",
            "         -0.1996,  0.4278, -0.1122,  0.3162,  0.3464,  0.3283, -0.1067, -0.0104,\n",
            "         -0.4752, -0.2596, -0.0153, -0.5171,  0.1020,  0.3398,  0.4807,  0.3186,\n",
            "         -0.1796, -0.1551,  0.3314,  0.0893,  0.0807,  0.4602, -0.0286,  0.2299,\n",
            "         -0.3378, -0.3217,  0.3143, -0.0349, -0.3611, -0.3241, -0.1161, -0.1877,\n",
            "         -0.0712, -0.4360,  0.1122,  0.1475,  0.0908,  0.1523, -0.3786,  0.4372,\n",
            "         -0.3874,  0.1202, -0.2671,  0.5074,  0.0129,  0.2074, -0.2325, -0.1762],\n",
            "        [ 0.4220,  0.3193, -0.2840,  0.3442,  0.4867,  0.3804, -0.0889, -0.1319,\n",
            "          0.0372,  0.3851, -0.5174, -0.0414,  0.4121, -0.3185, -0.0162,  0.0289,\n",
            "          0.2957, -0.2154,  0.4137, -0.3451,  0.2257,  0.4191, -0.5888,  0.2570,\n",
            "          0.0735, -0.5749, -0.2515, -0.2372,  0.3386,  0.1174, -0.4139, -0.3836,\n",
            "          0.0636,  0.3020,  0.0880, -0.1180,  0.3031, -0.2657,  0.2716, -0.4047,\n",
            "         -0.0013,  0.1660, -0.2466, -0.4178, -0.2795, -0.0898, -0.5415, -0.0045,\n",
            "         -0.4957,  0.0788,  0.2914,  0.1424,  0.5726, -0.1936,  0.4275,  0.4349,\n",
            "          0.3740, -0.3360,  0.0029,  0.3321,  0.0548,  0.0115,  0.3486, -0.0647]]), 'num_nodes': 6, 'num_node_features': tensor([64]), 'batch': tensor([0, 0, 0, 0, 0, 0]), 'ptr': tensor([0, 6])}}, '_edge_store_dict': {('node', 'CD', 'node'): {'edge_index': tensor([[0, 2, 2, 2, 2],\n",
            "        [2, 2, 2, 2, 2]])}, ('node', 'FD', 'node'): {'edge_index': tensor([[2, 2],\n",
            "        [2, 2]])}}}\n",
            "\n",
            "{('node', 'CD', 'node'): {'edge_index': tensor([[0, 2, 2, 2, 2],\n",
            "        [2, 2, 2, 2, 2]])}, ('node', 'FD', 'node'): {'edge_index': tensor([[2, 2],\n",
            "        [2, 2]])}}\n"
          ]
        }
      ],
      "source": [
        "for data in loader:\n",
        "  print(vars(data))\n",
        "  # data = data.to(device)\n",
        "  print()\n",
        "  print(data._edge_store_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for data in loader2:\n",
        "  print(vars(data))\n",
        "  # data = data.to(device)\n",
        "  print(data._store.x)\n",
        "  print(data.edge_index)\n",
        "  print(data.edge_type)\n",
        "  print(data.batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8ipbdjMsaG1",
        "outputId": "60e4cbb0-3cab-4d22-a907-d173bb3163ed"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_store': {'x': tensor([[ 2.9443e-01,  2.4020e-01, -3.5007e-02, -5.3109e-01,  6.1027e-03,\n",
            "         -1.6022e-01, -3.8866e-01,  2.0816e-01,  3.0737e-01,  7.0874e-02,\n",
            "         -3.3227e-01,  1.6522e-01,  3.9254e-01, -9.6531e-02, -1.2251e-01,\n",
            "          2.7382e-01, -4.3338e-01, -2.6536e-01, -3.2666e-01, -1.2912e-01,\n",
            "         -1.4889e-01, -1.8789e-01,  3.2412e-01, -4.8672e-01,  4.2398e-01,\n",
            "         -2.0261e-01,  1.1859e-01, -1.8840e-01, -3.6493e-01,  4.5412e-01,\n",
            "          8.1351e-02, -4.3888e-01, -2.8010e-01,  1.9178e-01,  4.0664e-01,\n",
            "         -1.9875e-01, -2.1171e-02, -3.4211e-01,  8.3194e-02,  7.9346e-02,\n",
            "         -1.6098e-02, -3.1080e-01, -5.3192e-01,  5.1327e-01, -4.0966e-01,\n",
            "          1.0375e-01, -2.8884e-01,  2.5118e-02,  1.7064e-01,  1.1391e-01,\n",
            "          3.4254e-01,  1.1217e-01, -5.7126e-01,  2.9078e-01, -1.6091e-01,\n",
            "          2.4829e-02, -5.0029e-01, -2.8908e-02, -1.7337e-01,  1.7868e-01,\n",
            "         -1.5459e-02,  3.1262e-01,  2.0956e-01, -2.5593e-01],\n",
            "        [ 1.7770e-01, -2.3009e-01,  4.5689e-01,  1.0094e-01, -2.8150e-01,\n",
            "         -4.2215e-01,  1.2061e-01, -2.5298e-01, -5.3690e-02, -4.5519e-03,\n",
            "          7.3074e-02,  2.7766e-01,  3.9536e-01, -2.4420e-01, -2.7086e-01,\n",
            "          2.8016e-01, -4.3293e-01,  1.7864e-01, -2.6929e-01, -5.1057e-01,\n",
            "          4.9183e-01, -2.5671e-01,  8.0775e-04, -8.1969e-02, -5.2619e-02,\n",
            "         -3.9195e-01, -3.3255e-01, -5.6745e-01,  7.9548e-02,  2.1620e-01,\n",
            "          3.5657e-01, -1.8659e-01, -5.6710e-01, -7.1607e-02,  2.4431e-01,\n",
            "         -2.5407e-01,  2.0474e-01, -5.4094e-01, -2.7053e-01, -1.3981e-01,\n",
            "         -7.4948e-02, -2.9377e-01,  1.8423e-01, -1.7833e-01,  5.0370e-02,\n",
            "         -3.6759e-01,  1.5601e-01,  2.5072e-01, -5.2125e-01, -1.3615e-01,\n",
            "         -4.4381e-01,  8.0419e-02,  3.8014e-01,  2.4570e-02,  4.2053e-01,\n",
            "          3.3400e-01, -5.7145e-02,  1.1518e-01,  2.5186e-01, -5.7882e-01,\n",
            "          3.5421e-01, -3.5838e-02, -9.0272e-02,  2.6345e-01],\n",
            "        [ 4.8777e-01,  2.7161e-01,  4.7382e-03, -3.4038e-01, -4.7300e-01,\n",
            "          6.0694e-01, -4.2306e-01,  4.3846e-01, -4.3730e-01, -1.4178e-01,\n",
            "          1.9863e-01, -2.6091e-01, -2.4979e-01,  2.4218e-01,  4.0476e-01,\n",
            "          2.1090e-03,  4.2535e-01,  5.5792e-01, -5.0635e-01,  1.1964e-01,\n",
            "         -9.1677e-04,  1.1196e-01, -4.9272e-01,  2.8013e-01, -3.4190e-01,\n",
            "          1.4254e-01, -1.0622e-01, -3.0979e-01, -2.8535e-01, -4.2420e-01,\n",
            "          6.1094e-02, -1.7029e-01, -2.9858e-01,  3.1577e-01,  4.1027e-01,\n",
            "         -2.5143e-01,  2.5193e-01, -3.4415e-01,  1.2899e-01,  3.9611e-01,\n",
            "         -3.8233e-01, -1.8182e-01, -1.4528e-02,  2.1883e-01, -3.8970e-01,\n",
            "          3.1556e-01, -4.8400e-01, -2.4615e-02, -2.1895e-01, -1.1946e-01,\n",
            "         -3.5972e-01, -2.7663e-01,  1.8108e-01, -4.5821e-01, -3.3740e-01,\n",
            "         -1.7525e-01, -3.5009e-01, -2.8179e-01, -4.4059e-01, -6.6023e-02,\n",
            "         -6.0092e-02,  9.1427e-02,  8.7923e-02,  1.9497e-01],\n",
            "        [-5.0587e-01,  5.6039e-01, -4.8974e-01, -5.3816e-02, -3.4694e-01,\n",
            "         -2.4207e-01,  3.3092e-01, -2.7769e-01,  2.9510e-01, -4.7216e-01,\n",
            "          4.2415e-01, -2.7692e-01,  4.2993e-01,  1.9047e-01, -4.3891e-01,\n",
            "          4.6834e-01,  4.8203e-01, -3.3334e-01, -1.1645e-01, -2.6487e-01,\n",
            "          9.5159e-02, -1.0721e-01, -7.9359e-02,  5.3533e-01,  2.5151e-01,\n",
            "         -3.6953e-01, -4.5523e-01,  4.6022e-01, -4.1541e-01, -5.1390e-02,\n",
            "         -4.4389e-01, -2.8876e-01, -1.0258e-01,  2.4498e-02,  7.0613e-02,\n",
            "          1.3817e-01,  1.6249e-01,  3.6900e-01, -4.7161e-01,  6.2956e-02,\n",
            "         -4.7652e-01, -2.4537e-01,  3.8694e-01, -1.6667e-01, -6.8921e-02,\n",
            "          3.2098e-01, -2.4683e-01, -3.0128e-01, -1.1418e-01,  4.4599e-01,\n",
            "         -3.1147e-01,  4.9754e-01, -2.6422e-01,  3.1439e-01,  2.6787e-01,\n",
            "         -8.4138e-02,  6.6825e-02, -5.1772e-01,  1.9693e-01, -2.0418e-01,\n",
            "         -2.8821e-01,  2.2320e-01,  4.5607e-01,  2.1529e-01],\n",
            "        [-7.5184e-02, -3.1646e-01, -1.3922e-01,  3.2484e-01,  1.1714e-02,\n",
            "          1.7715e-02, -1.3688e-01, -9.9273e-02,  3.7864e-01, -9.8457e-02,\n",
            "         -2.1247e-01, -2.3844e-01, -5.5708e-01, -2.8508e-01, -5.2007e-02,\n",
            "         -2.7886e-01,  3.6193e-01,  4.3418e-01,  3.0078e-02, -3.7312e-02,\n",
            "          3.2477e-01, -5.1555e-01, -3.2751e-01, -1.8038e-01, -3.1068e-01,\n",
            "          2.6249e-01, -4.9655e-01,  4.9659e-01,  3.6707e-01,  3.6954e-01,\n",
            "         -1.7966e-01, -1.4382e-01, -3.6395e-01, -5.3453e-01, -3.0224e-02,\n",
            "          6.1476e-05,  3.3707e-01,  4.2897e-01,  1.7774e-01, -1.1132e-02,\n",
            "         -4.6030e-01,  3.6889e-01,  2.7127e-01, -3.6692e-01,  4.1122e-01,\n",
            "          2.1559e-01,  2.5799e-01, -2.0675e-01,  4.8900e-01, -2.3623e-02,\n",
            "          1.7534e-01,  1.7801e-01, -4.1555e-01,  2.6550e-01, -7.1864e-02,\n",
            "         -1.3740e-01,  6.2497e-02, -7.4074e-02,  2.0186e-01,  3.2666e-01,\n",
            "          4.0106e-01,  4.3195e-01,  4.8914e-01, -8.5218e-02],\n",
            "        [-1.6295e-01,  5.4341e-01,  1.8002e-01, -2.7558e-01,  2.0765e-01,\n",
            "         -4.7952e-01,  1.7182e-02, -3.9623e-01, -1.9659e-01, -6.7397e-01,\n",
            "          2.6171e-01, -2.0211e-02,  4.7134e-01,  2.3072e-01, -3.4641e-01,\n",
            "         -5.1547e-01,  3.0685e-01,  1.8742e-01, -5.6439e-01, -1.0256e-01,\n",
            "          3.0630e-01, -2.8304e-01,  1.9917e-01,  4.1822e-01, -1.0335e-01,\n",
            "          2.3061e-01, -9.2453e-02, -1.5354e-01, -1.0898e-02,  1.2815e-01,\n",
            "          3.5190e-01,  2.1255e-01, -1.0696e-01,  4.6104e-01, -1.5019e-01,\n",
            "          2.0255e-02, -1.4867e-01,  1.6845e-01,  3.1246e-01,  4.4367e-01,\n",
            "          2.6453e-01, -2.0991e-01, -3.3357e-01,  4.0514e-02,  2.9127e-01,\n",
            "          3.9863e-01, -2.1284e-01,  3.6842e-01,  6.7295e-02,  1.9745e-01,\n",
            "          4.6634e-02,  8.0407e-02,  1.7949e-01, -4.3314e-03, -4.9930e-01,\n",
            "         -3.4889e-01,  3.1721e-01,  4.3418e-01,  1.8255e-01,  6.6883e-02,\n",
            "         -2.2133e-02, -2.2941e-01,  2.7484e-01,  3.5313e-02],\n",
            "        [-1.6965e-03,  4.1815e-01,  2.3695e-01,  4.5044e-01,  3.8478e-01,\n",
            "          7.5692e-02, -4.4112e-01, -2.4210e-01,  1.6479e-01, -3.4364e-01,\n",
            "         -5.3430e-01, -3.9185e-02, -4.4625e-02, -3.5618e-01,  1.6090e-01,\n",
            "         -8.9444e-02, -9.7509e-02, -1.1142e-01, -2.1282e-02,  5.0590e-01,\n",
            "          2.0685e-01,  6.4264e-01,  1.2080e-01, -3.6301e-01, -9.4240e-02,\n",
            "          2.6062e-01, -3.7572e-01, -4.6222e-01,  2.7940e-02,  2.9970e-01,\n",
            "         -5.1826e-01,  2.5681e-01,  3.1571e-01, -3.1959e-01, -2.3713e-01,\n",
            "         -3.9801e-02,  5.7085e-01,  3.0368e-01, -1.7566e-01, -5.5471e-01,\n",
            "         -4.1144e-01,  4.3922e-02, -2.0792e-01, -3.0493e-01,  2.1020e-01,\n",
            "         -2.8494e-01,  2.7256e-01, -1.4883e-02,  8.1984e-02, -2.0212e-01,\n",
            "          2.0692e-01,  2.7645e-01,  2.2291e-01, -3.2714e-01, -5.4224e-03,\n",
            "         -2.4555e-01,  5.0170e-01, -1.6703e-01, -5.5531e-04, -5.0613e-02,\n",
            "          6.9050e-03, -4.4529e-01,  3.1954e-02,  4.5596e-01],\n",
            "        [ 4.2967e-01, -1.7668e-01,  4.4497e-01, -6.6255e-02,  2.8526e-01,\n",
            "          2.3307e-01,  2.1988e-01, -3.4524e-01,  3.1513e-01,  1.4660e-01,\n",
            "         -3.1111e-01, -2.0904e-01, -4.5973e-01, -2.4059e-02,  4.3938e-01,\n",
            "          1.3524e-01, -3.2237e-01, -4.9100e-01,  4.7710e-02, -3.3337e-01,\n",
            "          3.2446e-01, -3.0649e-01, -2.4198e-01,  4.7776e-02,  3.1759e-01,\n",
            "          3.4821e-01, -4.3871e-01, -2.1977e-02,  2.8074e-01, -3.6511e-01,\n",
            "         -2.4598e-01, -1.0788e-01, -2.7688e-01, -2.9747e-02, -4.5003e-01,\n",
            "         -3.9471e-01, -3.5545e-01, -1.0777e-01,  3.4453e-01,  5.9166e-02,\n",
            "          3.8358e-01, -4.3514e-01,  4.0858e-01, -3.8324e-02, -4.3232e-01,\n",
            "          4.9553e-01,  2.1442e-01,  1.7107e-01,  2.8733e-01,  3.4957e-01,\n",
            "          3.6921e-01, -3.6882e-01, -3.0125e-01, -2.8976e-01, -4.6522e-01,\n",
            "         -3.6242e-01, -2.3915e-01, -5.4283e-03,  2.1762e-01,  3.8712e-01,\n",
            "         -1.6681e-01,  3.1029e-01,  2.9415e-01, -1.3352e-01],\n",
            "        [ 2.1060e-01, -2.8763e-01, -3.4052e-01,  2.8882e-01, -4.3288e-01,\n",
            "         -3.7122e-01,  5.0360e-01, -2.8117e-01,  3.8774e-01,  1.0704e-01,\n",
            "         -1.4586e-02, -3.9321e-02, -3.3351e-01,  4.7562e-01, -1.7641e-01,\n",
            "          1.0089e-01, -5.2658e-02,  4.6453e-01,  8.7285e-02, -2.7073e-01,\n",
            "          2.1790e-01, -5.6495e-01,  4.1967e-01, -2.6074e-01,  1.3662e-01,\n",
            "         -3.4449e-01, -1.6030e-04,  4.0013e-01,  1.1299e-01,  7.5611e-02,\n",
            "         -2.7383e-01, -2.1492e-01,  2.1772e-02, -1.2551e-01,  1.5349e-01,\n",
            "         -2.1680e-01, -4.3692e-01,  3.3205e-01, -3.2679e-01, -4.4146e-01,\n",
            "          4.9950e-01,  3.0813e-01, -7.7946e-02, -3.1638e-01,  1.4997e-01,\n",
            "         -1.6539e-01, -1.9834e-01, -2.8196e-01,  1.7658e-01, -1.3021e-04,\n",
            "         -4.2929e-01,  1.4016e-01, -9.6505e-02, -3.3792e-01, -1.1204e-01,\n",
            "          4.7436e-01,  9.1546e-02, -2.5717e-01,  3.7672e-01,  2.8204e-02,\n",
            "         -1.1113e-01, -4.0520e-01,  5.5472e-01, -2.4749e-01],\n",
            "        [ 3.7146e-01, -2.4193e-01, -3.2995e-01, -3.5705e-01, -3.5603e-01,\n",
            "         -2.8366e-01,  1.3212e-01,  5.5947e-02, -3.6467e-01, -1.5718e-01,\n",
            "         -4.5169e-01, -5.1850e-01,  8.5571e-02,  9.1580e-02,  3.6476e-01,\n",
            "          1.0827e-02, -2.7458e-01, -2.9223e-01, -4.2275e-01,  2.4894e-01,\n",
            "         -2.7921e-01, -2.7068e-01,  2.0845e-01,  2.0572e-01, -3.8617e-02,\n",
            "          4.6667e-01,  4.4596e-01,  4.6134e-02,  4.0902e-01,  1.5213e-01,\n",
            "          4.0628e-01, -7.8878e-02,  4.3719e-01,  4.0467e-02,  4.1432e-01,\n",
            "          2.1988e-01, -4.6529e-01, -4.2236e-01,  1.7599e-01, -2.2378e-02,\n",
            "         -4.3121e-01,  3.0813e-01,  1.8547e-01,  3.1668e-01, -1.8582e-01,\n",
            "          1.6303e-01,  2.4759e-01, -5.7322e-02,  3.5467e-01, -1.9710e-01,\n",
            "         -3.1371e-01, -4.0319e-01,  4.6170e-01,  2.8482e-01, -7.2999e-02,\n",
            "         -3.7440e-01,  4.6278e-01, -3.5013e-02,  5.3443e-01,  2.8034e-01,\n",
            "          2.0876e-01, -3.4044e-01,  3.9429e-01, -1.8728e-01],\n",
            "        [-3.8688e-01, -3.4540e-01,  3.3025e-02,  3.1577e-01, -2.2469e-01,\n",
            "         -2.1002e-01, -4.9464e-03,  3.9412e-01, -2.9980e-01,  3.0216e-01,\n",
            "          2.5909e-01,  5.8003e-01,  3.4712e-02,  3.8863e-01, -2.4669e-01,\n",
            "          1.6298e-01,  1.9696e-02,  4.4556e-01, -3.7756e-01,  3.5037e-01,\n",
            "          1.0213e-01,  1.8383e-01,  4.7854e-01,  4.5473e-02,  4.7297e-01,\n",
            "         -3.2955e-01, -5.4529e-01, -8.1455e-02,  2.7800e-01, -2.0943e-01,\n",
            "         -4.3471e-01, -2.3967e-01,  1.4236e-01, -4.8717e-01,  5.8243e-02,\n",
            "         -1.1832e-01,  6.5113e-02,  1.1108e-01,  2.3251e-02,  3.2330e-01,\n",
            "          3.0074e-01, -1.9632e-01,  2.7619e-01, -2.2028e-01,  2.8093e-01,\n",
            "         -2.0981e-01,  3.7235e-01, -4.7591e-01, -1.7470e-01,  1.1637e-01,\n",
            "         -3.2703e-01,  1.8774e-01, -2.8153e-01,  2.8637e-01,  3.4758e-01,\n",
            "          4.3403e-01, -1.1568e-01,  2.0266e-01, -3.2388e-01,  3.5193e-01,\n",
            "         -2.8526e-01, -5.9750e-01,  8.3482e-02, -4.1516e-01],\n",
            "        [-4.0823e-01,  4.7973e-01,  2.2877e-01, -1.8444e-01, -2.4290e-01,\n",
            "         -2.0850e-01, -4.1636e-01,  5.1378e-01,  2.8651e-01, -4.6101e-01,\n",
            "          3.2758e-01, -4.5851e-01,  4.5156e-01,  3.9472e-01, -1.8447e-01,\n",
            "         -3.7420e-01, -1.8616e-01, -5.6283e-02, -1.8378e-01, -7.2778e-02,\n",
            "         -2.0458e-01,  6.3440e-02, -2.2062e-01, -2.4068e-01,  4.8843e-01,\n",
            "          2.2425e-01,  5.1602e-01,  1.6423e-01, -2.7833e-02, -4.9412e-02,\n",
            "          8.4959e-02,  3.2736e-01, -4.0366e-01,  4.2470e-01,  2.4179e-01,\n",
            "         -5.2157e-01, -2.0029e-01, -8.2707e-02, -3.5050e-01, -2.3030e-01,\n",
            "         -4.6659e-01, -8.3355e-02,  1.4565e-01, -3.1176e-01,  1.9227e-02,\n",
            "         -5.6992e-03,  2.0588e-01, -2.9231e-01,  2.9820e-01, -4.0199e-01,\n",
            "         -1.5850e-01,  1.7367e-01,  5.2307e-01,  1.8689e-01,  4.4287e-01,\n",
            "         -4.0552e-01,  4.1332e-01, -1.5896e-01, -2.7818e-01, -3.6736e-01,\n",
            "         -3.5464e-01, -3.6775e-02,  1.5397e-01,  3.1856e-02]]), 'edge_index': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 6, 7, 9, 6, 7, 9, 6, 7, 9],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]]), 'edge_type': tensor([1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]), 'y': tensor([[0., 0., 1.],\n",
            "        [0., 0., 1.]]), 'num_nodes': 12, 'batch': tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]), 'ptr': tensor([ 0,  6, 12])}}\n",
            "tensor([[ 2.9443e-01,  2.4020e-01, -3.5007e-02, -5.3109e-01,  6.1027e-03,\n",
            "         -1.6022e-01, -3.8866e-01,  2.0816e-01,  3.0737e-01,  7.0874e-02,\n",
            "         -3.3227e-01,  1.6522e-01,  3.9254e-01, -9.6531e-02, -1.2251e-01,\n",
            "          2.7382e-01, -4.3338e-01, -2.6536e-01, -3.2666e-01, -1.2912e-01,\n",
            "         -1.4889e-01, -1.8789e-01,  3.2412e-01, -4.8672e-01,  4.2398e-01,\n",
            "         -2.0261e-01,  1.1859e-01, -1.8840e-01, -3.6493e-01,  4.5412e-01,\n",
            "          8.1351e-02, -4.3888e-01, -2.8010e-01,  1.9178e-01,  4.0664e-01,\n",
            "         -1.9875e-01, -2.1171e-02, -3.4211e-01,  8.3194e-02,  7.9346e-02,\n",
            "         -1.6098e-02, -3.1080e-01, -5.3192e-01,  5.1327e-01, -4.0966e-01,\n",
            "          1.0375e-01, -2.8884e-01,  2.5118e-02,  1.7064e-01,  1.1391e-01,\n",
            "          3.4254e-01,  1.1217e-01, -5.7126e-01,  2.9078e-01, -1.6091e-01,\n",
            "          2.4829e-02, -5.0029e-01, -2.8908e-02, -1.7337e-01,  1.7868e-01,\n",
            "         -1.5459e-02,  3.1262e-01,  2.0956e-01, -2.5593e-01],\n",
            "        [ 1.7770e-01, -2.3009e-01,  4.5689e-01,  1.0094e-01, -2.8150e-01,\n",
            "         -4.2215e-01,  1.2061e-01, -2.5298e-01, -5.3690e-02, -4.5519e-03,\n",
            "          7.3074e-02,  2.7766e-01,  3.9536e-01, -2.4420e-01, -2.7086e-01,\n",
            "          2.8016e-01, -4.3293e-01,  1.7864e-01, -2.6929e-01, -5.1057e-01,\n",
            "          4.9183e-01, -2.5671e-01,  8.0775e-04, -8.1969e-02, -5.2619e-02,\n",
            "         -3.9195e-01, -3.3255e-01, -5.6745e-01,  7.9548e-02,  2.1620e-01,\n",
            "          3.5657e-01, -1.8659e-01, -5.6710e-01, -7.1607e-02,  2.4431e-01,\n",
            "         -2.5407e-01,  2.0474e-01, -5.4094e-01, -2.7053e-01, -1.3981e-01,\n",
            "         -7.4948e-02, -2.9377e-01,  1.8423e-01, -1.7833e-01,  5.0370e-02,\n",
            "         -3.6759e-01,  1.5601e-01,  2.5072e-01, -5.2125e-01, -1.3615e-01,\n",
            "         -4.4381e-01,  8.0419e-02,  3.8014e-01,  2.4570e-02,  4.2053e-01,\n",
            "          3.3400e-01, -5.7145e-02,  1.1518e-01,  2.5186e-01, -5.7882e-01,\n",
            "          3.5421e-01, -3.5838e-02, -9.0272e-02,  2.6345e-01],\n",
            "        [ 4.8777e-01,  2.7161e-01,  4.7382e-03, -3.4038e-01, -4.7300e-01,\n",
            "          6.0694e-01, -4.2306e-01,  4.3846e-01, -4.3730e-01, -1.4178e-01,\n",
            "          1.9863e-01, -2.6091e-01, -2.4979e-01,  2.4218e-01,  4.0476e-01,\n",
            "          2.1090e-03,  4.2535e-01,  5.5792e-01, -5.0635e-01,  1.1964e-01,\n",
            "         -9.1677e-04,  1.1196e-01, -4.9272e-01,  2.8013e-01, -3.4190e-01,\n",
            "          1.4254e-01, -1.0622e-01, -3.0979e-01, -2.8535e-01, -4.2420e-01,\n",
            "          6.1094e-02, -1.7029e-01, -2.9858e-01,  3.1577e-01,  4.1027e-01,\n",
            "         -2.5143e-01,  2.5193e-01, -3.4415e-01,  1.2899e-01,  3.9611e-01,\n",
            "         -3.8233e-01, -1.8182e-01, -1.4528e-02,  2.1883e-01, -3.8970e-01,\n",
            "          3.1556e-01, -4.8400e-01, -2.4615e-02, -2.1895e-01, -1.1946e-01,\n",
            "         -3.5972e-01, -2.7663e-01,  1.8108e-01, -4.5821e-01, -3.3740e-01,\n",
            "         -1.7525e-01, -3.5009e-01, -2.8179e-01, -4.4059e-01, -6.6023e-02,\n",
            "         -6.0092e-02,  9.1427e-02,  8.7923e-02,  1.9497e-01],\n",
            "        [-5.0587e-01,  5.6039e-01, -4.8974e-01, -5.3816e-02, -3.4694e-01,\n",
            "         -2.4207e-01,  3.3092e-01, -2.7769e-01,  2.9510e-01, -4.7216e-01,\n",
            "          4.2415e-01, -2.7692e-01,  4.2993e-01,  1.9047e-01, -4.3891e-01,\n",
            "          4.6834e-01,  4.8203e-01, -3.3334e-01, -1.1645e-01, -2.6487e-01,\n",
            "          9.5159e-02, -1.0721e-01, -7.9359e-02,  5.3533e-01,  2.5151e-01,\n",
            "         -3.6953e-01, -4.5523e-01,  4.6022e-01, -4.1541e-01, -5.1390e-02,\n",
            "         -4.4389e-01, -2.8876e-01, -1.0258e-01,  2.4498e-02,  7.0613e-02,\n",
            "          1.3817e-01,  1.6249e-01,  3.6900e-01, -4.7161e-01,  6.2956e-02,\n",
            "         -4.7652e-01, -2.4537e-01,  3.8694e-01, -1.6667e-01, -6.8921e-02,\n",
            "          3.2098e-01, -2.4683e-01, -3.0128e-01, -1.1418e-01,  4.4599e-01,\n",
            "         -3.1147e-01,  4.9754e-01, -2.6422e-01,  3.1439e-01,  2.6787e-01,\n",
            "         -8.4138e-02,  6.6825e-02, -5.1772e-01,  1.9693e-01, -2.0418e-01,\n",
            "         -2.8821e-01,  2.2320e-01,  4.5607e-01,  2.1529e-01],\n",
            "        [-7.5184e-02, -3.1646e-01, -1.3922e-01,  3.2484e-01,  1.1714e-02,\n",
            "          1.7715e-02, -1.3688e-01, -9.9273e-02,  3.7864e-01, -9.8457e-02,\n",
            "         -2.1247e-01, -2.3844e-01, -5.5708e-01, -2.8508e-01, -5.2007e-02,\n",
            "         -2.7886e-01,  3.6193e-01,  4.3418e-01,  3.0078e-02, -3.7312e-02,\n",
            "          3.2477e-01, -5.1555e-01, -3.2751e-01, -1.8038e-01, -3.1068e-01,\n",
            "          2.6249e-01, -4.9655e-01,  4.9659e-01,  3.6707e-01,  3.6954e-01,\n",
            "         -1.7966e-01, -1.4382e-01, -3.6395e-01, -5.3453e-01, -3.0224e-02,\n",
            "          6.1476e-05,  3.3707e-01,  4.2897e-01,  1.7774e-01, -1.1132e-02,\n",
            "         -4.6030e-01,  3.6889e-01,  2.7127e-01, -3.6692e-01,  4.1122e-01,\n",
            "          2.1559e-01,  2.5799e-01, -2.0675e-01,  4.8900e-01, -2.3623e-02,\n",
            "          1.7534e-01,  1.7801e-01, -4.1555e-01,  2.6550e-01, -7.1864e-02,\n",
            "         -1.3740e-01,  6.2497e-02, -7.4074e-02,  2.0186e-01,  3.2666e-01,\n",
            "          4.0106e-01,  4.3195e-01,  4.8914e-01, -8.5218e-02],\n",
            "        [-1.6295e-01,  5.4341e-01,  1.8002e-01, -2.7558e-01,  2.0765e-01,\n",
            "         -4.7952e-01,  1.7182e-02, -3.9623e-01, -1.9659e-01, -6.7397e-01,\n",
            "          2.6171e-01, -2.0211e-02,  4.7134e-01,  2.3072e-01, -3.4641e-01,\n",
            "         -5.1547e-01,  3.0685e-01,  1.8742e-01, -5.6439e-01, -1.0256e-01,\n",
            "          3.0630e-01, -2.8304e-01,  1.9917e-01,  4.1822e-01, -1.0335e-01,\n",
            "          2.3061e-01, -9.2453e-02, -1.5354e-01, -1.0898e-02,  1.2815e-01,\n",
            "          3.5190e-01,  2.1255e-01, -1.0696e-01,  4.6104e-01, -1.5019e-01,\n",
            "          2.0255e-02, -1.4867e-01,  1.6845e-01,  3.1246e-01,  4.4367e-01,\n",
            "          2.6453e-01, -2.0991e-01, -3.3357e-01,  4.0514e-02,  2.9127e-01,\n",
            "          3.9863e-01, -2.1284e-01,  3.6842e-01,  6.7295e-02,  1.9745e-01,\n",
            "          4.6634e-02,  8.0407e-02,  1.7949e-01, -4.3314e-03, -4.9930e-01,\n",
            "         -3.4889e-01,  3.1721e-01,  4.3418e-01,  1.8255e-01,  6.6883e-02,\n",
            "         -2.2133e-02, -2.2941e-01,  2.7484e-01,  3.5313e-02],\n",
            "        [-1.6965e-03,  4.1815e-01,  2.3695e-01,  4.5044e-01,  3.8478e-01,\n",
            "          7.5692e-02, -4.4112e-01, -2.4210e-01,  1.6479e-01, -3.4364e-01,\n",
            "         -5.3430e-01, -3.9185e-02, -4.4625e-02, -3.5618e-01,  1.6090e-01,\n",
            "         -8.9444e-02, -9.7509e-02, -1.1142e-01, -2.1282e-02,  5.0590e-01,\n",
            "          2.0685e-01,  6.4264e-01,  1.2080e-01, -3.6301e-01, -9.4240e-02,\n",
            "          2.6062e-01, -3.7572e-01, -4.6222e-01,  2.7940e-02,  2.9970e-01,\n",
            "         -5.1826e-01,  2.5681e-01,  3.1571e-01, -3.1959e-01, -2.3713e-01,\n",
            "         -3.9801e-02,  5.7085e-01,  3.0368e-01, -1.7566e-01, -5.5471e-01,\n",
            "         -4.1144e-01,  4.3922e-02, -2.0792e-01, -3.0493e-01,  2.1020e-01,\n",
            "         -2.8494e-01,  2.7256e-01, -1.4883e-02,  8.1984e-02, -2.0212e-01,\n",
            "          2.0692e-01,  2.7645e-01,  2.2291e-01, -3.2714e-01, -5.4224e-03,\n",
            "         -2.4555e-01,  5.0170e-01, -1.6703e-01, -5.5531e-04, -5.0613e-02,\n",
            "          6.9050e-03, -4.4529e-01,  3.1954e-02,  4.5596e-01],\n",
            "        [ 4.2967e-01, -1.7668e-01,  4.4497e-01, -6.6255e-02,  2.8526e-01,\n",
            "          2.3307e-01,  2.1988e-01, -3.4524e-01,  3.1513e-01,  1.4660e-01,\n",
            "         -3.1111e-01, -2.0904e-01, -4.5973e-01, -2.4059e-02,  4.3938e-01,\n",
            "          1.3524e-01, -3.2237e-01, -4.9100e-01,  4.7710e-02, -3.3337e-01,\n",
            "          3.2446e-01, -3.0649e-01, -2.4198e-01,  4.7776e-02,  3.1759e-01,\n",
            "          3.4821e-01, -4.3871e-01, -2.1977e-02,  2.8074e-01, -3.6511e-01,\n",
            "         -2.4598e-01, -1.0788e-01, -2.7688e-01, -2.9747e-02, -4.5003e-01,\n",
            "         -3.9471e-01, -3.5545e-01, -1.0777e-01,  3.4453e-01,  5.9166e-02,\n",
            "          3.8358e-01, -4.3514e-01,  4.0858e-01, -3.8324e-02, -4.3232e-01,\n",
            "          4.9553e-01,  2.1442e-01,  1.7107e-01,  2.8733e-01,  3.4957e-01,\n",
            "          3.6921e-01, -3.6882e-01, -3.0125e-01, -2.8976e-01, -4.6522e-01,\n",
            "         -3.6242e-01, -2.3915e-01, -5.4283e-03,  2.1762e-01,  3.8712e-01,\n",
            "         -1.6681e-01,  3.1029e-01,  2.9415e-01, -1.3352e-01],\n",
            "        [ 2.1060e-01, -2.8763e-01, -3.4052e-01,  2.8882e-01, -4.3288e-01,\n",
            "         -3.7122e-01,  5.0360e-01, -2.8117e-01,  3.8774e-01,  1.0704e-01,\n",
            "         -1.4586e-02, -3.9321e-02, -3.3351e-01,  4.7562e-01, -1.7641e-01,\n",
            "          1.0089e-01, -5.2658e-02,  4.6453e-01,  8.7285e-02, -2.7073e-01,\n",
            "          2.1790e-01, -5.6495e-01,  4.1967e-01, -2.6074e-01,  1.3662e-01,\n",
            "         -3.4449e-01, -1.6030e-04,  4.0013e-01,  1.1299e-01,  7.5611e-02,\n",
            "         -2.7383e-01, -2.1492e-01,  2.1772e-02, -1.2551e-01,  1.5349e-01,\n",
            "         -2.1680e-01, -4.3692e-01,  3.3205e-01, -3.2679e-01, -4.4146e-01,\n",
            "          4.9950e-01,  3.0813e-01, -7.7946e-02, -3.1638e-01,  1.4997e-01,\n",
            "         -1.6539e-01, -1.9834e-01, -2.8196e-01,  1.7658e-01, -1.3021e-04,\n",
            "         -4.2929e-01,  1.4016e-01, -9.6505e-02, -3.3792e-01, -1.1204e-01,\n",
            "          4.7436e-01,  9.1546e-02, -2.5717e-01,  3.7672e-01,  2.8204e-02,\n",
            "         -1.1113e-01, -4.0520e-01,  5.5472e-01, -2.4749e-01],\n",
            "        [ 3.7146e-01, -2.4193e-01, -3.2995e-01, -3.5705e-01, -3.5603e-01,\n",
            "         -2.8366e-01,  1.3212e-01,  5.5947e-02, -3.6467e-01, -1.5718e-01,\n",
            "         -4.5169e-01, -5.1850e-01,  8.5571e-02,  9.1580e-02,  3.6476e-01,\n",
            "          1.0827e-02, -2.7458e-01, -2.9223e-01, -4.2275e-01,  2.4894e-01,\n",
            "         -2.7921e-01, -2.7068e-01,  2.0845e-01,  2.0572e-01, -3.8617e-02,\n",
            "          4.6667e-01,  4.4596e-01,  4.6134e-02,  4.0902e-01,  1.5213e-01,\n",
            "          4.0628e-01, -7.8878e-02,  4.3719e-01,  4.0467e-02,  4.1432e-01,\n",
            "          2.1988e-01, -4.6529e-01, -4.2236e-01,  1.7599e-01, -2.2378e-02,\n",
            "         -4.3121e-01,  3.0813e-01,  1.8547e-01,  3.1668e-01, -1.8582e-01,\n",
            "          1.6303e-01,  2.4759e-01, -5.7322e-02,  3.5467e-01, -1.9710e-01,\n",
            "         -3.1371e-01, -4.0319e-01,  4.6170e-01,  2.8482e-01, -7.2999e-02,\n",
            "         -3.7440e-01,  4.6278e-01, -3.5013e-02,  5.3443e-01,  2.8034e-01,\n",
            "          2.0876e-01, -3.4044e-01,  3.9429e-01, -1.8728e-01],\n",
            "        [-3.8688e-01, -3.4540e-01,  3.3025e-02,  3.1577e-01, -2.2469e-01,\n",
            "         -2.1002e-01, -4.9464e-03,  3.9412e-01, -2.9980e-01,  3.0216e-01,\n",
            "          2.5909e-01,  5.8003e-01,  3.4712e-02,  3.8863e-01, -2.4669e-01,\n",
            "          1.6298e-01,  1.9696e-02,  4.4556e-01, -3.7756e-01,  3.5037e-01,\n",
            "          1.0213e-01,  1.8383e-01,  4.7854e-01,  4.5473e-02,  4.7297e-01,\n",
            "         -3.2955e-01, -5.4529e-01, -8.1455e-02,  2.7800e-01, -2.0943e-01,\n",
            "         -4.3471e-01, -2.3967e-01,  1.4236e-01, -4.8717e-01,  5.8243e-02,\n",
            "         -1.1832e-01,  6.5113e-02,  1.1108e-01,  2.3251e-02,  3.2330e-01,\n",
            "          3.0074e-01, -1.9632e-01,  2.7619e-01, -2.2028e-01,  2.8093e-01,\n",
            "         -2.0981e-01,  3.7235e-01, -4.7591e-01, -1.7470e-01,  1.1637e-01,\n",
            "         -3.2703e-01,  1.8774e-01, -2.8153e-01,  2.8637e-01,  3.4758e-01,\n",
            "          4.3403e-01, -1.1568e-01,  2.0266e-01, -3.2388e-01,  3.5193e-01,\n",
            "         -2.8526e-01, -5.9750e-01,  8.3482e-02, -4.1516e-01],\n",
            "        [-4.0823e-01,  4.7973e-01,  2.2877e-01, -1.8444e-01, -2.4290e-01,\n",
            "         -2.0850e-01, -4.1636e-01,  5.1378e-01,  2.8651e-01, -4.6101e-01,\n",
            "          3.2758e-01, -4.5851e-01,  4.5156e-01,  3.9472e-01, -1.8447e-01,\n",
            "         -3.7420e-01, -1.8616e-01, -5.6283e-02, -1.8378e-01, -7.2778e-02,\n",
            "         -2.0458e-01,  6.3440e-02, -2.2062e-01, -2.4068e-01,  4.8843e-01,\n",
            "          2.2425e-01,  5.1602e-01,  1.6423e-01, -2.7833e-02, -4.9412e-02,\n",
            "          8.4959e-02,  3.2736e-01, -4.0366e-01,  4.2470e-01,  2.4179e-01,\n",
            "         -5.2157e-01, -2.0029e-01, -8.2707e-02, -3.5050e-01, -2.3030e-01,\n",
            "         -4.6659e-01, -8.3355e-02,  1.4565e-01, -3.1176e-01,  1.9227e-02,\n",
            "         -5.6992e-03,  2.0588e-01, -2.9231e-01,  2.9820e-01, -4.0199e-01,\n",
            "         -1.5850e-01,  1.7367e-01,  5.2307e-01,  1.8689e-01,  4.4287e-01,\n",
            "         -4.0552e-01,  4.1332e-01, -1.5896e-01, -2.7818e-01, -3.6736e-01,\n",
            "         -3.5464e-01, -3.6775e-02,  1.5397e-01,  3.1856e-02]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 6, 7, 9, 6, 7, 9, 6, 7, 9],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]])\n",
            "tensor([1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0])\n",
            "tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
            "{'_store': {'x': tensor([[ 0.1456, -0.3664, -0.1389, -0.3097, -0.2541, -0.4008,  0.4145,  0.3043,\n",
            "          0.3654,  0.0013,  0.2876, -0.4718, -0.4152,  0.4094,  0.2399, -0.4900,\n",
            "         -0.4600,  0.4566, -0.4910,  0.2632,  0.3687, -0.2352, -0.1895, -0.0964,\n",
            "         -0.0120,  0.4097, -0.0477, -0.2001, -0.3826,  0.5298,  0.5086,  0.1128,\n",
            "         -0.5435, -0.1753, -0.3084,  0.4191, -0.1288, -0.2903,  0.3143, -0.5139,\n",
            "         -0.1392, -0.4412, -0.3825, -0.4452,  0.4280, -0.1966, -0.3084,  0.1565,\n",
            "         -0.0757,  0.3106, -0.2919, -0.0538,  0.4041,  0.2458,  0.2066, -0.0800,\n",
            "         -0.3679,  0.2820,  0.0248, -0.4164, -0.0609,  0.1966, -0.3539,  0.5427],\n",
            "        [-0.2540, -0.4848,  0.0433,  0.1408,  0.2253,  0.0394,  0.3577, -0.1115,\n",
            "         -0.0129,  0.3216,  0.0769, -0.2294, -0.1812, -0.3127,  0.1179,  0.0714,\n",
            "          0.1572,  0.3949, -0.2610,  0.2634,  0.1940, -0.3969,  0.2122, -0.4521,\n",
            "          0.4091, -0.3378, -0.3415,  0.4216,  0.2251,  0.4155, -0.5380, -0.0750,\n",
            "          0.1296, -0.2907, -0.1060, -0.2580,  0.6248,  0.0448,  0.4242,  0.2426,\n",
            "          0.5679, -0.4362,  0.0228, -0.1314, -0.4253, -0.2159, -0.3535, -0.3309,\n",
            "         -0.1562,  0.2688,  0.2007,  0.0307,  0.2456, -0.1981, -0.5506, -0.0749,\n",
            "          0.3574, -0.0827, -0.2388,  0.3051, -0.2469,  0.0606,  0.1583,  0.4083],\n",
            "        [ 0.0798, -0.4743,  0.0072,  0.5535,  0.3759, -0.5134,  0.3284,  0.5694,\n",
            "         -0.2030,  0.0979,  0.0661,  0.1967, -0.3703,  0.1588,  0.1666,  0.2465,\n",
            "          0.1714,  0.0129, -0.1525, -0.1290,  0.5388, -0.4020, -0.4172, -0.0120,\n",
            "         -0.3621, -0.1616, -0.2046,  0.3707,  0.2743, -0.3517,  0.0919,  0.0649,\n",
            "          0.0766, -0.2709,  0.0546,  0.2740,  0.5040, -0.2771,  0.3195, -0.4502,\n",
            "          0.3233,  0.4823,  0.2367,  0.3987,  0.4334,  0.2193, -0.2057, -0.1434,\n",
            "         -0.3436, -0.0010, -0.0560, -0.3180, -0.1817,  0.4792, -0.3680, -0.3506,\n",
            "          0.3278,  0.1772, -0.4804, -0.1774, -0.2564,  0.2704,  0.3528,  0.1487],\n",
            "        [-0.1042,  0.2380, -0.2351, -0.2912, -0.4517,  0.2344,  0.5195,  0.0465,\n",
            "          0.3876,  0.0863,  0.3760,  0.2096, -0.3923,  0.2774, -0.3302,  0.1202,\n",
            "         -0.2038,  0.4427, -0.3352, -0.1830, -0.5139, -0.5946,  0.4701,  0.5739,\n",
            "          0.2991, -0.1301,  0.2645, -0.1230, -0.2572,  0.4364, -0.3554,  0.3683,\n",
            "         -0.3094,  0.2691,  0.4048,  0.2822,  0.3080, -0.0745,  0.2332, -0.3628,\n",
            "          0.0845,  0.2454,  0.3087, -0.1068, -0.1758, -0.3928, -0.2783, -0.0120,\n",
            "         -0.0695, -0.3481,  0.2734,  0.0712, -0.2566, -0.0995, -0.1655,  0.0804,\n",
            "          0.1426,  0.1286, -0.1513,  0.1519,  0.2518, -0.3281,  0.3926,  0.5226],\n",
            "        [ 0.1215,  0.3101, -0.3400, -0.3717, -0.3394,  0.1297, -0.2103, -0.1353,\n",
            "          0.3776, -0.4941,  0.0127,  0.4460, -0.3592,  0.1652, -0.3444, -0.4618,\n",
            "         -0.1996,  0.4278, -0.1122,  0.3162,  0.3464,  0.3283, -0.1067, -0.0104,\n",
            "         -0.4752, -0.2596, -0.0153, -0.5171,  0.1020,  0.3398,  0.4807,  0.3186,\n",
            "         -0.1796, -0.1551,  0.3314,  0.0893,  0.0807,  0.4602, -0.0286,  0.2299,\n",
            "         -0.3378, -0.3217,  0.3143, -0.0349, -0.3611, -0.3241, -0.1161, -0.1877,\n",
            "         -0.0712, -0.4360,  0.1122,  0.1475,  0.0908,  0.1523, -0.3786,  0.4372,\n",
            "         -0.3874,  0.1202, -0.2671,  0.5074,  0.0129,  0.2074, -0.2325, -0.1762],\n",
            "        [ 0.4220,  0.3193, -0.2840,  0.3442,  0.4867,  0.3804, -0.0889, -0.1319,\n",
            "          0.0372,  0.3851, -0.5174, -0.0414,  0.4121, -0.3185, -0.0162,  0.0289,\n",
            "          0.2957, -0.2154,  0.4137, -0.3451,  0.2257,  0.4191, -0.5888,  0.2570,\n",
            "          0.0735, -0.5749, -0.2515, -0.2372,  0.3386,  0.1174, -0.4139, -0.3836,\n",
            "          0.0636,  0.3020,  0.0880, -0.1180,  0.3031, -0.2657,  0.2716, -0.4047,\n",
            "         -0.0013,  0.1660, -0.2466, -0.4178, -0.2795, -0.0898, -0.5415, -0.0045,\n",
            "         -0.4957,  0.0788,  0.2914,  0.1424,  0.5726, -0.1936,  0.4275,  0.4349,\n",
            "          0.3740, -0.3360,  0.0029,  0.3321,  0.0548,  0.0115,  0.3486, -0.0647]]), 'edge_index': tensor([[0, 2, 2, 2, 2, 2, 2],\n",
            "        [2, 2, 2, 2, 2, 2, 2]]), 'edge_type': tensor([1, 1, 1, 0, 1, 0, 1]), 'y': tensor([[0., 0., 1.]]), 'num_nodes': 6, 'batch': tensor([0, 0, 0, 0, 0, 0]), 'ptr': tensor([0, 6])}}\n",
            "tensor([[ 0.1456, -0.3664, -0.1389, -0.3097, -0.2541, -0.4008,  0.4145,  0.3043,\n",
            "          0.3654,  0.0013,  0.2876, -0.4718, -0.4152,  0.4094,  0.2399, -0.4900,\n",
            "         -0.4600,  0.4566, -0.4910,  0.2632,  0.3687, -0.2352, -0.1895, -0.0964,\n",
            "         -0.0120,  0.4097, -0.0477, -0.2001, -0.3826,  0.5298,  0.5086,  0.1128,\n",
            "         -0.5435, -0.1753, -0.3084,  0.4191, -0.1288, -0.2903,  0.3143, -0.5139,\n",
            "         -0.1392, -0.4412, -0.3825, -0.4452,  0.4280, -0.1966, -0.3084,  0.1565,\n",
            "         -0.0757,  0.3106, -0.2919, -0.0538,  0.4041,  0.2458,  0.2066, -0.0800,\n",
            "         -0.3679,  0.2820,  0.0248, -0.4164, -0.0609,  0.1966, -0.3539,  0.5427],\n",
            "        [-0.2540, -0.4848,  0.0433,  0.1408,  0.2253,  0.0394,  0.3577, -0.1115,\n",
            "         -0.0129,  0.3216,  0.0769, -0.2294, -0.1812, -0.3127,  0.1179,  0.0714,\n",
            "          0.1572,  0.3949, -0.2610,  0.2634,  0.1940, -0.3969,  0.2122, -0.4521,\n",
            "          0.4091, -0.3378, -0.3415,  0.4216,  0.2251,  0.4155, -0.5380, -0.0750,\n",
            "          0.1296, -0.2907, -0.1060, -0.2580,  0.6248,  0.0448,  0.4242,  0.2426,\n",
            "          0.5679, -0.4362,  0.0228, -0.1314, -0.4253, -0.2159, -0.3535, -0.3309,\n",
            "         -0.1562,  0.2688,  0.2007,  0.0307,  0.2456, -0.1981, -0.5506, -0.0749,\n",
            "          0.3574, -0.0827, -0.2388,  0.3051, -0.2469,  0.0606,  0.1583,  0.4083],\n",
            "        [ 0.0798, -0.4743,  0.0072,  0.5535,  0.3759, -0.5134,  0.3284,  0.5694,\n",
            "         -0.2030,  0.0979,  0.0661,  0.1967, -0.3703,  0.1588,  0.1666,  0.2465,\n",
            "          0.1714,  0.0129, -0.1525, -0.1290,  0.5388, -0.4020, -0.4172, -0.0120,\n",
            "         -0.3621, -0.1616, -0.2046,  0.3707,  0.2743, -0.3517,  0.0919,  0.0649,\n",
            "          0.0766, -0.2709,  0.0546,  0.2740,  0.5040, -0.2771,  0.3195, -0.4502,\n",
            "          0.3233,  0.4823,  0.2367,  0.3987,  0.4334,  0.2193, -0.2057, -0.1434,\n",
            "         -0.3436, -0.0010, -0.0560, -0.3180, -0.1817,  0.4792, -0.3680, -0.3506,\n",
            "          0.3278,  0.1772, -0.4804, -0.1774, -0.2564,  0.2704,  0.3528,  0.1487],\n",
            "        [-0.1042,  0.2380, -0.2351, -0.2912, -0.4517,  0.2344,  0.5195,  0.0465,\n",
            "          0.3876,  0.0863,  0.3760,  0.2096, -0.3923,  0.2774, -0.3302,  0.1202,\n",
            "         -0.2038,  0.4427, -0.3352, -0.1830, -0.5139, -0.5946,  0.4701,  0.5739,\n",
            "          0.2991, -0.1301,  0.2645, -0.1230, -0.2572,  0.4364, -0.3554,  0.3683,\n",
            "         -0.3094,  0.2691,  0.4048,  0.2822,  0.3080, -0.0745,  0.2332, -0.3628,\n",
            "          0.0845,  0.2454,  0.3087, -0.1068, -0.1758, -0.3928, -0.2783, -0.0120,\n",
            "         -0.0695, -0.3481,  0.2734,  0.0712, -0.2566, -0.0995, -0.1655,  0.0804,\n",
            "          0.1426,  0.1286, -0.1513,  0.1519,  0.2518, -0.3281,  0.3926,  0.5226],\n",
            "        [ 0.1215,  0.3101, -0.3400, -0.3717, -0.3394,  0.1297, -0.2103, -0.1353,\n",
            "          0.3776, -0.4941,  0.0127,  0.4460, -0.3592,  0.1652, -0.3444, -0.4618,\n",
            "         -0.1996,  0.4278, -0.1122,  0.3162,  0.3464,  0.3283, -0.1067, -0.0104,\n",
            "         -0.4752, -0.2596, -0.0153, -0.5171,  0.1020,  0.3398,  0.4807,  0.3186,\n",
            "         -0.1796, -0.1551,  0.3314,  0.0893,  0.0807,  0.4602, -0.0286,  0.2299,\n",
            "         -0.3378, -0.3217,  0.3143, -0.0349, -0.3611, -0.3241, -0.1161, -0.1877,\n",
            "         -0.0712, -0.4360,  0.1122,  0.1475,  0.0908,  0.1523, -0.3786,  0.4372,\n",
            "         -0.3874,  0.1202, -0.2671,  0.5074,  0.0129,  0.2074, -0.2325, -0.1762],\n",
            "        [ 0.4220,  0.3193, -0.2840,  0.3442,  0.4867,  0.3804, -0.0889, -0.1319,\n",
            "          0.0372,  0.3851, -0.5174, -0.0414,  0.4121, -0.3185, -0.0162,  0.0289,\n",
            "          0.2957, -0.2154,  0.4137, -0.3451,  0.2257,  0.4191, -0.5888,  0.2570,\n",
            "          0.0735, -0.5749, -0.2515, -0.2372,  0.3386,  0.1174, -0.4139, -0.3836,\n",
            "          0.0636,  0.3020,  0.0880, -0.1180,  0.3031, -0.2657,  0.2716, -0.4047,\n",
            "         -0.0013,  0.1660, -0.2466, -0.4178, -0.2795, -0.0898, -0.5415, -0.0045,\n",
            "         -0.4957,  0.0788,  0.2914,  0.1424,  0.5726, -0.1936,  0.4275,  0.4349,\n",
            "          0.3740, -0.3360,  0.0029,  0.3321,  0.0548,  0.0115,  0.3486, -0.0647]])\n",
            "tensor([[0, 2, 2, 2, 2, 2, 2],\n",
            "        [2, 2, 2, 2, 2, 2, 2]])\n",
            "tensor([1, 1, 1, 0, 1, 0, 1])\n",
            "tensor([0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "id": "-qUJ0xqT-_GR"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data._store.x, data.edge_index, data.edge_type, data.batch)\n",
        "    loss = criterion(out, data.y)  # Compute the loss.\n",
        "    loss.backward()  # Derive gradients.\n",
        "    optimizer.step()  # Update parameters based on gradients.\n",
        "    print(loss)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "id": "A5pOiEcmK6Gi"
      },
      "outputs": [],
      "source": [
        "# batch = Batch().from_data_list(data_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "id": "oauk_11BdM47"
      },
      "outputs": [],
      "source": [
        "# vars(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "id": "iWvdgbatdSt0"
      },
      "outputs": [],
      "source": [
        "# len(batch._edge_store_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "id": "dkgbMOhe7hIA"
      },
      "outputs": [],
      "source": [
        "# from torch_geometric.loader import DataLoader\n",
        "\n",
        "# train_loader = DataLoader(batch, batch_size=1, shuffle=True)\n",
        "# test_loader = DataLoader(batch, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "sTiqqKeXCCZY"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test(loader):\n",
        "     model.eval()\n",
        "\n",
        "     correct = 0\n",
        "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
        "         out = model(data.x, data.edge_index, data.edge_type,data.batch)  \n",
        "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "         correct += int((pred == data.y.argmax(dim=1)).sum())  # Check against ground-truth labels.\n",
        "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "id": "6YMw5ibPp78L"
      },
      "outputs": [],
      "source": [
        "# model = RGAT(data.num_features, 16, data.num_classes, data.num_relations)\n",
        "# print(model)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0005)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {
        "id": "Wq9dJT97cgUj"
      },
      "outputs": [],
      "source": [
        "# data = process0(x=x,y=y,edge_indices=edge_indices, edge_type=edge_type, edge_index1=edge_indices1, edge_index0=edge_indices0)\n",
        "# data = process1(x=x,y=y,edge_index=edge_index, edge_type=edge_type)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teBWZbxu4RcE",
        "outputId": "af86e2c4-0dc4-4310-e17b-0cd5d82d8d8a"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1387, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1387, grad_fn=<DivBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvNex0aWCDhG",
        "outputId": "0f33c8aa-1ac0-455a-b1e4-0034116c8196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.5359, grad_fn=<DivBackward1>)\n",
            "Epoch: 001, Train Acc: 1.0000, Test Acc: 1.0000\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, 2):\n",
        "    train()\n",
        "    train_acc = test(loader2)\n",
        "    test_acc = test(loader2)\n",
        "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "PDG Final",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}