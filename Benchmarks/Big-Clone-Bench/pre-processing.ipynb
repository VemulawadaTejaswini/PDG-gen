{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Jsonl to Java files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9126 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9126/9126 [00:02<00:00, 3875.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tqdm\n",
    "import pyparsing\n",
    "\n",
    "def process_the_code_and_save(code, id, output_folder_location):\n",
    "    \n",
    "    # Remove all comments\n",
    "    commentFilter = pyparsing.javaStyleComment.suppress()\n",
    "    #code = commentFilter.transformString(code)\n",
    "    \n",
    "    output_file = open(output_folder_location + \"/\" + id + \".java\", \"+w\")\n",
    "    code_lines = code.split(\"\\n\")\n",
    "    output_file.write(\"public class dummy {\\n\")\n",
    "    \n",
    "    for line in code_lines:\n",
    "        line = line.replace('\\u00A0', \" \")\n",
    "        \n",
    "        # Skip empty lines, lines like @Test\n",
    "        if len(line.strip()) == 0 or line.strip().startswith(\"@\"):\n",
    "            continue\n",
    "        \n",
    "        # Add newline at the end\n",
    "        if not line.endswith(\"\\n\"):\n",
    "            line += \"\\n\"\n",
    "        output_file.write(line)\n",
    "    \n",
    "    output_file.write(\"}\\n\")\n",
    "    output_file.close()\n",
    "\n",
    "OUTPUT_FOLDER_LOCATION = \"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Benchmarks/Big-Clone-Bench/java_files\"\n",
    "\n",
    "with open('/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Benchmarks/Big-Clone-Bench/raw_dataset/data.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "\n",
    "for json_str in tqdm.tqdm(json_list):\n",
    "    result = json.loads(json_str)\n",
    "    process_the_code_and_save(result[\"func\"], result[\"idx\"], OUTPUT_FOLDER_LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean PDG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import tqdm\n",
    "\n",
    "\"\"\" ALGORITHM\n",
    "\n",
    "a. Clean the raw edge info (eg. remove wrongly formatted edges, class edges etc.)\n",
    "b. Merge same code-lines into a single line/node\n",
    "c. Consider all nodes that are reachable from the API node\n",
    "d. Consider all nodes from which API node is reachable\n",
    "e. Add the all the edges(CD/FD) in the current subgraph\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "PRUNING_ERROR_COUNT, GOOD_DATA_POINTS, TOTAL_DATA_POINTS = 0, 0, 0\n",
    "PRUNING_ERROR_COUNT_IN_DATASET, GOOD_DATA_POINTS_IN_DATASET, TOTAL_DATA_POINTS_IN_DATASET = 0, 0, 0\n",
    "DATASET_STATISTICS = {}\n",
    "\n",
    "def get_pruned_pdg(pdg_file, output_pdg_file):\n",
    "    \n",
    "    global PRUNING_ERROR_COUNT, GOOD_DATA_POINTS, TOTAL_DATA_POINTS\n",
    "    \n",
    "    # all_edges = [bytes(l, 'utf-8').decode('utf-8', 'ignore').strip()\n",
    "    #              for l in pdg_file.readlines()]\n",
    "    all_edges = [l.replace(\"\\n\", \"\").replace(\"\\r\", \"\").strip()\n",
    "                 for l in pdg_file.readlines()]\n",
    "\n",
    "    # Remove unnecesssary edges(\"class\" edge, wrongly formatted edges etc.)\n",
    "    all_edges = [edge for edge in all_edges if edge.find(\n",
    "        \"-->\") != -1 and edge.count(\"$$\") == 2]\n",
    "    all_edges = [edge for edge in all_edges if len(edge.split(\"-->\")) == 2 and\n",
    "                 len(edge.split(\"-->\")[0].split(\"$$\")) == 2 and\n",
    "                 len(edge.split(\"-->\")[1].split(\"$$\")) == 2]\n",
    "    all_edges = [edge for edge in all_edges if edge.split(\"-->\")[0].find(\"Entry\") == -1 and\n",
    "                 edge.split(\"-->\")[0].find(\"class\") == -1]\n",
    "    #print(\"ALL EDGES : \\n\")\n",
    "    #print(all_edges, \"\\n\")\n",
    "\n",
    "    # Merge nodes referring to same code-line\n",
    "    line_mapping, edge_mapping = {}, {}\n",
    "    for edge in all_edges:\n",
    "        node_1, node_2 = edge[:edge.rindex(\"[\")].strip().split(\"-->\")\n",
    "        edge_type = edge[edge.rindex(\"[\") + 1: -1].strip()\n",
    "        line_numbers = []\n",
    "        for node in [node_1, node_2]:\n",
    "            line_number, line_code = node.strip().split(\"$$\")\n",
    "            line_number, line_code = line_number.strip(), line_code.strip()\n",
    "            line_numbers.append(line_number)\n",
    "            if line_number in line_mapping:\n",
    "                if line_mapping[line_number] != line_code:\n",
    "                    line_mapping[line_number] = line_code if len(line_code) > len(\n",
    "                        line_mapping[line_number]) else line_mapping[line_number]\n",
    "            else:\n",
    "                line_mapping[line_number] = line_code\n",
    "        if tuple(line_numbers) in edge_mapping:\n",
    "            edge_mapping[tuple(line_numbers)] = list(set(edge_mapping[tuple(line_numbers)] + [edge_type]))\n",
    "        else:\n",
    "            edge_mapping[tuple(line_numbers)] = [edge_type]\n",
    "\n",
    "    # Remove self-loops from subgraph\n",
    "    edges_temp = {}\n",
    "    for edge in edge_mapping:\n",
    "        if edge[0] != edge[1]:\n",
    "            edges_temp[edge] = edge_mapping[edge]\n",
    "    edge_mapping = edges_temp\n",
    "    #print(\"AFTER REMOVING SELF-LOOPS : \\n\")\n",
    "    #print(sub_graph_edges, \"\\n\")\n",
    "\n",
    "    # Save the pruned PDG\n",
    "    edge_data_list = []\n",
    "    for edge in edge_mapping:\n",
    "        for edge_type in edge_mapping[edge]:\n",
    "            edge_data = edge[0].strip() + \" $$ \" + \\\n",
    "                        line_mapping[edge[0]].strip() + \" --> \" + \\\n",
    "                        edge[1].strip() + \" $$ \" + \\\n",
    "                        line_mapping[edge[1]].strip() + \" [\" + \\\n",
    "                        edge_type.strip() + \"]\\n\"\n",
    "            edge_data_list.append(edge_data)\n",
    "    #print(\"FINAL EDGE LIST: \\n\")\n",
    "    #print(edge_data_list, \"\\n\")\n",
    "    if len(edge_data_list) >= 3:\n",
    "        GOOD_DATA_POINTS += 1\n",
    "        \n",
    "    output_pdg_file.writelines(edge_data_list)\n",
    "    if len(edge_data_list) > 0:\n",
    "        TOTAL_DATA_POINTS += 1\n",
    "\n",
    "    return output_pdg_file, len(edge_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9125/9125 [03:09<00:00, 48.04it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GOOD PDG DATA POINTS: 8809\n",
      "\n",
      "\n",
      "TOTAL PDG DATA POINTS: 8898\n",
      "\n",
      "\n",
      "TOTAL PRUNING ERROR: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "PDG_FOLDER_LOCATION = \"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Benchmarks/Big-Clone-Bench/pdg_data/NA\"\n",
    "OUTPUT_FOLDER_LOCATION = \"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Benchmarks/Big-Clone-Bench/processed_pdg_data\"\n",
    "\n",
    "pdg_files_list = glob.glob(os.path.join(PDG_FOLDER_LOCATION, '*.txt'))\n",
    "if not os.path.exists(OUTPUT_FOLDER_LOCATION):\n",
    "    os.makedirs(OUTPUT_FOLDER_LOCATION)\n",
    "    \n",
    "for pdg_file_location in tqdm.tqdm(pdg_files_list):\n",
    "    pdg_file = open(pdg_file_location, 'r')\n",
    "    output_file_location = OUTPUT_FOLDER_LOCATION + \"/\" + pdg_file_location[pdg_file_location.rindex(\"/\")+1:]\n",
    "    output_pdg_file = open(output_file_location, \"+w\")\n",
    "    try:\n",
    "        output_pdg_file, no_of_edges = get_pruned_pdg(pdg_file, output_pdg_file)\n",
    "    except Exception as e:\n",
    "        PRUNING_ERROR_COUNT += 1\n",
    "        print(\"\\nERROR WHILE PRUNING PDG\\n\")\n",
    "        print(\"\\nFile: {}\\n\".format(pdg_file_location))\n",
    "        print(\"\\nERROR: {}\\n\".format(e))\n",
    "        pdg_file.close()\n",
    "        output_pdg_file.close()\n",
    "        os.remove(output_file_location)\n",
    "    else:\n",
    "        output_pdg_file.close()\n",
    "        if no_of_edges == 0:\n",
    "            os.remove(output_file_location)\n",
    "        pdg_file.close()\n",
    "\n",
    "print(\"\\nGOOD PDG DATA POINTS: {}\\n\".format(GOOD_DATA_POINTS))\n",
    "print(\"\\nTOTAL PDG DATA POINTS: {}\\n\".format(TOTAL_DATA_POINTS))\n",
    "print(\"\\nTOTAL PRUNING ERROR: {}\\n\".format(PRUNING_ERROR_COUNT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MuGNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
