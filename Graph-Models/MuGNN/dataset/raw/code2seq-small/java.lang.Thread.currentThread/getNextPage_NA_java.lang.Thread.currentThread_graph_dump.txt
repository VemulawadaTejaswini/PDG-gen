Line_8 $$ if (closed || batchSize <= 0) -->Line_10 $$ return null[ CD ]
Line_15 $$ if (constantBlocks[fieldId] != null) -->Line_19 $$ blocks[fieldId] = new LazyBlock(batchSize, new ParquetBlockLoader(columnDescriptor, batchSize, type))[ CD ]
Line_6 $$ int batchSize = parquetReader.nextBatch()-->Line_16 $$ blocks[fieldId] = constantBlocks[fieldId].getRegion(0, batchSize)[ FD ]
Line_13 $$ for (int fieldId = 0; fieldId < blocks.length; fieldId++) -->Line_18 $$ ColumnDescriptor columnDescriptor = this.requestedSchema.getColumns().get(fieldId)[ FD ]
Line_15 $$ if (constantBlocks[fieldId] != null) -->Line_16 $$ blocks[fieldId] = constantBlocks[fieldId].getRegion(0, batchSize)[ CD ]
Line_30 $$ if (e instanceof InterruptedException) -->Line_31 $$ Thread.currentThread().interrupt()[ CD ]
Line_8 $$ if (closed || batchSize <= 0) -->Line_9 $$ close()[ CD ]
Line_13 $$ for (int fieldId = 0; fieldId < blocks.length; fieldId++) -->Line_15 $$ if (constantBlocks[fieldId] != null) [ CD ]
Line_13 $$ for (int fieldId = 0; fieldId < blocks.length; fieldId++) -->Line_14 $$ Type type = types.get(fieldId)[ CD ]
Line_15 $$ if (constantBlocks[fieldId] != null) -->Line_18 $$ ColumnDescriptor columnDescriptor = this.requestedSchema.getColumns().get(fieldId)[ CD ]
Line_13 $$ for (int fieldId = 0; fieldId < blocks.length; fieldId++) -->Line_14 $$ Type type = types.get(fieldId)[ FD ]
Line_23 $$ long newCompletedBytes = (long) (totalBytes * parquetReader.getProgress())-->Line_24 $$ completedBytes = min(totalBytes, max(completedBytes, newCompletedBytes))[ FD ]
