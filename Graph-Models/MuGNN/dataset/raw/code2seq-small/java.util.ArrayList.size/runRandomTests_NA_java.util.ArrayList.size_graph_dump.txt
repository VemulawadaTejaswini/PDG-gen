Line_65 $$ String valueString = new String(value.getBytes(), 0, value.getLength())-->Line_69 $$ assertEquals("Checking record content:", origRecord, valueString)[ FD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_16 $$ LOG.info("----------------------------------------------------------")[ CD ]
Line_49 $$ FixedLengthInputFormat format = new FixedLengthInputFormat()-->Line_50 $$ List<InputSplit> splits = format.getSplits(job)[ FD ]
Line_49 $$ FixedLengthInputFormat format = new FixedLengthInputFormat()-->Line_56 $$ RecordReader<LongWritable, BytesWritable> reader = format.createRecordReader(split, context)[ FD ]
Line_2 $$ private void runRandomTests(CompressionCodec codec) throws Exception -->Line_7 $$ localFs.delete(workDir, true)[ CD ]
Line_68 $$ String origRecord = recordList.get(recordNumber)-->Line_69 $$ assertEquals("Checking record content:", origRecord, valueString)[ FD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_18 $$ if (i == 8) [ CD ]
Line_56 $$ RecordReader<LongWritable, BytesWritable> reader = format.createRecordReader(split, context)-->Line_62 $$ key = reader.getCurrentKey()[ FD ]
Line_23 $$ recordLength = 1-->Line_33 $$ FixedLengthInputFormat.setRecordLength(job.getConfiguration(), recordLength)[ FD ]
Line_61 $$ while (reader.nextKeyValue()) -->Line_65 $$ String valueString = new String(value.getBytes(), 0, value.getLength())[ CD ]
Line_61 $$ while (reader.nextKeyValue()) -->Line_68 $$ String origRecord = recordList.get(recordNumber)[ CD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_21 $$ int recordLength = random.nextInt(1024 * 100) + 1[ CD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_36 $$ if (i == (MAX_TESTS - 1)) [ FD ]
Line_11 $$ Random random = new Random(seed)-->Line_17 $$ int totalRecords = random.nextInt(999) + 1[ FD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_50 $$ List<InputSplit> splits = format.getSplits(job)[ CD ]
Line_27 $$ Job job = Job.getInstance(defaultConf)-->Line_55 $$ TaskAttemptContext context = MapReduceTestUtil.createDummyMapTaskAttemptContext(job.getConfiguration())[ FD ]
Line_57 $$ MapContext<LongWritable, BytesWritable, LongWritable, BytesWritable> mcontext = new MapContextImpl<LongWritable, BytesWritable, LongWritable, BytesWritable>(job.getConfiguration(), context.getTaskAttemptID(), reader, null, null, MapReduceTestUtil.createDummyReporter(), split)-->Line_58 $$ reader.initialize(split, mcontext)[ FD ]
Line_56 $$ RecordReader<LongWritable, BytesWritable> reader = format.createRecordReader(split, context)-->Line_59 $$ Class<?> clazz = reader.getClass()[ FD ]
Line_13 $$ LongWritable key-->Line_62 $$ key = reader.getCurrentKey()[ FD ]
Line_35 $$ if (i > 0) -->Line_45 $$ LOG.info("Number of splits set to: " + numSplits)[ CD ]
Line_35 $$ if (i > 0) -->Line_36 $$ if (i == (MAX_TESTS - 1)) [ CD ]
Line_53 $$ int recordNumber = 0-->Line_70 $$ recordNumber++[ FD ]
Line_2 $$ private void runRandomTests(CompressionCodec codec) throws Exception -->Line_10 $$ LOG.info("Seed = " + seed)[ CD ]
Line_13 $$ LongWritable key-->Line_64 $$ assertEquals("Checking key", (long) (recordNumber * recordLength), key.get())[ FD ]
Line_2 $$ private void runRandomTests(CompressionCodec codec) throws Exception -->Line_13 $$ LongWritable key[ CD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_49 $$ FixedLengthInputFormat format = new FixedLengthInputFormat()[ CD ]
Line_11 $$ Random random = new Random(seed)-->Line_40 $$ numSplits = fileSize / (fileSize - random.nextInt(fileSize))[ FD ]
Line_21 $$ int recordLength = random.nextInt(1024 * 100) + 1-->Line_31 $$ ArrayList<String> recordList = createFile(file, codec, recordLength, totalRecords)[ FD ]
Line_31 $$ ArrayList<String> recordList = createFile(file, codec, recordLength, totalRecords)-->Line_74 $$ assertEquals("Total original records should be total read records:", recordList.size(), recordNumber)[ FD ]
Line_27 $$ Job job = Job.getInstance(defaultConf)-->Line_48 $$ FileInputFormat.setInputPaths(job, workDir)[ FD ]
Line_8 $$ Path file = new Path(workDir, fileName.toString())-->Line_32 $$ assertTrue(localFs.exists(file))[ FD ]
Line_14 $$ BytesWritable value-->Line_65 $$ String valueString = new String(value.getBytes(), 0, value.getLength())[ FD ]
Line_2 $$ private void runRandomTests(CompressionCodec codec) throws Exception -->Line_14 $$ BytesWritable value[ CD ]
Line_2 $$ private void runRandomTests(CompressionCodec codec) throws Exception -->Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) [ CD ]
Line_56 $$ RecordReader<LongWritable, BytesWritable> reader = format.createRecordReader(split, context)-->Line_63 $$ value = reader.getCurrentValue()[ FD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_51 $$ LOG.info("Actual number of splits = " + splits.size())[ CD ]
Line_3 $$ StringBuilder fileName = new StringBuilder("testFormat.txt")-->Line_8 $$ Path file = new Path(workDir, fileName.toString())[ FD ]
Line_2 $$ private void runRandomTests(CompressionCodec codec) throws Exception -->Line_12 $$ int MAX_TESTS = 20[ CD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_25 $$ int fileSize = (totalRecords * recordLength)[ CD ]
Line_34 $$ int numSplits = 1-->Line_42 $$ numSplits = Math.max(1, fileSize / random.nextInt(Integer.MAX_VALUE))[ FD ]
Line_3 $$ StringBuilder fileName = new StringBuilder("testFormat.txt")-->Line_5 $$ fileName.append(".gz")[ FD ]
Line_56 $$ RecordReader<LongWritable, BytesWritable> reader = format.createRecordReader(split, context)-->Line_61 $$ while (reader.nextKeyValue()) [ FD ]
Line_2 $$ private void runRandomTests(CompressionCodec codec) throws Exception -->Line_31 $$ ArrayList<String> recordList = createFile(file, codec, recordLength, totalRecords)[ FD ]
Line_21 $$ int recordLength = random.nextInt(1024 * 100) + 1-->Line_66 $$ assertEquals("Checking record length:", recordLength, value.getLength())[ FD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_52 $$ long recordOffset = 0[ CD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_28 $$ if (codec != null) [ CD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_74 $$ assertEquals("Total original records should be total read records:", recordList.size(), recordNumber)[ CD ]
Line_17 $$ int totalRecords = random.nextInt(999) + 1-->Line_31 $$ ArrayList<String> recordList = createFile(file, codec, recordLength, totalRecords)[ FD ]
Line_62 $$ key = reader.getCurrentKey()-->Line_64 $$ assertEquals("Checking key", (long) (recordNumber * recordLength), key.get())[ FD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_22 $$ if (i == 10) [ FD ]
Line_63 $$ value = reader.getCurrentValue()-->Line_66 $$ assertEquals("Checking record length:", recordLength, value.getLength())[ FD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_32 $$ assertTrue(localFs.exists(file))[ CD ]
Line_2 $$ private void runRandomTests(CompressionCodec codec) throws Exception -->Line_9 $$ int seed = new Random().nextInt()[ CD ]
Line_59 $$ Class<?> clazz = reader.getClass()-->Line_60 $$ assertEquals("RecordReader class should be FixedLengthRecordReader:", FixedLengthRecordReader.class, clazz)[ FD ]
Line_53 $$ int recordNumber = 0-->Line_74 $$ assertEquals("Total original records should be total read records:", recordList.size(), recordNumber)[ FD ]
Line_34 $$ int numSplits = 1-->Line_40 $$ numSplits = fileSize / (fileSize - random.nextInt(fileSize))[ FD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_53 $$ int recordNumber = 0[ CD ]
Line_23 $$ recordLength = 1-->Line_66 $$ assertEquals("Checking record length:", recordLength, value.getLength())[ FD ]
Line_37 $$ numSplits = (int) (fileSize / Math.floor(recordLength / 2))-->Line_40 $$ numSplits = fileSize / (fileSize - random.nextInt(fileSize))[ FD ]
Line_22 $$ if (i == 10) -->Line_23 $$ recordLength = 1[ CD ]
Line_61 $$ while (reader.nextKeyValue()) -->Line_70 $$ recordNumber++[ CD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_47 $$ job.getConfiguration().setLong("mapreduce.input.fileinputformat.split.maxsize", (long) (fileSize / numSplits))[ CD ]
Line_61 $$ while (reader.nextKeyValue()) -->Line_67 $$ assertTrue("Checking for more records than expected:", recordNumber < totalRecords)[ CD ]
Line_2 $$ private void runRandomTests(CompressionCodec codec) throws Exception -->Line_3 $$ StringBuilder fileName = new StringBuilder("testFormat.txt")[ CD ]
Line_23 $$ recordLength = 1-->Line_31 $$ ArrayList<String> recordList = createFile(file, codec, recordLength, totalRecords)[ FD ]
Line_34 $$ int numSplits = 1-->Line_37 $$ numSplits = (int) (fileSize / Math.floor(recordLength / 2))[ FD ]
Line_25 $$ int fileSize = (totalRecords * recordLength)-->Line_40 $$ numSplits = fileSize / (fileSize - random.nextInt(fileSize))[ FD ]
Line_14 $$ BytesWritable value-->Line_66 $$ assertEquals("Checking record length:", recordLength, value.getLength())[ FD ]
Line_2 $$ private void runRandomTests(CompressionCodec codec) throws Exception -->Line_29 $$ ReflectionUtils.setConf(codec, job.getConfiguration())[ FD ]
Line_55 $$ TaskAttemptContext context = MapReduceTestUtil.createDummyMapTaskAttemptContext(job.getConfiguration())-->Line_57 $$ MapContext<LongWritable, BytesWritable, LongWritable, BytesWritable> mcontext = new MapContextImpl<LongWritable, BytesWritable, LongWritable, BytesWritable>(job.getConfiguration(), context.getTaskAttemptID(), reader, null, null, MapReduceTestUtil.createDummyReporter(), split)[ FD ]
Line_11 $$ Random random = new Random(seed)-->Line_21 $$ int recordLength = random.nextInt(1024 * 100) + 1[ FD ]
Line_53 $$ int recordNumber = 0-->Line_68 $$ String origRecord = recordList.get(recordNumber)[ FD ]
Line_61 $$ while (reader.nextKeyValue()) -->Line_63 $$ value = reader.getCurrentValue()[ CD ]
Line_54 $$ for (InputSplit split : splits) -->Line_56 $$ RecordReader<LongWritable, BytesWritable> reader = format.createRecordReader(split, context)[ FD ]
Line_27 $$ Job job = Job.getInstance(defaultConf)-->Line_47 $$ job.getConfiguration().setLong("mapreduce.input.fileinputformat.split.maxsize", (long) (fileSize / numSplits))[ FD ]
Line_12 $$ int MAX_TESTS = 20-->Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) [ FD ]
Line_2 $$ private void runRandomTests(CompressionCodec codec) throws Exception -->Line_4 $$ if (codec != null) [ CD ]
Line_18 $$ if (i == 8) -->Line_19 $$ totalRecords = 0[ CD ]
Line_21 $$ int recordLength = random.nextInt(1024 * 100) + 1-->Line_23 $$ recordLength = 1[ FD ]
Line_37 $$ numSplits = (int) (fileSize / Math.floor(recordLength / 2))-->Line_42 $$ numSplits = Math.max(1, fileSize / random.nextInt(Integer.MAX_VALUE))[ FD ]
Line_36 $$ if (i == (MAX_TESTS - 1)) -->Line_37 $$ numSplits = (int) (fileSize / Math.floor(recordLength / 2))[ CD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_34 $$ int numSplits = 1[ CD ]
Line_61 $$ while (reader.nextKeyValue()) -->Line_69 $$ assertEquals("Checking record content:", origRecord, valueString)[ CD ]
Line_11 $$ Random random = new Random(seed)-->Line_42 $$ numSplits = Math.max(1, fileSize / random.nextInt(Integer.MAX_VALUE))[ FD ]
Line_55 $$ TaskAttemptContext context = MapReduceTestUtil.createDummyMapTaskAttemptContext(job.getConfiguration())-->Line_56 $$ RecordReader<LongWritable, BytesWritable> reader = format.createRecordReader(split, context)[ FD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_18 $$ if (i == 8) [ FD ]
Line_39 $$ if (MAX_TESTS % i == 0) -->Line_42 $$ numSplits = Math.max(1, fileSize / random.nextInt(Integer.MAX_VALUE))[ CD ]
Line_40 $$ numSplits = fileSize / (fileSize - random.nextInt(fileSize))-->Line_42 $$ numSplits = Math.max(1, fileSize / random.nextInt(Integer.MAX_VALUE))[ FD ]
Line_4 $$ if (codec != null) -->Line_5 $$ fileName.append(".gz")[ CD ]
Line_2 $$ private void runRandomTests(CompressionCodec codec) throws Exception -->Line_8 $$ Path file = new Path(workDir, fileName.toString())[ CD ]
Line_2 $$ private void runRandomTests(CompressionCodec codec) throws Exception -->Line_28 $$ if (codec != null) [ FD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_33 $$ FixedLengthInputFormat.setRecordLength(job.getConfiguration(), recordLength)[ CD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_31 $$ ArrayList<String> recordList = createFile(file, codec, recordLength, totalRecords)[ CD ]
Line_36 $$ if (i == (MAX_TESTS - 1)) -->Line_39 $$ if (MAX_TESTS % i == 0) [ CD ]
Line_14 $$ BytesWritable value-->Line_63 $$ value = reader.getCurrentValue()[ FD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_27 $$ Job job = Job.getInstance(defaultConf)[ CD ]
Line_31 $$ ArrayList<String> recordList = createFile(file, codec, recordLength, totalRecords)-->Line_68 $$ String origRecord = recordList.get(recordNumber)[ FD ]
Line_27 $$ Job job = Job.getInstance(defaultConf)-->Line_57 $$ MapContext<LongWritable, BytesWritable, LongWritable, BytesWritable> mcontext = new MapContextImpl<LongWritable, BytesWritable, LongWritable, BytesWritable>(job.getConfiguration(), context.getTaskAttemptID(), reader, null, null, MapReduceTestUtil.createDummyReporter(), split)[ FD ]
Line_61 $$ while (reader.nextKeyValue()) -->Line_66 $$ assertEquals("Checking record length:", recordLength, value.getLength())[ CD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_35 $$ if (i > 0) [ CD ]
Line_54 $$ for (InputSplit split : splits) -->Line_58 $$ reader.initialize(split, mcontext)[ FD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_22 $$ if (i == 10) [ CD ]
Line_39 $$ if (MAX_TESTS % i == 0) -->Line_40 $$ numSplits = fileSize / (fileSize - random.nextInt(fileSize))[ CD ]
Line_27 $$ Job job = Job.getInstance(defaultConf)-->Line_50 $$ List<InputSplit> splits = format.getSplits(job)[ FD ]
Line_56 $$ RecordReader<LongWritable, BytesWritable> reader = format.createRecordReader(split, context)-->Line_58 $$ reader.initialize(split, mcontext)[ FD ]
Line_61 $$ while (reader.nextKeyValue()) -->Line_64 $$ assertEquals("Checking key", (long) (recordNumber * recordLength), key.get())[ CD ]
Line_8 $$ Path file = new Path(workDir, fileName.toString())-->Line_31 $$ ArrayList<String> recordList = createFile(file, codec, recordLength, totalRecords)[ FD ]
Line_63 $$ value = reader.getCurrentValue()-->Line_65 $$ String valueString = new String(value.getBytes(), 0, value.getLength())[ FD ]
Line_2 $$ private void runRandomTests(CompressionCodec codec) throws Exception -->Line_4 $$ if (codec != null) [ FD ]
Line_56 $$ RecordReader<LongWritable, BytesWritable> reader = format.createRecordReader(split, context)-->Line_72 $$ reader.close()[ FD ]
Line_2 $$ private void runRandomTests(CompressionCodec codec) throws Exception -->Line_11 $$ Random random = new Random(seed)[ CD ]
Line_21 $$ int recordLength = random.nextInt(1024 * 100) + 1-->Line_33 $$ FixedLengthInputFormat.setRecordLength(job.getConfiguration(), recordLength)[ FD ]
Line_27 $$ Job job = Job.getInstance(defaultConf)-->Line_29 $$ ReflectionUtils.setConf(codec, job.getConfiguration())[ FD ]
Line_28 $$ if (codec != null) -->Line_29 $$ ReflectionUtils.setConf(codec, job.getConfiguration())[ CD ]
Line_61 $$ while (reader.nextKeyValue()) -->Line_62 $$ key = reader.getCurrentKey()[ CD ]
Line_27 $$ Job job = Job.getInstance(defaultConf)-->Line_33 $$ FixedLengthInputFormat.setRecordLength(job.getConfiguration(), recordLength)[ FD ]
Line_17 $$ int totalRecords = random.nextInt(999) + 1-->Line_19 $$ totalRecords = 0[ FD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_26 $$ LOG.info("totalRecords=" + totalRecords + " recordLength=" + recordLength)[ CD ]
Line_19 $$ totalRecords = 0-->Line_31 $$ ArrayList<String> recordList = createFile(file, codec, recordLength, totalRecords)[ FD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_48 $$ FileInputFormat.setInputPaths(job, workDir)[ CD ]
Line_50 $$ List<InputSplit> splits = format.getSplits(job)-->Line_51 $$ LOG.info("Actual number of splits = " + splits.size())[ FD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_17 $$ int totalRecords = random.nextInt(999) + 1[ CD ]
Line_15 $$ for (int i = 0; i < MAX_TESTS; i++) -->Line_35 $$ if (i > 0) [ FD ]
