Line_16 $$ long chunkOffset = 0-->Line_17 $$ while (chunkOffset < blockLocation.getLength()) [ FD ]
Line_8 $$ long maxBytes = maxSplitSize.toBytes()-->Line_20 $$ maxBytes = maxSplitSize.toBytes()[ FD ]
Line_15 $$ long targetChunkSize = (long) Math.ceil(blockLocation.getLength() * 1.0 / chunks)-->Line_25 $$ long chunkLength = Math.min(targetChunkSize, blockLocation.getLength() - chunkOffset)[ FD ]
Line_9 $$ boolean creatingInitialSplits = false-->Line_18 $$ if (remainingInitialSplits.decrementAndGet() < 0 && creatingInitialSplits) [ FD ]
Line_5 $$ if (splittable) -->Line_32 $$ List<HostAddress> addresses = ImmutableList.of()[ CD ]
Line_10 $$ if (remainingInitialSplits.get() > 0) -->Line_12 $$ creatingInitialSplits = true[ CD ]
Line_7 $$ List<HostAddress> addresses = toHostAddress(blockLocation.getHosts())-->Line_34 $$ addresses = toHostAddress(blockLocations[0].getHosts())[ FD ]
Line_15 $$ long targetChunkSize = (long) Math.ceil(blockLocation.getLength() * 1.0 / chunks)-->Line_23 $$ targetChunkSize = (long) Math.ceil(remainingLength * 1.0 / chunks)[ FD ]
Line_2 $$ private List<HiveSplit> createHiveSplits(String partitionName, String path, BlockLocation[] blockLocations, long start, long length, Properties schema, List<HivePartitionKey> partitionKeys, boolean splittable, ConnectorSession session, TupleDomain<HiveColumnHandle> effectivePredicate) throws IOException -->Line_3 $$ ImmutableList.Builder<HiveSplit> builder = ImmutableList.builder()[ CD ]
Line_14 $$ int chunks = Math.max(1, (int) (blockLocation.getLength() / maxBytes))-->Line_22 $$ chunks = Math.max(1, (int) (remainingLength / maxBytes))[ FD ]
Line_2 $$ private List<HiveSplit> createHiveSplits(String partitionName, String path, BlockLocation[] blockLocations, long start, long length, Properties schema, List<HivePartitionKey> partitionKeys, boolean splittable, ConnectorSession session, TupleDomain<HiveColumnHandle> effectivePredicate) throws IOException -->Line_4 $$ boolean forceLocalScheduling = HiveSessionProperties.isForceLocalScheduling(session)[ CD ]
Line_6 $$ for (BlockLocation blockLocation : blockLocations) -->Line_7 $$ List<HostAddress> addresses = toHostAddress(blockLocation.getHosts())[ FD ]
Line_17 $$ while (chunkOffset < blockLocation.getLength()) -->Line_27 $$ chunkOffset += chunkLength[ CD ]
Line_6 $$ for (BlockLocation blockLocation : blockLocations) -->Line_21 $$ long remainingLength = blockLocation.getLength() - chunkOffset[ FD ]
Line_16 $$ long chunkOffset = 0-->Line_27 $$ chunkOffset += chunkLength[ FD ]
Line_18 $$ if (remainingInitialSplits.decrementAndGet() < 0 && creatingInitialSplits) -->Line_23 $$ targetChunkSize = (long) Math.ceil(remainingLength * 1.0 / chunks)[ CD ]
Line_11 $$ maxBytes = maxInitialSplitSize.toBytes()-->Line_20 $$ maxBytes = maxSplitSize.toBytes()[ FD ]
Line_3 $$ ImmutableList.Builder<HiveSplit> builder = ImmutableList.builder()-->Line_26 $$ builder.add(new HiveSplit(connectorId, table.getDbName(), table.getTableName(), partitionName, path, blockLocation.getOffset() + chunkOffset, chunkLength, schema, partitionKeys, addresses, forceLocalScheduling, effectivePredicate))[ FD ]
Line_6 $$ for (BlockLocation blockLocation : blockLocations) -->Line_25 $$ long chunkLength = Math.min(targetChunkSize, blockLocation.getLength() - chunkOffset)[ FD ]
Line_9 $$ boolean creatingInitialSplits = false-->Line_19 $$ creatingInitialSplits = false[ FD ]
Line_3 $$ ImmutableList.Builder<HiveSplit> builder = ImmutableList.builder()-->Line_36 $$ builder.add(new HiveSplit(connectorId, table.getDbName(), table.getTableName(), partitionName, path, start, length, schema, partitionKeys, addresses, forceLocalScheduling, effectivePredicate))[ FD ]
Line_27 $$ chunkOffset += chunkLength-->Line_17 $$ while (chunkOffset < blockLocation.getLength()) [ FD ]
Line_2 $$ private List<HiveSplit> createHiveSplits(String partitionName, String path, BlockLocation[] blockLocations, long start, long length, Properties schema, List<HivePartitionKey> partitionKeys, boolean splittable, ConnectorSession session, TupleDomain<HiveColumnHandle> effectivePredicate) throws IOException -->Line_38 $$ return builder.build()[ CD ]
Line_18 $$ if (remainingInitialSplits.decrementAndGet() < 0 && creatingInitialSplits) -->Line_19 $$ creatingInitialSplits = false[ CD ]
Line_9 $$ boolean creatingInitialSplits = false-->Line_12 $$ creatingInitialSplits = true[ FD ]
Line_8 $$ long maxBytes = maxSplitSize.toBytes()-->Line_11 $$ maxBytes = maxInitialSplitSize.toBytes()[ FD ]
Line_6 $$ for (BlockLocation blockLocation : blockLocations) -->Line_17 $$ while (chunkOffset < blockLocation.getLength()) [ FD ]
Line_6 $$ for (BlockLocation blockLocation : blockLocations) -->Line_15 $$ long targetChunkSize = (long) Math.ceil(blockLocation.getLength() * 1.0 / chunks)[ FD ]
Line_18 $$ if (remainingInitialSplits.decrementAndGet() < 0 && creatingInitialSplits) -->Line_20 $$ maxBytes = maxSplitSize.toBytes()[ CD ]
Line_12 $$ creatingInitialSplits = true-->Line_19 $$ creatingInitialSplits = false[ FD ]
Line_6 $$ for (BlockLocation blockLocation : blockLocations) -->Line_29 $$ checkState(chunkOffset == blockLocation.getLength(), "Error splitting blocks")[ FD ]
Line_17 $$ while (chunkOffset < blockLocation.getLength()) -->Line_26 $$ builder.add(new HiveSplit(connectorId, table.getDbName(), table.getTableName(), partitionName, path, blockLocation.getOffset() + chunkOffset, chunkLength, schema, partitionKeys, addresses, forceLocalScheduling, effectivePredicate))[ CD ]
Line_33 $$ if (blockLocations.length > 0) -->Line_34 $$ addresses = toHostAddress(blockLocations[0].getHosts())[ CD ]
Line_3 $$ ImmutableList.Builder<HiveSplit> builder = ImmutableList.builder()-->Line_38 $$ return builder.build()[ FD ]
Line_6 $$ for (BlockLocation blockLocation : blockLocations) -->Line_26 $$ builder.add(new HiveSplit(connectorId, table.getDbName(), table.getTableName(), partitionName, path, blockLocation.getOffset() + chunkOffset, chunkLength, schema, partitionKeys, addresses, forceLocalScheduling, effectivePredicate))[ FD ]
Line_5 $$ if (splittable) -->Line_36 $$ builder.add(new HiveSplit(connectorId, table.getDbName(), table.getTableName(), partitionName, path, start, length, schema, partitionKeys, addresses, forceLocalScheduling, effectivePredicate))[ CD ]
Line_17 $$ while (chunkOffset < blockLocation.getLength()) -->Line_25 $$ long chunkLength = Math.min(targetChunkSize, blockLocation.getLength() - chunkOffset)[ CD ]
Line_5 $$ if (splittable) -->Line_33 $$ if (blockLocations.length > 0) [ CD ]
Line_2 $$ private List<HiveSplit> createHiveSplits(String partitionName, String path, BlockLocation[] blockLocations, long start, long length, Properties schema, List<HivePartitionKey> partitionKeys, boolean splittable, ConnectorSession session, TupleDomain<HiveColumnHandle> effectivePredicate) throws IOException -->Line_4 $$ boolean forceLocalScheduling = HiveSessionProperties.isForceLocalScheduling(session)[ FD ]
Line_18 $$ if (remainingInitialSplits.decrementAndGet() < 0 && creatingInitialSplits) -->Line_22 $$ chunks = Math.max(1, (int) (remainingLength / maxBytes))[ CD ]
Line_10 $$ if (remainingInitialSplits.get() > 0) -->Line_11 $$ maxBytes = maxInitialSplitSize.toBytes()[ CD ]
Line_18 $$ if (remainingInitialSplits.decrementAndGet() < 0 && creatingInitialSplits) -->Line_21 $$ long remainingLength = blockLocation.getLength() - chunkOffset[ CD ]
Line_25 $$ long chunkLength = Math.min(targetChunkSize, blockLocation.getLength() - chunkOffset)-->Line_27 $$ chunkOffset += chunkLength[ FD ]
Line_12 $$ creatingInitialSplits = true-->Line_18 $$ if (remainingInitialSplits.decrementAndGet() < 0 && creatingInitialSplits) [ FD ]
Line_23 $$ targetChunkSize = (long) Math.ceil(remainingLength * 1.0 / chunks)-->Line_25 $$ long chunkLength = Math.min(targetChunkSize, blockLocation.getLength() - chunkOffset)[ FD ]
Line_6 $$ for (BlockLocation blockLocation : blockLocations) -->Line_14 $$ int chunks = Math.max(1, (int) (blockLocation.getLength() / maxBytes))[ FD ]
Line_2 $$ private List<HiveSplit> createHiveSplits(String partitionName, String path, BlockLocation[] blockLocations, long start, long length, Properties schema, List<HivePartitionKey> partitionKeys, boolean splittable, ConnectorSession session, TupleDomain<HiveColumnHandle> effectivePredicate) throws IOException -->Line_5 $$ if (splittable) [ CD ]
Line_19 $$ creatingInitialSplits = false-->Line_18 $$ if (remainingInitialSplits.decrementAndGet() < 0 && creatingInitialSplits) [ FD ]
Line_17 $$ while (chunkOffset < blockLocation.getLength()) -->Line_18 $$ if (remainingInitialSplits.decrementAndGet() < 0 && creatingInitialSplits) [ CD ]
