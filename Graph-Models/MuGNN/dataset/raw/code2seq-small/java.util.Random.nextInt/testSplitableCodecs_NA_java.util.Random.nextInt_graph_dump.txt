Line_53 $$ Text key = null-->Line_60 $$ final int k = Integer.parseInt(key.toString())[ FD ]
Line_42 $$ List<InputSplit> splits = format.getSplits(job)-->Line_52 $$ reader.initialize(splits.get(j), mcontext)[ FD ]
Line_49 $$ RecordReader<Text, Text> reader = format.createRecordReader(splits.get(j), context)-->Line_75 $$ reader.close()[ FD ]
Line_46 $$ for (int j = 0; j < splits.size(); j++) -->Line_52 $$ reader.initialize(splits.get(j), mcontext)[ FD ]
Line_46 $$ for (int j = 0; j < splits.size(); j++) -->Line_47 $$ LOG.debug("split[" + j + "]= " + splits.get(j))[ FD ]
Line_48 $$ TaskAttemptContext context = MapReduceTestUtil.createDummyMapTaskAttemptContext(job.getConfiguration())-->Line_49 $$ RecordReader<Text, Text> reader = format.createRecordReader(splits.get(j), context)[ FD ]
Line_4 $$ final Job job = Job.getInstance(defaultConf)-->Line_18 $$ FileInputFormat.setInputPaths(job, workDir)[ FD ]
Line_9 $$ codec = (CompressionCodec) ReflectionUtils.newInstance(conf.getClassByName("org.apache.hadoop.io.compress.BZip2Codec"), conf)-->Line_13 $$ Path file = new Path(workDir, "test" + codec.getDefaultExtension())[ FD ]
Line_27 $$ for (int i = 0; i < length; i++) -->Line_30 $$ writer.write(Integer.toString(i))[ CD ]
Line_4 $$ final Job job = Job.getInstance(defaultConf)-->Line_20 $$ FileInputFormat.setMaxInputSplitSize(job, MAX_LENGTH / 20)[ FD ]
Line_46 $$ for (int j = 0; j < splits.size(); j++) -->Line_50 $$ Class<?> clazz = reader.getClass()[ CD ]
Line_27 $$ for (int i = 0; i < length; i++) -->Line_29 $$ writer.write("\t")[ CD ]
Line_39 $$ for (int i = 0; i < 3; i++) -->Line_40 $$ int numSplits = random.nextInt(MAX_LENGTH / 2000) + 1[ CD ]
Line_69 $$ if (count > 0) -->Line_72 $$ LOG.debug("splits[" + j + "]=" + splits.get(j) + " count=" + count)[ CD ]
Line_57 $$ while (reader.nextKeyValue()) -->Line_61 $$ final int v = Integer.parseInt(value.toString())[ CD ]
Line_49 $$ RecordReader<Text, Text> reader = format.createRecordReader(splits.get(j), context)-->Line_59 $$ value = reader.getCurrentValue()[ FD ]
Line_39 $$ for (int i = 0; i < 3; i++) -->Line_41 $$ LOG.info("splitting: requesting = " + numSplits)[ CD ]
Line_57 $$ while (reader.nextKeyValue()) -->Line_59 $$ value = reader.getCurrentValue()[ CD ]
Line_49 $$ RecordReader<Text, Text> reader = format.createRecordReader(splits.get(j), context)-->Line_50 $$ Class<?> clazz = reader.getClass()[ FD ]
Line_42 $$ List<InputSplit> splits = format.getSplits(job)-->Line_43 $$ LOG.info("splitting: got =        " + splits.size())[ FD ]
Line_16 $$ Random random = new Random(seed)-->Line_40 $$ int numSplits = random.nextInt(MAX_LENGTH / 2000) + 1[ FD ]
Line_27 $$ for (int i = 0; i < length; i++) -->Line_39 $$ for (int i = 0; i < 3; i++) [ FD ]
Line_39 $$ for (int i = 0; i < 3; i++) -->Line_42 $$ List<InputSplit> splits = format.getSplits(job)[ CD ]
Line_49 $$ RecordReader<Text, Text> reader = format.createRecordReader(splits.get(j), context)-->Line_58 $$ key = reader.getCurrentKey()[ FD ]
Line_57 $$ while (reader.nextKeyValue()) -->Line_67 $$ count++[ CD ]
Line_56 $$ int count = 0-->Line_69 $$ if (count > 0) [ FD ]
Line_57 $$ while (reader.nextKeyValue()) -->Line_66 $$ bits.set(v)[ CD ]
Line_4 $$ final Job job = Job.getInstance(defaultConf)-->Line_38 $$ assertTrue("KVTIF claims not splittable", format.isSplitable(job, file))[ FD ]
Line_46 $$ for (int j = 0; j < splits.size(); j++) -->Line_51 $$ MapContext<Text, Text, Text, Text> mcontext = new MapContextImpl<Text, Text, Text, Text>(job.getConfiguration(), context.getTaskAttemptID(), reader, null, null, MapReduceTestUtil.createDummyReporter(), splits.get(j))[ CD ]
Line_4 $$ final Job job = Job.getInstance(defaultConf)-->Line_51 $$ MapContext<Text, Text, Text, Text> mcontext = new MapContextImpl<Text, Text, Text, Text>(job.getConfiguration(), context.getTaskAttemptID(), reader, null, null, MapReduceTestUtil.createDummyReporter(), splits.get(j))[ FD ]
Line_46 $$ for (int j = 0; j < splits.size(); j++) -->Line_49 $$ RecordReader<Text, Text> reader = format.createRecordReader(splits.get(j), context)[ CD ]
Line_42 $$ List<InputSplit> splits = format.getSplits(job)-->Line_51 $$ MapContext<Text, Text, Text, Text> mcontext = new MapContextImpl<Text, Text, Text, Text>(job.getConfiguration(), context.getTaskAttemptID(), reader, null, null, MapReduceTestUtil.createDummyReporter(), splits.get(j))[ FD ]
Line_27 $$ for (int i = 0; i < length; i++) -->Line_31 $$ writer.write("\n")[ CD ]
Line_42 $$ List<InputSplit> splits = format.getSplits(job)-->Line_72 $$ LOG.debug("splits[" + j + "]=" + splits.get(j) + " count=" + count)[ FD ]
Line_46 $$ for (int j = 0; j < splits.size(); j++) -->Line_47 $$ LOG.debug("split[" + j + "]= " + splits.get(j))[ CD ]
Line_39 $$ for (int i = 0; i < 3; i++) -->Line_78 $$ assertEquals("Some keys in no partition.", length, bits.cardinality())[ CD ]
Line_13 $$ Path file = new Path(workDir, "test" + codec.getDefaultExtension())-->Line_38 $$ assertTrue("KVTIF claims not splittable", format.isSplitable(job, file))[ FD ]
Line_4 $$ final Job job = Job.getInstance(defaultConf)-->Line_5 $$ final Configuration conf = job.getConfiguration()[ FD ]
Line_39 $$ for (int i = 0; i < 3; i++) -->Line_46 $$ for (int j = 0; j < splits.size(); j++) [ CD ]
Line_49 $$ RecordReader<Text, Text> reader = format.createRecordReader(splits.get(j), context)-->Line_57 $$ while (reader.nextKeyValue()) [ FD ]
Line_61 $$ final int v = Integer.parseInt(value.toString())-->Line_66 $$ bits.set(v)[ FD ]
Line_57 $$ while (reader.nextKeyValue()) -->Line_58 $$ key = reader.getCurrentKey()[ CD ]
Line_27 $$ for (int i = 0; i < length; i++) -->Line_30 $$ writer.write(Integer.toString(i))[ FD ]
Line_27 $$ for (int i = 0; i < length; i++) -->Line_28 $$ writer.write(Integer.toString(i * 2))[ CD ]
Line_42 $$ List<InputSplit> splits = format.getSplits(job)-->Line_49 $$ RecordReader<Text, Text> reader = format.createRecordReader(splits.get(j), context)[ FD ]
Line_46 $$ for (int j = 0; j < splits.size(); j++) -->Line_49 $$ RecordReader<Text, Text> reader = format.createRecordReader(splits.get(j), context)[ FD ]
Line_39 $$ for (int i = 0; i < 3; i++) -->Line_43 $$ LOG.info("splitting: got =        " + splits.size())[ CD ]
Line_57 $$ while (reader.nextKeyValue()) -->Line_63 $$ assertEquals("Mismatched key/value", k / 2, v)[ CD ]
Line_42 $$ List<InputSplit> splits = format.getSplits(job)-->Line_47 $$ LOG.debug("split[" + j + "]= " + splits.get(j))[ FD ]
Line_58 $$ key = reader.getCurrentKey()-->Line_60 $$ final int k = Integer.parseInt(key.toString())[ FD ]
Line_5 $$ final Configuration conf = job.getConfiguration()-->Line_9 $$ codec = (CompressionCodec) ReflectionUtils.newInstance(conf.getClassByName("org.apache.hadoop.io.compress.BZip2Codec"), conf)[ FD ]
Line_57 $$ while (reader.nextKeyValue()) -->Line_64 $$ LOG.debug("read " + k + "," + v)[ CD ]
Line_42 $$ List<InputSplit> splits = format.getSplits(job)-->Line_70 $$ LOG.info("splits[" + j + "]=" + splits.get(j) + " count=" + count)[ FD ]
Line_54 $$ Text value = null-->Line_59 $$ value = reader.getCurrentValue()[ FD ]
Line_46 $$ for (int j = 0; j < splits.size(); j++) -->Line_52 $$ reader.initialize(splits.get(j), mcontext)[ CD ]
Line_51 $$ MapContext<Text, Text, Text, Text> mcontext = new MapContextImpl<Text, Text, Text, Text>(job.getConfiguration(), context.getTaskAttemptID(), reader, null, null, MapReduceTestUtil.createDummyReporter(), splits.get(j))-->Line_52 $$ reader.initialize(splits.get(j), mcontext)[ FD ]
Line_4 $$ final Job job = Job.getInstance(defaultConf)-->Line_48 $$ TaskAttemptContext context = MapReduceTestUtil.createDummyMapTaskAttemptContext(job.getConfiguration())[ FD ]
Line_59 $$ value = reader.getCurrentValue()-->Line_61 $$ final int v = Integer.parseInt(value.toString())[ FD ]
Line_61 $$ final int v = Integer.parseInt(value.toString())-->Line_65 $$ assertFalse(k + "," + v + " in multiple partitions.", bits.get(v))[ FD ]
Line_48 $$ TaskAttemptContext context = MapReduceTestUtil.createDummyMapTaskAttemptContext(job.getConfiguration())-->Line_51 $$ MapContext<Text, Text, Text, Text> mcontext = new MapContextImpl<Text, Text, Text, Text>(job.getConfiguration(), context.getTaskAttemptID(), reader, null, null, MapReduceTestUtil.createDummyReporter(), splits.get(j))[ FD ]
Line_46 $$ for (int j = 0; j < splits.size(); j++) -->Line_54 $$ Text value = null[ CD ]
Line_46 $$ for (int j = 0; j < splits.size(); j++) -->Line_51 $$ MapContext<Text, Text, Text, Text> mcontext = new MapContextImpl<Text, Text, Text, Text>(job.getConfiguration(), context.getTaskAttemptID(), reader, null, null, MapReduceTestUtil.createDummyReporter(), splits.get(j))[ FD ]
Line_49 $$ RecordReader<Text, Text> reader = format.createRecordReader(splits.get(j), context)-->Line_52 $$ reader.initialize(splits.get(j), mcontext)[ FD ]
Line_42 $$ List<InputSplit> splits = format.getSplits(job)-->Line_46 $$ for (int j = 0; j < splits.size(); j++) [ FD ]
Line_4 $$ final Job job = Job.getInstance(defaultConf)-->Line_42 $$ List<InputSplit> splits = format.getSplits(job)[ FD ]
Line_61 $$ final int v = Integer.parseInt(value.toString())-->Line_63 $$ assertEquals("Mismatched key/value", k / 2, v)[ FD ]
Line_56 $$ int count = 0-->Line_67 $$ count++[ FD ]
Line_46 $$ for (int j = 0; j < splits.size(); j++) -->Line_70 $$ LOG.info("splits[" + j + "]=" + splits.get(j) + " count=" + count)[ FD ]
Line_57 $$ while (reader.nextKeyValue()) -->Line_65 $$ assertFalse(k + "," + v + " in multiple partitions.", bits.get(v))[ CD ]
Line_57 $$ while (reader.nextKeyValue()) -->Line_60 $$ final int k = Integer.parseInt(key.toString())[ CD ]
Line_46 $$ for (int j = 0; j < splits.size(); j++) -->Line_72 $$ LOG.debug("splits[" + j + "]=" + splits.get(j) + " count=" + count)[ FD ]
Line_57 $$ while (reader.nextKeyValue()) -->Line_62 $$ assertEquals("Bad key", 0, k % 2)[ CD ]
Line_53 $$ Text key = null-->Line_58 $$ key = reader.getCurrentKey()[ FD ]
Line_69 $$ if (count > 0) -->Line_70 $$ LOG.info("splits[" + j + "]=" + splits.get(j) + " count=" + count)[ CD ]
Line_46 $$ for (int j = 0; j < splits.size(); j++) -->Line_48 $$ TaskAttemptContext context = MapReduceTestUtil.createDummyMapTaskAttemptContext(job.getConfiguration())[ CD ]
Line_46 $$ for (int j = 0; j < splits.size(); j++) -->Line_53 $$ Text key = null[ CD ]
Line_54 $$ Text value = null-->Line_61 $$ final int v = Integer.parseInt(value.toString())[ FD ]
