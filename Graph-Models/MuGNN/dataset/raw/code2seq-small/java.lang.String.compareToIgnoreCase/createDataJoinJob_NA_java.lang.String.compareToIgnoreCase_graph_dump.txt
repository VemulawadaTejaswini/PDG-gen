Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_14 $$ Class reducer = getClassByName(args[5])[ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_44 $$ job.setMapOutputKeyClass(Text.class)[ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_18 $$ if (args[7].compareToIgnoreCase("text") != 0) [ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_47 $$ job.setOutputValueClass(outputValueClass)[ CD ]
Line_17 $$ Class outputValueClass = Text.class-->Line_47 $$ job.setOutputValueClass(outputValueClass)[ FD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_50 $$ job.setNumReduceTasks(numOfReducers)[ CD ]
Line_5 $$ Class inputFormat = SequenceFileInputFormat.class-->Line_10 $$ inputFormat = TextInputFormat.class[ FD ]
Line_34 $$ JobConf job = new JobConf(defaults, DataJoinJob.class)-->Line_42 $$ job.setOutputFormat(outputFormat)[ FD ]
Line_33 $$ Configuration defaults = new Configuration()-->Line_36 $$ FileSystem fs = FileSystem.get(defaults)[ FD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_34 $$ JobConf job = new JobConf(defaults, DataJoinJob.class)[ CD ]
Line_6 $$ if (args[2].compareToIgnoreCase("text") != 0) -->Line_10 $$ inputFormat = TextInputFormat.class[ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_15 $$ Class mapoutputValueClass = getClassByName(args[6])[ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_30 $$ if (args.length > 9) [ CD ]
Line_34 $$ JobConf job = new JobConf(defaults, DataJoinJob.class)-->Line_41 $$ FileOutputFormat.setOutputPath(job, new Path(outputDir))[ FD ]
Line_18 $$ if (args[7].compareToIgnoreCase("text") != 0) -->Line_23 $$ System.out.println("Using TextOutputFormat: " + args[7])[ CD ]
Line_36 $$ FileSystem fs = FileSystem.get(defaults)-->Line_37 $$ fs.delete(new Path(outputDir), true)[ FD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_38 $$ FileInputFormat.setInputPaths(job, inputDir)[ CD ]
Line_34 $$ JobConf job = new JobConf(defaults, DataJoinJob.class)-->Line_49 $$ job.setNumMapTasks(1)[ FD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_49 $$ job.setNumMapTasks(1)[ CD ]
Line_34 $$ JobConf job = new JobConf(defaults, DataJoinJob.class)-->Line_39 $$ job.setInputFormat(inputFormat)[ FD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_52 $$ return job[ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_26 $$ String jobName = ""[ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_39 $$ job.setInputFormat(inputFormat)[ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_41 $$ FileOutputFormat.setOutputPath(job, new Path(outputDir))[ CD ]
Line_28 $$ maxNumOfValuesPerGroup = Long.parseLong(args[8])-->Line_51 $$ job.setLong("datajoin.maxNumOfValuesPerGroup", maxNumOfValuesPerGroup)[ FD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_40 $$ job.setMapperClass(mapper)[ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_16 $$ Class outputFormat = TextOutputFormat.class[ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_25 $$ long maxNumOfValuesPerGroup = 100[ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_5 $$ Class inputFormat = SequenceFileInputFormat.class[ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_43 $$ SequenceFileOutputFormat.setOutputCompressionType(job, SequenceFile.CompressionType.BLOCK)[ CD ]
Line_12 $$ int numOfReducers = Integer.parseInt(args[3])-->Line_50 $$ job.setNumReduceTasks(numOfReducers)[ FD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_35 $$ job.setJobName("DataJoinJob: " + jobName)[ CD ]
Line_34 $$ JobConf job = new JobConf(defaults, DataJoinJob.class)-->Line_46 $$ job.setOutputKeyClass(Text.class)[ FD ]
Line_34 $$ JobConf job = new JobConf(defaults, DataJoinJob.class)-->Line_50 $$ job.setNumReduceTasks(numOfReducers)[ FD ]
Line_6 $$ if (args[2].compareToIgnoreCase("text") != 0) -->Line_7 $$ System.out.println("Using SequenceFileInputFormat: " + args[2])[ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_51 $$ job.setLong("datajoin.maxNumOfValuesPerGroup", maxNumOfValuesPerGroup)[ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_46 $$ job.setOutputKeyClass(Text.class)[ CD ]
Line_34 $$ JobConf job = new JobConf(defaults, DataJoinJob.class)-->Line_45 $$ job.setMapOutputValueClass(mapoutputValueClass)[ FD ]
Line_18 $$ if (args[7].compareToIgnoreCase("text") != 0) -->Line_21 $$ outputValueClass = getClassByName(args[7])[ CD ]
Line_34 $$ JobConf job = new JobConf(defaults, DataJoinJob.class)-->Line_43 $$ SequenceFileOutputFormat.setOutputCompressionType(job, SequenceFile.CompressionType.BLOCK)[ FD ]
Line_34 $$ JobConf job = new JobConf(defaults, DataJoinJob.class)-->Line_48 $$ job.setReducerClass(reducer)[ FD ]
Line_25 $$ long maxNumOfValuesPerGroup = 100-->Line_51 $$ job.setLong("datajoin.maxNumOfValuesPerGroup", maxNumOfValuesPerGroup)[ FD ]
Line_34 $$ JobConf job = new JobConf(defaults, DataJoinJob.class)-->Line_38 $$ FileInputFormat.setInputPaths(job, inputDir)[ FD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_4 $$ String outputDir = args[1][ CD ]
Line_34 $$ JobConf job = new JobConf(defaults, DataJoinJob.class)-->Line_40 $$ job.setMapperClass(mapper)[ FD ]
Line_34 $$ JobConf job = new JobConf(defaults, DataJoinJob.class)-->Line_47 $$ job.setOutputValueClass(outputValueClass)[ FD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_45 $$ job.setMapOutputValueClass(mapoutputValueClass)[ CD ]
Line_34 $$ JobConf job = new JobConf(defaults, DataJoinJob.class)-->Line_35 $$ job.setJobName("DataJoinJob: " + jobName)[ FD ]
Line_18 $$ if (args[7].compareToIgnoreCase("text") != 0) -->Line_19 $$ System.out.println("Using SequenceFileOutputFormat: " + args[7])[ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_42 $$ job.setOutputFormat(outputFormat)[ CD ]
Line_25 $$ long maxNumOfValuesPerGroup = 100-->Line_28 $$ maxNumOfValuesPerGroup = Long.parseLong(args[8])[ FD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_17 $$ Class outputValueClass = Text.class[ CD ]
Line_16 $$ Class outputFormat = TextOutputFormat.class-->Line_20 $$ outputFormat = SequenceFileOutputFormat.class[ FD ]
Line_21 $$ outputValueClass = getClassByName(args[7])-->Line_47 $$ job.setOutputValueClass(outputValueClass)[ FD ]
Line_14 $$ Class reducer = getClassByName(args[5])-->Line_48 $$ job.setReducerClass(reducer)[ FD ]
Line_18 $$ if (args[7].compareToIgnoreCase("text") != 0) -->Line_20 $$ outputFormat = SequenceFileOutputFormat.class[ CD ]
Line_26 $$ String jobName = ""-->Line_31 $$ jobName = args[9][ FD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_12 $$ int numOfReducers = Integer.parseInt(args[3])[ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_3 $$ String inputDir = args[0][ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_27 $$ if (args.length > 8) [ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_6 $$ if (args[2].compareToIgnoreCase("text") != 0) [ CD ]
Line_3 $$ String inputDir = args[0]-->Line_38 $$ FileInputFormat.setInputPaths(job, inputDir)[ FD ]
Line_27 $$ if (args.length > 8) -->Line_28 $$ maxNumOfValuesPerGroup = Long.parseLong(args[8])[ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_48 $$ job.setReducerClass(reducer)[ CD ]
Line_6 $$ if (args[2].compareToIgnoreCase("text") != 0) -->Line_9 $$ System.out.println("Using TextInputFormat: " + args[2])[ CD ]
Line_30 $$ if (args.length > 9) -->Line_31 $$ jobName = args[9][ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_33 $$ Configuration defaults = new Configuration()[ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_37 $$ fs.delete(new Path(outputDir), true)[ CD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_13 $$ Class mapper = getClassByName(args[4])[ CD ]
Line_34 $$ JobConf job = new JobConf(defaults, DataJoinJob.class)-->Line_51 $$ job.setLong("datajoin.maxNumOfValuesPerGroup", maxNumOfValuesPerGroup)[ FD ]
Line_16 $$ Class outputFormat = TextOutputFormat.class-->Line_42 $$ job.setOutputFormat(outputFormat)[ FD ]
Line_34 $$ JobConf job = new JobConf(defaults, DataJoinJob.class)-->Line_44 $$ job.setMapOutputKeyClass(Text.class)[ FD ]
Line_13 $$ Class mapper = getClassByName(args[4])-->Line_40 $$ job.setMapperClass(mapper)[ FD ]
Line_5 $$ Class inputFormat = SequenceFileInputFormat.class-->Line_39 $$ job.setInputFormat(inputFormat)[ FD ]
Line_17 $$ Class outputValueClass = Text.class-->Line_21 $$ outputValueClass = getClassByName(args[7])[ FD ]
Line_10 $$ inputFormat = TextInputFormat.class-->Line_39 $$ job.setInputFormat(inputFormat)[ FD ]
Line_2 $$ public static JobConf createDataJoinJob(String[] args) throws IOException -->Line_36 $$ FileSystem fs = FileSystem.get(defaults)[ CD ]
Line_20 $$ outputFormat = SequenceFileOutputFormat.class-->Line_42 $$ job.setOutputFormat(outputFormat)[ FD ]
Line_15 $$ Class mapoutputValueClass = getClassByName(args[6])-->Line_45 $$ job.setMapOutputValueClass(mapoutputValueClass)[ FD ]
