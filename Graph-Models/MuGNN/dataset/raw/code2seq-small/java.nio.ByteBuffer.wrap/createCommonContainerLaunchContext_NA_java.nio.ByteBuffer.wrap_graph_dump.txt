Line_44 $$ for (final String shuffleProvider : shuffleProviders) -->Line_50 $$ serviceData.put(shuffleProvider, ByteBuffer.allocate(0))[ FD ]
Line_10 $$ if (jobJar != null) -->Line_11 $$ Path remoteJobJar = (new Path(jobJar)).makeQualified(remoteFS.getUri(), remoteFS.getWorkingDirectory())[ CD ]
Line_5 $$ Map<String, ByteBuffer> serviceData = new HashMap<String, ByteBuffer>()-->Line_50 $$ serviceData.put(shuffleProvider, ByteBuffer.allocate(0))[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_39 $$ Token<JobTokenIdentifier> shuffleToken = new Token<JobTokenIdentifier>(jobToken.getIdentifier(), shuffleSecret, jobToken.getKind(), jobToken.getService())[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_34 $$ byte[] shuffleSecret = TokenCache.getShuffleSecretKey(credentials)[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_21 $$ Path remoteJobSubmitDir = new Path(path, oldJobId.toString())[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_9 $$ String jobJar = conf.get(MRJobConfig.JAR)[ FD ]
Line_6 $$ ByteBuffer taskCredentialsBuffer = ByteBuffer.wrap(new byte[] -->Line_32 $$ taskCredentialsBuffer = ByteBuffer.wrap(containerTokens_dob.getData(), 0, containerTokens_dob.getLength())[ FD ]
Line_27 $$ Credentials taskCredentials = new Credentials(credentials)-->Line_28 $$ TokenCache.setJobToken(jobToken, taskCredentials)[ FD ]
Line_35 $$ if (shuffleSecret == null) -->Line_36 $$ LOG.warn("Cannot locate shuffle secret in credentials." + " Using job token as shuffle secret.")[ CD ]
Line_3 $$ Map<String, LocalResource> localResources = new HashMap<String, LocalResource>()-->Line_25 $$ MRApps.setupDistributedCache(conf, localResources)[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_64 $$ MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(), MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf)[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_6 $$ ByteBuffer taskCredentialsBuffer = ByteBuffer.wrap(new byte[] [ CD ]
Line_27 $$ Credentials taskCredentials = new Credentials(credentials)-->Line_31 $$ taskCredentials.writeTokenStorageToStream(containerTokens_dob)[ FD ]
Line_10 $$ if (jobJar != null) -->Line_18 $$ LOG.info("Job jar is not present. " + "Not adding any jar to the list of resources.")[ CD ]
Line_22 $$ Path remoteJobConfPath = new Path(remoteJobSubmitDir, MRJobConfig.JOB_CONF_FILE)-->Line_24 $$ LOG.info("The job-conf file on the remote FS is " + remoteJobConfPath.toUri().toASCIIString())[ FD ]
Line_10 $$ if (jobJar != null) -->Line_12 $$ LocalResource rc = createLocalResource(remoteFS, remoteJobJar, LocalResourceType.PATTERN, LocalResourceVisibility.APPLICATION)[ CD ]
Line_4 $$ Map<String, String> environment = new HashMap<String, String>()-->Line_64 $$ MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(), MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf)[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_5 $$ Map<String, ByteBuffer> serviceData = new HashMap<String, ByteBuffer>()[ CD ]
Line_4 $$ Map<String, String> environment = new HashMap<String, String>()-->Line_66 $$ ContainerLaunchContext container = ContainerLaunchContext.newInstance(localResources, environment, null, serviceData, taskCredentialsBuffer, applicationACLs)[ FD ]
Line_12 $$ LocalResource rc = createLocalResource(remoteFS, remoteJobJar, LocalResourceType.PATTERN, LocalResourceVisibility.APPLICATION)-->Line_14 $$ rc.setPattern(pattern)[ FD ]
Line_43 $$ Collection<String> auxNames = conf.getStringCollection(YarnConfiguration.NM_AUX_SERVICES)-->Line_48 $$ if (auxNames.contains(shuffleProvider)) [ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_41 $$ Collection<String> shuffleProviders = conf.getStringCollection(MRJobConfig.MAPREDUCE_JOB_SHUFFLE_PROVIDER_SERVICES)[ FD ]
Line_10 $$ if (jobJar != null) -->Line_13 $$ String pattern = conf.getPattern(JobContext.JAR_UNPACK_PATTERN, JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern()[ CD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_25 $$ MRApps.setupDistributedCache(conf, localResources)[ FD ]
Line_22 $$ Path remoteJobConfPath = new Path(remoteJobSubmitDir, MRJobConfig.JOB_CONF_FILE)-->Line_23 $$ localResources.put(MRJobConfig.JOB_CONF_FILE, createLocalResource(remoteFS, remoteJobConfPath, LocalResourceType.FILE, LocalResourceVisibility.APPLICATION))[ FD ]
Line_4 $$ Map<String, String> environment = new HashMap<String, String>()-->Line_65 $$ MRApps.setEnvFromInputString(environment, conf.get(MRJobConfig.MAPRED_ADMIN_USER_ENV, MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV), conf)[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_20 $$ Path path = MRApps.getStagingAreaDir(conf, UserGroupInformation.getCurrentUser().getShortUserName())[ FD ]
Line_41 $$ Collection<String> shuffleProviders = conf.getStringCollection(MRJobConfig.MAPREDUCE_JOB_SHUFFLE_PROVIDER_SERVICES)-->Line_42 $$ if (!shuffleProviders.isEmpty()) [ FD ]
Line_4 $$ Map<String, String> environment = new HashMap<String, String>()-->Line_63 $$ environment.put(Environment.SHELL.name(), conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL, MRJobConfig.DEFAULT_SHELL))[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_4 $$ Map<String, String> environment = new HashMap<String, String>()[ CD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_28 $$ TokenCache.setJobToken(jobToken, taskCredentials)[ FD ]
Line_10 $$ if (jobJar != null) -->Line_14 $$ rc.setPattern(pattern)[ CD ]
Line_29 $$ DataOutputBuffer containerTokens_dob = new DataOutputBuffer()-->Line_32 $$ taskCredentialsBuffer = ByteBuffer.wrap(containerTokens_dob.getData(), 0, containerTokens_dob.getLength())[ FD ]
Line_44 $$ for (final String shuffleProvider : shuffleProviders) -->Line_48 $$ if (auxNames.contains(shuffleProvider)) [ FD ]
Line_57 $$ if (initialAppClasspath != null) -->Line_58 $$ MRApps.addToEnvironment(environment, Environment.APP_CLASSPATH.name(), initialAppClasspath, conf)[ CD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_65 $$ MRApps.setEnvFromInputString(environment, conf.get(MRJobConfig.MAPRED_ADMIN_USER_ENV, MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV), conf)[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_58 $$ MRApps.addToEnvironment(environment, Environment.APP_CLASSPATH.name(), initialAppClasspath, conf)[ FD ]
Line_5 $$ Map<String, ByteBuffer> serviceData = new HashMap<String, ByteBuffer>()-->Line_40 $$ serviceData.put(ShuffleHandler.MAPREDUCE_SHUFFLE_SERVICEID, ShuffleHandler.serializeServiceData(shuffleToken))[ FD ]
Line_10 $$ if (jobJar != null) -->Line_16 $$ LOG.info("The job-jar file on the remote FS is " + remoteJobJar.toUri().toASCIIString())[ CD ]
Line_5 $$ Map<String, ByteBuffer> serviceData = new HashMap<String, ByteBuffer>()-->Line_66 $$ ContainerLaunchContext container = ContainerLaunchContext.newInstance(localResources, environment, null, serviceData, taskCredentialsBuffer, applicationACLs)[ FD ]
Line_32 $$ taskCredentialsBuffer = ByteBuffer.wrap(containerTokens_dob.getData(), 0, containerTokens_dob.getLength())-->Line_66 $$ ContainerLaunchContext container = ContainerLaunchContext.newInstance(localResources, environment, null, serviceData, taskCredentialsBuffer, applicationACLs)[ FD ]
Line_10 $$ if (jobJar != null) -->Line_15 $$ localResources.put(MRJobConfig.JOB_JAR, rc)[ CD ]
Line_44 $$ for (final String shuffleProvider : shuffleProviders) -->Line_45 $$ if (shuffleProvider.equals(ShuffleHandler.MAPREDUCE_SHUFFLE_SERVICEID)) [ FD ]
Line_6 $$ ByteBuffer taskCredentialsBuffer = ByteBuffer.wrap(new byte[] -->Line_66 $$ ContainerLaunchContext container = ContainerLaunchContext.newInstance(localResources, environment, null, serviceData, taskCredentialsBuffer, applicationACLs)[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_3 $$ Map<String, LocalResource> localResources = new HashMap<String, LocalResource>()[ CD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_64 $$ MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(), MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf)[ CD ]
Line_48 $$ if (auxNames.contains(shuffleProvider)) -->Line_50 $$ serviceData.put(shuffleProvider, ByteBuffer.allocate(0))[ CD ]
Line_11 $$ Path remoteJobJar = (new Path(jobJar)).makeQualified(remoteFS.getUri(), remoteFS.getWorkingDirectory())-->Line_12 $$ LocalResource rc = createLocalResource(remoteFS, remoteJobJar, LocalResourceType.PATTERN, LocalResourceVisibility.APPLICATION)[ FD ]
Line_9 $$ String jobJar = conf.get(MRJobConfig.JAR)-->Line_10 $$ if (jobJar != null) [ FD ]
Line_4 $$ Map<String, String> environment = new HashMap<String, String>()-->Line_58 $$ MRApps.addToEnvironment(environment, Environment.APP_CLASSPATH.name(), initialAppClasspath, conf)[ FD ]
Line_4 $$ Map<String, String> environment = new HashMap<String, String>()-->Line_56 $$ MRApps.addToEnvironment(environment, Environment.CLASSPATH.name(), getInitialClasspath(conf), conf)[ FD ]
Line_3 $$ Map<String, LocalResource> localResources = new HashMap<String, LocalResource>()-->Line_15 $$ localResources.put(MRJobConfig.JOB_JAR, rc)[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_26 $$ LOG.info("Adding #" + credentials.numberOfTokens() + " tokens and #" + credentials.numberOfSecretKeys() + " secret keys for NM use for launching container")[ FD ]
Line_35 $$ if (shuffleSecret == null) -->Line_37 $$ shuffleSecret = jobToken.getPassword()[ CD ]
Line_34 $$ byte[] shuffleSecret = TokenCache.getShuffleSecretKey(credentials)-->Line_35 $$ if (shuffleSecret == null) [ FD ]
Line_3 $$ Map<String, LocalResource> localResources = new HashMap<String, LocalResource>()-->Line_66 $$ ContainerLaunchContext container = ContainerLaunchContext.newInstance(localResources, environment, null, serviceData, taskCredentialsBuffer, applicationACLs)[ FD ]
Line_8 $$ FileSystem remoteFS = FileSystem.get(conf)-->Line_12 $$ LocalResource rc = createLocalResource(remoteFS, remoteJobJar, LocalResourceType.PATTERN, LocalResourceVisibility.APPLICATION)[ FD ]
Line_8 $$ FileSystem remoteFS = FileSystem.get(conf)-->Line_11 $$ Path remoteJobJar = (new Path(jobJar)).makeQualified(remoteFS.getUri(), remoteFS.getWorkingDirectory())[ FD ]
Line_13 $$ String pattern = conf.getPattern(JobContext.JAR_UNPACK_PATTERN, JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern()-->Line_14 $$ rc.setPattern(pattern)[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_56 $$ MRApps.addToEnvironment(environment, Environment.CLASSPATH.name(), getInitialClasspath(conf), conf)[ FD ]
Line_48 $$ if (auxNames.contains(shuffleProvider)) -->Line_49 $$ LOG.info("Adding ShuffleProvider Service: " + shuffleProvider + " to serviceData")[ CD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_63 $$ environment.put(Environment.SHELL.name(), conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL, MRJobConfig.DEFAULT_SHELL))[ CD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_43 $$ Collection<String> auxNames = conf.getStringCollection(YarnConfiguration.NM_AUX_SERVICES)[ FD ]
Line_27 $$ Credentials taskCredentials = new Credentials(credentials)-->Line_30 $$ LOG.info("Size of containertokens_dob is " + taskCredentials.numberOfTokens())[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_67 $$ return container[ CD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_65 $$ MRApps.setEnvFromInputString(environment, conf.get(MRJobConfig.MAPRED_ADMIN_USER_ENV, MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV), conf)[ CD ]
Line_39 $$ Token<JobTokenIdentifier> shuffleToken = new Token<JobTokenIdentifier>(jobToken.getIdentifier(), shuffleSecret, jobToken.getKind(), jobToken.getService())-->Line_40 $$ serviceData.put(ShuffleHandler.MAPREDUCE_SHUFFLE_SERVICEID, ShuffleHandler.serializeServiceData(shuffleToken))[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_63 $$ environment.put(Environment.SHELL.name(), conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL, MRJobConfig.DEFAULT_SHELL))[ FD ]
Line_11 $$ Path remoteJobJar = (new Path(jobJar)).makeQualified(remoteFS.getUri(), remoteFS.getWorkingDirectory())-->Line_16 $$ LOG.info("The job-jar file on the remote FS is " + remoteJobJar.toUri().toASCIIString())[ FD ]
Line_42 $$ if (!shuffleProviders.isEmpty()) -->Line_43 $$ Collection<String> auxNames = conf.getStringCollection(YarnConfiguration.NM_AUX_SERVICES)[ CD ]
Line_8 $$ FileSystem remoteFS = FileSystem.get(conf)-->Line_23 $$ localResources.put(MRJobConfig.JOB_CONF_FILE, createLocalResource(remoteFS, remoteJobConfPath, LocalResourceType.FILE, LocalResourceVisibility.APPLICATION))[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_13 $$ String pattern = conf.getPattern(JobContext.JAR_UNPACK_PATTERN, JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern()[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_66 $$ ContainerLaunchContext container = ContainerLaunchContext.newInstance(localResources, environment, null, serviceData, taskCredentialsBuffer, applicationACLs)[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_8 $$ FileSystem remoteFS = FileSystem.get(conf)[ FD ]
Line_34 $$ byte[] shuffleSecret = TokenCache.getShuffleSecretKey(credentials)-->Line_37 $$ shuffleSecret = jobToken.getPassword()[ FD ]
Line_29 $$ DataOutputBuffer containerTokens_dob = new DataOutputBuffer()-->Line_31 $$ taskCredentials.writeTokenStorageToStream(containerTokens_dob)[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_66 $$ ContainerLaunchContext container = ContainerLaunchContext.newInstance(localResources, environment, null, serviceData, taskCredentialsBuffer, applicationACLs)[ CD ]
Line_3 $$ Map<String, LocalResource> localResources = new HashMap<String, LocalResource>()-->Line_23 $$ localResources.put(MRJobConfig.JOB_CONF_FILE, createLocalResource(remoteFS, remoteJobConfPath, LocalResourceType.FILE, LocalResourceVisibility.APPLICATION))[ FD ]
Line_2 $$ private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Credentials credentials) -->Line_37 $$ shuffleSecret = jobToken.getPassword()[ FD ]
Line_12 $$ LocalResource rc = createLocalResource(remoteFS, remoteJobJar, LocalResourceType.PATTERN, LocalResourceVisibility.APPLICATION)-->Line_15 $$ localResources.put(MRJobConfig.JOB_JAR, rc)[ FD ]
