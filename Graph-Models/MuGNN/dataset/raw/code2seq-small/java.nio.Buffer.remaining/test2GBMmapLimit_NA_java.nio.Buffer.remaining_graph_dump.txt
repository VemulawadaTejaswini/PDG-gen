Line_2 $$ public void test2GBMmapLimit() throws Exception -->Line_6 $$ conf.set(DFSConfigKeys.DFS_CHECKSUM_TYPE_KEY, "NULL")[ CD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_46 $$ Assert.assertEquals(2147483648L, fsIn2.getPos())[ FD ]
Line_42 $$ fsIn2 = fs.open(TEST_PATH2)-->Line_52 $$ fsIn2.releaseBuffer(buf2)[ FD ]
Line_26 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_56 $$ fsIn.releaseBuffer(buf1)[ FD ]
Line_2 $$ public void test2GBMmapLimit() throws Exception -->Line_8 $$ MiniDFSCluster cluster = null[ CD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_61 $$ IOUtils.cleanup(null, fsIn, fsIn2)[ FD ]
Line_8 $$ MiniDFSCluster cluster = null-->Line_62 $$ if (cluster != null) [ FD ]
Line_21 $$ buf1 = fsIn.read(null, 1, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_22 $$ Assert.assertEquals(1, buf1.remaining())[ FD ]
Line_10 $$ final String CONTEXT = "test2GBMmapLimit"-->Line_11 $$ conf.set(DFSConfigKeys.DFS_CLIENT_CONTEXT, CONTEXT)[ FD ]
Line_26 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_29 $$ fsIn.releaseBuffer(buf1)[ FD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_59 $$ fsIn2.releaseBuffer(buf2)[ FD ]
Line_20 $$ fsIn = fs.open(TEST_PATH)-->Line_21 $$ buf1 = fsIn.read(null, 1, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_51 $$ Assert.assertEquals(2147484672L, fsIn2.getPos())[ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_44 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_50 $$ Assert.assertEquals(1024, buf2.remaining())[ FD ]
Line_49 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_59 $$ fsIn2.releaseBuffer(buf2)[ FD ]
Line_26 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_28 $$ Assert.assertEquals(Integer.MAX_VALUE, buf1.limit())[ FD ]
Line_21 $$ buf1 = fsIn.read(null, 1, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_24 $$ buf1 = null[ FD ]
Line_21 $$ buf1 = fsIn.read(null, 1, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_23 $$ fsIn.releaseBuffer(buf1)[ FD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_33 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_26 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_27 $$ Assert.assertEquals(7, buf1.remaining())[ FD ]
Line_62 $$ if (cluster != null) -->Line_63 $$ cluster.shutdown()[ CD ]
Line_55 $$ if (buf1 != null) -->Line_56 $$ fsIn.releaseBuffer(buf1)[ CD ]
Line_30 $$ buf1 = null-->Line_33 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_24 $$ buf1 = null-->Line_56 $$ fsIn.releaseBuffer(buf1)[ FD ]
Line_48 $$ buf2 = null-->Line_52 $$ fsIn2.releaseBuffer(buf2)[ FD ]
Line_17 $$ DistributedFileSystem fs = cluster.getFileSystem()-->Line_42 $$ fsIn2 = fs.open(TEST_PATH2)[ FD ]
Line_38 $$ fsIn = null-->Line_61 $$ IOUtils.cleanup(null, fsIn, fsIn2)[ FD ]
Line_24 $$ buf1 = null-->Line_29 $$ fsIn.releaseBuffer(buf1)[ FD ]
Line_42 $$ fsIn2 = fs.open(TEST_PATH2)-->Line_43 $$ fsIn2.seek(2147483640L)[ FD ]
Line_15 $$ cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build()-->Line_63 $$ cluster.shutdown()[ FD ]
Line_42 $$ fsIn2 = fs.open(TEST_PATH2)-->Line_44 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_21 $$ buf1 = fsIn.read(null, 1, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_27 $$ Assert.assertEquals(7, buf1.remaining())[ FD ]
Line_21 $$ buf1 = fsIn.read(null, 1, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_33 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_38 $$ fsIn = null-->Line_56 $$ fsIn.releaseBuffer(buf1)[ FD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_25 $$ fsIn.seek(2147483640L)[ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_56 $$ fsIn.releaseBuffer(buf1)[ FD ]
Line_26 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_33 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_42 $$ fsIn2 = fs.open(TEST_PATH2)-->Line_46 $$ Assert.assertEquals(2147483648L, fsIn2.getPos())[ FD ]
Line_42 $$ fsIn2 = fs.open(TEST_PATH2)-->Line_47 $$ fsIn2.releaseBuffer(buf2)[ FD ]
Line_20 $$ fsIn = fs.open(TEST_PATH)-->Line_29 $$ fsIn.releaseBuffer(buf1)[ FD ]
Line_24 $$ buf1 = null-->Line_28 $$ Assert.assertEquals(Integer.MAX_VALUE, buf1.limit())[ FD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_29 $$ fsIn.releaseBuffer(buf1)[ FD ]
Line_8 $$ MiniDFSCluster cluster = null-->Line_15 $$ cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build()[ FD ]
Line_49 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_52 $$ fsIn2.releaseBuffer(buf2)[ FD ]
Line_44 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_59 $$ fsIn2.releaseBuffer(buf2)[ FD ]
Line_20 $$ fsIn = fs.open(TEST_PATH)-->Line_38 $$ fsIn = null[ FD ]
Line_20 $$ fsIn = fs.open(TEST_PATH)-->Line_23 $$ fsIn.releaseBuffer(buf1)[ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_22 $$ Assert.assertEquals(1, buf1.remaining())[ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_55 $$ if (buf1 != null) [ FD ]
Line_24 $$ buf1 = null-->Line_55 $$ if (buf1 != null) [ FD ]
Line_20 $$ fsIn = fs.open(TEST_PATH)-->Line_33 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_24 $$ buf1 = null[ FD ]
Line_20 $$ fsIn = fs.open(TEST_PATH)-->Line_26 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_5 $$ final long TEST_FILE_LENGTH = 2469605888L-->Line_18 $$ DFSTestUtil.createFile(fs, TEST_PATH, TEST_FILE_LENGTH, (short) 1, 0xB)[ FD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_43 $$ fsIn2.seek(2147483640L)[ FD ]
Line_44 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_52 $$ fsIn2.releaseBuffer(buf2)[ FD ]
Line_2 $$ public void test2GBMmapLimit() throws Exception -->Line_7 $$ conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, TEST_FILE_LENGTH)[ CD ]
Line_49 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_58 $$ if (buf2 != null) [ FD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_20 $$ fsIn = fs.open(TEST_PATH)[ FD ]
Line_2 $$ public void test2GBMmapLimit() throws Exception -->Line_5 $$ final long TEST_FILE_LENGTH = 2469605888L[ CD ]
Line_58 $$ if (buf2 != null) -->Line_59 $$ fsIn2.releaseBuffer(buf2)[ CD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_23 $$ fsIn.releaseBuffer(buf1)[ FD ]
Line_4 $$ HdfsConfiguration conf = initZeroCopyTest()-->Line_7 $$ conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, TEST_FILE_LENGTH)[ FD ]
Line_42 $$ fsIn2 = fs.open(TEST_PATH2)-->Line_49 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_49 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_47 $$ fsIn2.releaseBuffer(buf2)[ FD ]
Line_24 $$ buf1 = null-->Line_27 $$ Assert.assertEquals(7, buf1.remaining())[ FD ]
Line_15 $$ cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build()-->Line_16 $$ cluster.waitActive()[ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_59 $$ fsIn2.releaseBuffer(buf2)[ FD ]
Line_2 $$ public void test2GBMmapLimit() throws Exception -->Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null[ CD ]
Line_30 $$ buf1 = null-->Line_55 $$ if (buf1 != null) [ FD ]
Line_53 $$ buf2 = null-->Line_59 $$ fsIn2.releaseBuffer(buf2)[ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_47 $$ fsIn2.releaseBuffer(buf2)[ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_58 $$ if (buf2 != null) [ FD ]
Line_26 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_55 $$ if (buf1 != null) [ FD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_56 $$ fsIn.releaseBuffer(buf1)[ FD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_42 $$ fsIn2 = fs.open(TEST_PATH2)[ FD ]
Line_9 $$ final Path TEST_PATH = new Path("/a")-->Line_20 $$ fsIn = fs.open(TEST_PATH)[ FD ]
Line_15 $$ cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build()-->Line_17 $$ DistributedFileSystem fs = cluster.getFileSystem()[ FD ]
Line_44 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_47 $$ fsIn2.releaseBuffer(buf2)[ FD ]
Line_9 $$ final Path TEST_PATH = new Path("/a")-->Line_18 $$ DFSTestUtil.createFile(fs, TEST_PATH, TEST_FILE_LENGTH, (short) 1, 0xB)[ FD ]
Line_2 $$ public void test2GBMmapLimit() throws Exception -->Line_11 $$ conf.set(DFSConfigKeys.DFS_CLIENT_CONTEXT, CONTEXT)[ CD ]
Line_33 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_55 $$ if (buf1 != null) [ FD ]
Line_53 $$ buf2 = null-->Line_58 $$ if (buf2 != null) [ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_52 $$ fsIn2.releaseBuffer(buf2)[ FD ]
Line_42 $$ fsIn2 = fs.open(TEST_PATH2)-->Line_51 $$ Assert.assertEquals(2147484672L, fsIn2.getPos())[ FD ]
Line_21 $$ buf1 = fsIn.read(null, 1, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_30 $$ buf1 = null[ FD ]
Line_17 $$ DistributedFileSystem fs = cluster.getFileSystem()-->Line_19 $$ DFSTestUtil.waitReplication(fs, TEST_PATH, (short) 1)[ FD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_23 $$ fsIn.releaseBuffer(buf1)[ FD ]
Line_5 $$ final long TEST_FILE_LENGTH = 2469605888L-->Line_41 $$ DFSTestUtil.createFile(fs, TEST_PATH2, 1024 * 1024, TEST_FILE_LENGTH, 268435456L, (short) 1, 0xA)[ FD ]
Line_17 $$ DistributedFileSystem fs = cluster.getFileSystem()-->Line_20 $$ fsIn = fs.open(TEST_PATH)[ FD ]
Line_4 $$ HdfsConfiguration conf = initZeroCopyTest()-->Line_6 $$ conf.set(DFSConfigKeys.DFS_CHECKSUM_TYPE_KEY, "NULL")[ FD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_44 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_38 $$ fsIn = null[ FD ]
Line_17 $$ DistributedFileSystem fs = cluster.getFileSystem()-->Line_18 $$ DFSTestUtil.createFile(fs, TEST_PATH, TEST_FILE_LENGTH, (short) 1, 0xB)[ FD ]
Line_8 $$ MiniDFSCluster cluster = null-->Line_63 $$ cluster.shutdown()[ FD ]
Line_9 $$ final Path TEST_PATH = new Path("/a")-->Line_19 $$ DFSTestUtil.waitReplication(fs, TEST_PATH, (short) 1)[ FD ]
Line_20 $$ fsIn = fs.open(TEST_PATH)-->Line_31 $$ Assert.assertEquals(2147483647L, fsIn.getPos())[ FD ]
Line_2 $$ public void test2GBMmapLimit() throws Exception -->Line_4 $$ HdfsConfiguration conf = initZeroCopyTest()[ CD ]
Line_5 $$ final long TEST_FILE_LENGTH = 2469605888L-->Line_7 $$ conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, TEST_FILE_LENGTH)[ FD ]
Line_48 $$ buf2 = null-->Line_58 $$ if (buf2 != null) [ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_48 $$ buf2 = null[ FD ]
Line_8 $$ MiniDFSCluster cluster = null-->Line_17 $$ DistributedFileSystem fs = cluster.getFileSystem()[ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_33 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_42 $$ fsIn2 = fs.open(TEST_PATH2)-->Line_61 $$ IOUtils.cleanup(null, fsIn, fsIn2)[ FD ]
Line_2 $$ public void test2GBMmapLimit() throws Exception -->Line_3 $$ Assume.assumeTrue(BlockReaderTestUtil.shouldTestLargeFiles())[ CD ]
Line_44 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_50 $$ Assert.assertEquals(1024, buf2.remaining())[ FD ]
Line_26 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_30 $$ buf1 = null[ FD ]
Line_44 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_58 $$ if (buf2 != null) [ FD ]
Line_44 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_49 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_21 $$ buf1 = fsIn.read(null, 1, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_37 $$ fsIn.close()[ FD ]
Line_49 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_50 $$ Assert.assertEquals(1024, buf2.remaining())[ FD ]
Line_20 $$ fsIn = fs.open(TEST_PATH)-->Line_56 $$ fsIn.releaseBuffer(buf1)[ FD ]
Line_48 $$ buf2 = null-->Line_49 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_20 $$ fsIn = fs.open(TEST_PATH)-->Line_61 $$ IOUtils.cleanup(null, fsIn, fsIn2)[ FD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_52 $$ fsIn2.releaseBuffer(buf2)[ FD ]
Line_4 $$ HdfsConfiguration conf = initZeroCopyTest()-->Line_40 $$ conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, 268435456L)[ FD ]
Line_21 $$ buf1 = fsIn.read(null, 1, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_26 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_21 $$ buf1 = fsIn.read(null, 1, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_28 $$ Assert.assertEquals(Integer.MAX_VALUE, buf1.limit())[ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_29 $$ fsIn.releaseBuffer(buf1)[ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_28 $$ Assert.assertEquals(Integer.MAX_VALUE, buf1.limit())[ FD ]
Line_44 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_53 $$ buf2 = null[ FD ]
Line_49 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_53 $$ buf2 = null[ FD ]
Line_44 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_48 $$ buf2 = null[ FD ]
Line_21 $$ buf1 = fsIn.read(null, 1, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_55 $$ if (buf1 != null) [ FD ]
Line_48 $$ buf2 = null-->Line_50 $$ Assert.assertEquals(1024, buf2.remaining())[ FD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_26 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_27 $$ Assert.assertEquals(7, buf1.remaining())[ FD ]
Line_48 $$ buf2 = null-->Line_53 $$ buf2 = null[ FD ]
Line_48 $$ buf2 = null-->Line_59 $$ fsIn2.releaseBuffer(buf2)[ FD ]
Line_39 $$ final Path TEST_PATH2 = new Path("/b")-->Line_41 $$ DFSTestUtil.createFile(fs, TEST_PATH2, 1024 * 1024, TEST_FILE_LENGTH, 268435456L, (short) 1, 0xA)[ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_53 $$ buf2 = null[ FD ]
Line_21 $$ buf1 = fsIn.read(null, 1, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_56 $$ fsIn.releaseBuffer(buf1)[ FD ]
Line_21 $$ buf1 = fsIn.read(null, 1, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_29 $$ fsIn.releaseBuffer(buf1)[ FD ]
Line_33 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_56 $$ fsIn.releaseBuffer(buf1)[ FD ]
Line_39 $$ final Path TEST_PATH2 = new Path("/b")-->Line_42 $$ fsIn2 = fs.open(TEST_PATH2)[ FD ]
Line_17 $$ DistributedFileSystem fs = cluster.getFileSystem()-->Line_41 $$ DFSTestUtil.createFile(fs, TEST_PATH2, 1024 * 1024, TEST_FILE_LENGTH, 268435456L, (short) 1, 0xA)[ FD ]
Line_20 $$ fsIn = fs.open(TEST_PATH)-->Line_37 $$ fsIn.close()[ FD ]
Line_15 $$ cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build()-->Line_62 $$ if (cluster != null) [ FD ]
Line_8 $$ MiniDFSCluster cluster = null-->Line_16 $$ cluster.waitActive()[ FD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_31 $$ Assert.assertEquals(2147483647L, fsIn.getPos())[ FD ]
Line_44 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))-->Line_45 $$ Assert.assertEquals(8, buf2.remaining())[ FD ]
Line_2 $$ public void test2GBMmapLimit() throws Exception -->Line_13 $$ ByteBuffer buf1 = null, buf2 = null[ CD ]
Line_4 $$ HdfsConfiguration conf = initZeroCopyTest()-->Line_11 $$ conf.set(DFSConfigKeys.DFS_CLIENT_CONTEXT, CONTEXT)[ FD ]
Line_12 $$ FSDataInputStream fsIn = null, fsIn2 = null-->Line_21 $$ buf1 = fsIn.read(null, 1, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_30 $$ buf1 = null-->Line_56 $$ fsIn.releaseBuffer(buf1)[ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_49 $$ buf2 = fsIn2.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_42 $$ fsIn2 = fs.open(TEST_PATH2)-->Line_59 $$ fsIn2.releaseBuffer(buf2)[ FD ]
Line_20 $$ fsIn = fs.open(TEST_PATH)-->Line_25 $$ fsIn.seek(2147483640L)[ FD ]
Line_24 $$ buf1 = null-->Line_30 $$ buf1 = null[ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_30 $$ buf1 = null[ FD ]
Line_2 $$ public void test2GBMmapLimit() throws Exception -->Line_9 $$ final Path TEST_PATH = new Path("/a")[ CD ]
Line_2 $$ public void test2GBMmapLimit() throws Exception -->Line_10 $$ final String CONTEXT = "test2GBMmapLimit"[ CD ]
Line_24 $$ buf1 = null-->Line_33 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_45 $$ Assert.assertEquals(8, buf2.remaining())[ FD ]
Line_13 $$ ByteBuffer buf1 = null, buf2 = null-->Line_26 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
Line_24 $$ buf1 = null-->Line_26 $$ buf1 = fsIn.read(null, 1024, EnumSet.of(ReadOption.SKIP_CHECKSUMS))[ FD ]
