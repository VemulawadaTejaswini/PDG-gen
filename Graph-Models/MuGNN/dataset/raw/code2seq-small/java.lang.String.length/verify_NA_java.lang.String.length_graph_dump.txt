Line_42 $$ final JobClient client = new JobClient(GridmixTestUtils.mrvl.getConfig())-->Line_43 $$ final TaskReport[] mReports = client.getMapTaskReports(JobID.downgrade(job.getJobID()))[ FD ]
Line_13 $$ if (GenerateData.JOB_NAME.equals(jobName)) -->Line_18 $$ final Path in = new Path("foo").makeQualified(GridmixTestUtils.dfs.getUri(), GridmixTestUtils.dfs.getWorkingDirectory())[ CD ]
Line_31 $$ final String originalJobName = spec.getName()-->Line_36 $$ assertTrue(originalJobName.substring(originalJobName.length() - seqNumLength).equals(jobSeqNum))[ FD ]
Line_7 $$ for (JobStory spec : submitted) -->Line_39 $$ assertEquals("Wrong owner for " + jobName, spec.getUser(), stat.getOwner())[ FD ]
Line_43 $$ final TaskReport[] mReports = client.getMapTaskReports(JobID.downgrade(job.getJobID()))-->Line_45 $$ check(TaskType.MAP, spec, mReports, 0, 0, SLOPBYTES, nReds)[ FD ]
Line_13 $$ if (GenerateData.JOB_NAME.equals(jobName)) -->Line_19 $$ final ContentSummary generated = GridmixTestUtils.dfs.getContentSummary(in)[ CD ]
Line_2 $$ public void verify(ArrayList<JobStory> submitted) throws Exception -->Line_5 $$ assertEquals("Bad job count", expected, retiredJobs.drainTo(succeeded))[ CD ]
Line_6 $$ final HashMap<String, JobStory> sub = new HashMap<String, JobStory>()-->Line_28 $$ final JobStory spec = sub.get(originalJobId)[ FD ]
Line_41 $$ final int nReds = spec.getNumberReduces()-->Line_45 $$ check(TaskType.MAP, spec, mReports, 0, 0, SLOPBYTES, nReds)[ FD ]
Line_46 $$ final TaskReport[] rReports = client.getReduceTaskReports(JobID.downgrade(job.getJobID()))-->Line_48 $$ check(TaskType.REDUCE, spec, rReports, nMaps * SLOPBYTES, 2 * nMaps, 0, 0)[ FD ]
Line_13 $$ if (GenerateData.JOB_NAME.equals(jobName)) -->Line_22 $$ assertEquals(generated.getLength(), counter.getValue())[ CD ]
Line_11 $$ final String jobName = job.getJobName()-->Line_37 $$ assertTrue("Gridmix job name is not in the expected format.", jobName.equals(GridmixJob.JOB_NAME_PREFIX + jobSeqNum))[ FD ]
Line_13 $$ if (GenerateData.JOB_NAME.equals(jobName)) -->Line_21 $$ Counter counter = job.getCounters().getGroup("org.apache.hadoop.mapreduce.FileSystemCounter").findCounter("HDFS_BYTES_WRITTEN")[ CD ]
Line_7 $$ for (JobStory spec : submitted) -->Line_45 $$ check(TaskType.MAP, spec, mReports, 0, 0, SLOPBYTES, nReds)[ FD ]
Line_40 $$ final int nMaps = spec.getNumberMaps()-->Line_44 $$ assertEquals("Mismatched map count", nMaps, mReports.length)[ FD ]
Line_18 $$ final Path in = new Path("foo").makeQualified(GridmixTestUtils.dfs.getUri(), GridmixTestUtils.dfs.getWorkingDirectory())-->Line_19 $$ final ContentSummary generated = GridmixTestUtils.dfs.getContentSummary(in)[ FD ]
Line_13 $$ if (GenerateData.JOB_NAME.equals(jobName)) -->Line_14 $$ RemoteIterator<LocatedFileStatus> rit = GridmixTestUtils.dfs.listFiles(new Path("/"), true)[ CD ]
Line_10 $$ for (Job job : succeeded) -->Line_30 $$ assertNotNull("No counters for " + jobName, job.getCounters())[ FD ]
Line_10 $$ for (Job job : succeeded) -->Line_12 $$ Configuration configuration = job.getConfiguration()[ FD ]
Line_13 $$ if (GenerateData.JOB_NAME.equals(jobName)) -->Line_15 $$ while (rit.hasNext()) [ CD ]
Line_7 $$ for (JobStory spec : submitted) -->Line_29 $$ assertNotNull("No spec for " + jobName, spec)[ FD ]
Line_11 $$ final String jobName = job.getJobName()-->Line_13 $$ if (GenerateData.JOB_NAME.equals(jobName)) [ FD ]
Line_10 $$ for (Job job : succeeded) -->Line_43 $$ final TaskReport[] mReports = client.getMapTaskReports(JobID.downgrade(job.getJobID()))[ FD ]
Line_41 $$ final int nReds = spec.getNumberReduces()-->Line_47 $$ assertEquals("Mismatched reduce count", nReds, rReports.length)[ FD ]
Line_15 $$ while (rit.hasNext()) -->Line_16 $$ System.out.println(rit.next().toString())[ CD ]
Line_4 $$ final ArrayList<Job> succeeded = new ArrayList<Job>()-->Line_5 $$ assertEquals("Bad job count", expected, retiredJobs.drainTo(succeeded))[ FD ]
Line_12 $$ Configuration configuration = job.getConfiguration()-->Line_35 $$ String jobSeqNum = new DecimalFormat("000000").format(configuration.getInt(GridmixJob.GRIDMIX_JOB_SEQ, -1))[ FD ]
Line_6 $$ final HashMap<String, JobStory> sub = new HashMap<String, JobStory>()-->Line_8 $$ sub.put(spec.getJobID().toString(), spec)[ FD ]
Line_7 $$ for (JobStory spec : submitted) -->Line_31 $$ final String originalJobName = spec.getName()[ FD ]
Line_12 $$ Configuration configuration = job.getConfiguration()-->Line_27 $$ final String originalJobId = configuration.get(Gridmix.ORIGINAL_JOB_ID)[ FD ]
Line_31 $$ final String originalJobName = spec.getName()-->Line_33 $$ assertTrue("Original job name is wrong.", originalJobName.equals(configuration.get(Gridmix.ORIGINAL_JOB_NAME)))[ FD ]
Line_10 $$ for (Job job : succeeded) -->Line_21 $$ Counter counter = job.getCounters().getGroup("org.apache.hadoop.mapreduce.FileSystemCounter").findCounter("HDFS_BYTES_WRITTEN")[ FD ]
Line_7 $$ for (JobStory spec : submitted) -->Line_48 $$ check(TaskType.REDUCE, spec, rReports, nMaps * SLOPBYTES, 2 * nMaps, 0, 0)[ FD ]
Line_2 $$ public void verify(ArrayList<JobStory> submitted) throws Exception -->Line_3 $$ assertEquals("Bad job count", expected, retiredJobs.size())[ CD ]
Line_19 $$ final ContentSummary generated = GridmixTestUtils.dfs.getContentSummary(in)-->Line_20 $$ assertEquals(550000, generated.getLength(), 10000)[ FD ]
Line_19 $$ final ContentSummary generated = GridmixTestUtils.dfs.getContentSummary(in)-->Line_22 $$ assertEquals(generated.getLength(), counter.getValue())[ FD ]
Line_27 $$ final String originalJobId = configuration.get(Gridmix.ORIGINAL_JOB_ID)-->Line_28 $$ final JobStory spec = sub.get(originalJobId)[ FD ]
Line_42 $$ final JobClient client = new JobClient(GridmixTestUtils.mrvl.getConfig())-->Line_46 $$ final TaskReport[] rReports = client.getReduceTaskReports(JobID.downgrade(job.getJobID()))[ FD ]
Line_10 $$ for (Job job : succeeded) -->Line_11 $$ final String jobName = job.getJobName()[ FD ]
Line_2 $$ public void verify(ArrayList<JobStory> submitted) throws Exception -->Line_6 $$ final HashMap<String, JobStory> sub = new HashMap<String, JobStory>()[ CD ]
Line_21 $$ Counter counter = job.getCounters().getGroup("org.apache.hadoop.mapreduce.FileSystemCounter").findCounter("HDFS_BYTES_WRITTEN")-->Line_22 $$ assertEquals(generated.getLength(), counter.getValue())[ FD ]
Line_14 $$ RemoteIterator<LocatedFileStatus> rit = GridmixTestUtils.dfs.listFiles(new Path("/"), true)-->Line_16 $$ System.out.println(rit.next().toString())[ FD ]
Line_13 $$ if (GenerateData.JOB_NAME.equals(jobName)) -->Line_24 $$ if (GenerateDistCacheData.JOB_NAME.equals(jobName)) [ CD ]
Line_11 $$ final String jobName = job.getJobName()-->Line_24 $$ if (GenerateDistCacheData.JOB_NAME.equals(jobName)) [ FD ]
Line_38 $$ final FileStatus stat = GridmixTestUtils.dfs.getFileStatus(new Path(GridmixTestUtils.DEST, "" + Integer.valueOf(jobSeqNum)))-->Line_39 $$ assertEquals("Wrong owner for " + jobName, spec.getUser(), stat.getOwner())[ FD ]
Line_10 $$ for (Job job : succeeded) -->Line_46 $$ final TaskReport[] rReports = client.getReduceTaskReports(JobID.downgrade(job.getJobID()))[ FD ]
Line_2 $$ public void verify(ArrayList<JobStory> submitted) throws Exception -->Line_4 $$ final ArrayList<Job> succeeded = new ArrayList<Job>()[ CD ]
Line_7 $$ for (JobStory spec : submitted) -->Line_40 $$ final int nMaps = spec.getNumberMaps()[ FD ]
Line_14 $$ RemoteIterator<LocatedFileStatus> rit = GridmixTestUtils.dfs.listFiles(new Path("/"), true)-->Line_15 $$ while (rit.hasNext()) [ FD ]
Line_7 $$ for (JobStory spec : submitted) -->Line_8 $$ sub.put(spec.getJobID().toString(), spec)[ FD ]
Line_35 $$ String jobSeqNum = new DecimalFormat("000000").format(configuration.getInt(GridmixJob.GRIDMIX_JOB_SEQ, -1))-->Line_36 $$ assertTrue(originalJobName.substring(originalJobName.length() - seqNumLength).equals(jobSeqNum))[ FD ]
Line_13 $$ if (GenerateData.JOB_NAME.equals(jobName)) -->Line_20 $$ assertEquals(550000, generated.getLength(), 10000)[ CD ]
Line_12 $$ Configuration configuration = job.getConfiguration()-->Line_33 $$ assertTrue("Original job name is wrong.", originalJobName.equals(configuration.get(Gridmix.ORIGINAL_JOB_NAME)))[ FD ]
Line_35 $$ String jobSeqNum = new DecimalFormat("000000").format(configuration.getInt(GridmixJob.GRIDMIX_JOB_SEQ, -1))-->Line_38 $$ final FileStatus stat = GridmixTestUtils.dfs.getFileStatus(new Path(GridmixTestUtils.DEST, "" + Integer.valueOf(jobSeqNum)))[ FD ]
Line_7 $$ for (JobStory spec : submitted) -->Line_41 $$ final int nReds = spec.getNumberReduces()[ FD ]
