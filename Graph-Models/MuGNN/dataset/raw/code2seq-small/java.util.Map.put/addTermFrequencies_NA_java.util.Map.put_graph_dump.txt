Line_8 $$ CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class)-->Line_11 $$ String word = termAtt.toString()[ FD ]
Line_11 $$ String word = termAtt.toString()-->Line_24 $$ termFreqMap.put(word, new Int())[ FD ]
Line_10 $$ while (ts.incrementToken()) -->Line_19 $$ if (isSkipTerm(fieldName, word)) [ CD ]
Line_2 $$ private void addTermFrequencies(Reader r, Map<String, Int> termFreqMap, String fieldName) throws IOException -->Line_24 $$ termFreqMap.put(word, new Int())[ FD ]
Line_10 $$ while (ts.incrementToken()) -->Line_11 $$ String word = termAtt.toString()[ CD ]
Line_2 $$ private void addTermFrequencies(Reader r, Map<String, Int> termFreqMap, String fieldName) throws IOException -->Line_22 $$ Int cnt = termFreqMap.get(word)[ FD ]
Line_6 $$ try (TokenStream ts = analyzer.tokenStream(fieldName, r)) -->Line_9 $$ ts.reset()[ FD ]
Line_22 $$ Int cnt = termFreqMap.get(word)-->Line_23 $$ if (cnt == null) [ FD ]
Line_6 $$ try (TokenStream ts = analyzer.tokenStream(fieldName, r)) -->Line_8 $$ CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class)[ FD ]
Line_10 $$ while (ts.incrementToken()) -->Line_22 $$ Int cnt = termFreqMap.get(word)[ CD ]
Line_11 $$ String word = termAtt.toString()-->Line_16 $$ if (isNoiseWord(word)) [ FD ]
Line_10 $$ while (ts.incrementToken()) -->Line_13 $$ if (tokenCount > maxNumTokensParsed) [ CD ]
Line_2 $$ private void addTermFrequencies(Reader r, Map<String, Int> termFreqMap, String fieldName) throws IOException -->Line_3 $$ if (analyzer == null) [ CD ]
Line_23 $$ if (cnt == null) -->Line_26 $$ cnt.x++[ CD ]
Line_10 $$ while (ts.incrementToken()) -->Line_16 $$ if (isNoiseWord(word)) [ CD ]
Line_11 $$ String word = termAtt.toString()-->Line_22 $$ Int cnt = termFreqMap.get(word)[ FD ]
Line_23 $$ if (cnt == null) -->Line_24 $$ termFreqMap.put(word, new Int())[ CD ]
Line_6 $$ try (TokenStream ts = analyzer.tokenStream(fieldName, r)) -->Line_29 $$ ts.end()[ FD ]
Line_2 $$ private void addTermFrequencies(Reader r, Map<String, Int> termFreqMap, String fieldName) throws IOException -->Line_19 $$ if (isSkipTerm(fieldName, word)) [ FD ]
Line_10 $$ while (ts.incrementToken()) -->Line_12 $$ tokenCount++[ CD ]
Line_6 $$ try (TokenStream ts = analyzer.tokenStream(fieldName, r)) -->Line_10 $$ while (ts.incrementToken()) [ FD ]
Line_7 $$ int tokenCount = 0-->Line_13 $$ if (tokenCount > maxNumTokensParsed) [ FD ]
Line_2 $$ private void addTermFrequencies(Reader r, Map<String, Int> termFreqMap, String fieldName) throws IOException -->Line_6 $$ try (TokenStream ts = analyzer.tokenStream(fieldName, r)) [ FD ]
Line_10 $$ while (ts.incrementToken()) -->Line_23 $$ if (cnt == null) [ CD ]
Line_7 $$ int tokenCount = 0-->Line_12 $$ tokenCount++[ FD ]
Line_11 $$ String word = termAtt.toString()-->Line_19 $$ if (isSkipTerm(fieldName, word)) [ FD ]
