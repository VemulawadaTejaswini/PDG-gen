Line_9 $$ FileSystem lfs = FileSystem.getLocal(conf)-->Line_18 $$ lfs.delete(tempDir, true)[ FD ]
Line_8 $$ JobConf conf = new JobConf()-->Line_13 $$ org.apache.hadoop.mapred.FileOutputFormat.setCompressOutput(conf, true)[ FD ]
Line_8 $$ JobConf conf = new JobConf()-->Line_11 $$ CompressionEmulationUtil.setCompressionEmulationEnabled(conf, true)[ FD ]
Line_8 $$ JobConf conf = new JobConf()-->Line_14 $$ org.apache.hadoop.mapred.FileOutputFormat.setOutputCompressorClass(conf, GzipCodec.class)[ FD ]
Line_17 $$ Path tempDir = new Path(rootTempDir, "TestFileQueueDecompression")-->Line_18 $$ lfs.delete(tempDir, true)[ FD ]
Line_10 $$ String inputLine = "Hi Hello!"-->Line_30 $$ byte[] bytes = new byte[inputLine.getBytes().length][ FD ]
Line_8 $$ JobConf conf = new JobConf()-->Line_21 $$ OutputStream out = CompressionEmulationUtil.getPossiblyCompressedOutputStream(compressedFile, conf)[ FD ]
Line_8 $$ JobConf conf = new JobConf()-->Line_12 $$ CompressionEmulationUtil.setInputCompressionEmulationEnabled(conf, true)[ FD ]
Line_8 $$ JobConf conf = new JobConf()-->Line_9 $$ FileSystem lfs = FileSystem.getLocal(conf)[ FD ]
Line_29 $$ FileQueue queue = new FileQueue(split, conf)-->Line_32 $$ queue.close()[ FD ]
Line_30 $$ byte[] bytes = new byte[inputLine.getBytes().length]-->Line_31 $$ queue.read(bytes)[ FD ]
Line_10 $$ String inputLine = "Hi Hello!"-->Line_34 $$ assertEquals("Compression/Decompression error", inputLine, readLine)[ FD ]
Line_22 $$ BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(out))-->Line_23 $$ writer.write(inputLine)[ FD ]
Line_33 $$ String readLine = new String(bytes)-->Line_34 $$ assertEquals("Compression/Decompression error", inputLine, readLine)[ FD ]
Line_22 $$ BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(out))-->Line_24 $$ writer.close()[ FD ]
Line_10 $$ String inputLine = "Hi Hello!"-->Line_23 $$ writer.write(inputLine)[ FD ]
Line_29 $$ FileQueue queue = new FileQueue(split, conf)-->Line_31 $$ queue.read(bytes)[ FD ]
