Line_3 $$ JobConf configuration = new JobConf()-->Line_6 $$ assertTrue(configuration.get("hadoop.tmp.dir", null) == null)[ FD ]
Line_29 $$ if (outputFiles.length > 0) -->Line_30 $$ InputStream is = getFileSystem().open(outputFiles[0])[ CD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_4 $$ assertTrue(configuration.get("hadoop.tmp.dir", null) != null)[ CD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_8 $$ Path outDir = new Path("testing/jobconf/output")[ CD ]
Line_10 $$ Writer wr = new OutputStreamWriter(os)-->Line_12 $$ wr.write("hello\n")[ FD ]
Line_10 $$ Writer wr = new OutputStreamWriter(os)-->Line_13 $$ wr.close()[ FD ]
Line_14 $$ JobConf conf = new JobConf(false)-->Line_25 $$ FileInputFormat.setInputPaths(conf, inDir)[ FD ]
Line_14 $$ JobConf conf = new JobConf(false)-->Line_19 $$ conf.setMapOutputValueClass(Text.class)[ FD ]
Line_14 $$ JobConf conf = new JobConf(false)-->Line_17 $$ conf.setInputFormat(TextInputFormat.class)[ FD ]
Line_14 $$ JobConf conf = new JobConf(false)-->Line_18 $$ conf.setMapOutputKeyClass(LongWritable.class)[ FD ]
Line_14 $$ JobConf conf = new JobConf(false)-->Line_21 $$ conf.setOutputKeyClass(LongWritable.class)[ FD ]
Line_34 $$ while (line != null) -->Line_35 $$ counter++[ CD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_23 $$ conf.setMapperClass(org.apache.hadoop.mapred.lib.IdentityMapper.class)[ CD ]
Line_33 $$ int counter = 0-->Line_35 $$ counter++[ FD ]
Line_14 $$ JobConf conf = new JobConf(false)-->Line_23 $$ conf.setMapperClass(org.apache.hadoop.mapred.lib.IdentityMapper.class)[ FD ]
Line_10 $$ Writer wr = new OutputStreamWriter(os)-->Line_11 $$ wr.write("hello\n")[ FD ]
Line_32 $$ String line = reader.readLine()-->Line_37 $$ line = reader.readLine()[ FD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_3 $$ JobConf configuration = new JobConf()[ CD ]
Line_37 $$ line = reader.readLine()-->Line_36 $$ assertTrue(line.contains("hello"))[ FD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_11 $$ wr.write("hello\n")[ CD ]
Line_14 $$ JobConf conf = new JobConf(false)-->Line_16 $$ conf.setJobName("mr")[ FD ]
Line_14 $$ JobConf conf = new JobConf(false)-->Line_26 $$ FileOutputFormat.setOutputPath(conf, outDir)[ FD ]
Line_32 $$ String line = reader.readLine()-->Line_36 $$ assertTrue(line.contains("hello"))[ FD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_16 $$ conf.setJobName("mr")[ CD ]
Line_14 $$ JobConf conf = new JobConf(false)-->Line_27 $$ JobClient.runJob(conf)[ FD ]
Line_3 $$ JobConf configuration = new JobConf()-->Line_4 $$ assertTrue(configuration.get("hadoop.tmp.dir", null) != null)[ FD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_29 $$ if (outputFiles.length > 0) [ CD ]
Line_29 $$ if (outputFiles.length > 0) -->Line_40 $$ assertEquals(2, counter)[ CD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_27 $$ JobClient.runJob(conf)[ CD ]
Line_29 $$ if (outputFiles.length > 0) -->Line_33 $$ int counter = 0[ CD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_7 $$ Path inDir = new Path("testing/jobconf/input")[ CD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_9 $$ OutputStream os = getFileSystem().create(new Path(inDir, "text.txt"))[ CD ]
Line_31 $$ BufferedReader reader = new BufferedReader(new InputStreamReader(is))-->Line_39 $$ reader.close()[ FD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_18 $$ conf.setMapOutputKeyClass(LongWritable.class)[ CD ]
Line_5 $$ configuration = new JobConf(false)-->Line_6 $$ assertTrue(configuration.get("hadoop.tmp.dir", null) == null)[ FD ]
Line_14 $$ JobConf conf = new JobConf(false)-->Line_15 $$ conf.set("fs.defaultFS", createJobConf().get("fs.defaultFS"))[ FD ]
Line_37 $$ line = reader.readLine()-->Line_34 $$ while (line != null) [ FD ]
Line_29 $$ if (outputFiles.length > 0) -->Line_39 $$ reader.close()[ CD ]
Line_31 $$ BufferedReader reader = new BufferedReader(new InputStreamReader(is))-->Line_32 $$ String line = reader.readLine()[ FD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_25 $$ FileInputFormat.setInputPaths(conf, inDir)[ CD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_15 $$ conf.set("fs.defaultFS", createJobConf().get("fs.defaultFS"))[ CD ]
Line_8 $$ Path outDir = new Path("testing/jobconf/output")-->Line_28 $$ Path[] outputFiles = FileUtil.stat2Paths(getFileSystem().listStatus(outDir, new Utils.OutputFileUtils.OutputFilesFilter()))[ FD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_13 $$ wr.close()[ CD ]
Line_33 $$ int counter = 0-->Line_40 $$ assertEquals(2, counter)[ FD ]
Line_8 $$ Path outDir = new Path("testing/jobconf/output")-->Line_26 $$ FileOutputFormat.setOutputPath(conf, outDir)[ FD ]
Line_3 $$ JobConf configuration = new JobConf()-->Line_5 $$ configuration = new JobConf(false)[ FD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_14 $$ JobConf conf = new JobConf(false)[ CD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_19 $$ conf.setMapOutputValueClass(Text.class)[ CD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_20 $$ conf.setOutputFormat(TextOutputFormat.class)[ CD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_17 $$ conf.setInputFormat(TextInputFormat.class)[ CD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_5 $$ configuration = new JobConf(false)[ CD ]
Line_14 $$ JobConf conf = new JobConf(false)-->Line_20 $$ conf.setOutputFormat(TextOutputFormat.class)[ FD ]
Line_7 $$ Path inDir = new Path("testing/jobconf/input")-->Line_25 $$ FileInputFormat.setInputPaths(conf, inDir)[ FD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_6 $$ assertTrue(configuration.get("hadoop.tmp.dir", null) == null)[ CD ]
Line_32 $$ String line = reader.readLine()-->Line_34 $$ while (line != null) [ FD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_24 $$ conf.setReducerClass(org.apache.hadoop.mapred.lib.IdentityReducer.class)[ CD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_26 $$ FileOutputFormat.setOutputPath(conf, outDir)[ CD ]
Line_34 $$ while (line != null) -->Line_36 $$ assertTrue(line.contains("hello"))[ CD ]
Line_29 $$ if (outputFiles.length > 0) -->Line_31 $$ BufferedReader reader = new BufferedReader(new InputStreamReader(is))[ CD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_12 $$ wr.write("hello\n")[ CD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_21 $$ conf.setOutputKeyClass(LongWritable.class)[ CD ]
Line_29 $$ if (outputFiles.length > 0) -->Line_32 $$ String line = reader.readLine()[ CD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_22 $$ conf.setOutputValueClass(Text.class)[ CD ]
Line_14 $$ JobConf conf = new JobConf(false)-->Line_24 $$ conf.setReducerClass(org.apache.hadoop.mapred.lib.IdentityReducer.class)[ FD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_28 $$ Path[] outputFiles = FileUtil.stat2Paths(getFileSystem().listStatus(outDir, new Utils.OutputFileUtils.OutputFilesFilter()))[ CD ]
Line_29 $$ if (outputFiles.length > 0) -->Line_34 $$ while (line != null) [ CD ]
Line_34 $$ while (line != null) -->Line_37 $$ line = reader.readLine()[ CD ]
Line_2 $$ public void testNoDefaults() throws Exception -->Line_10 $$ Writer wr = new OutputStreamWriter(os)[ CD ]
Line_14 $$ JobConf conf = new JobConf(false)-->Line_22 $$ conf.setOutputValueClass(Text.class)[ FD ]
Line_31 $$ BufferedReader reader = new BufferedReader(new InputStreamReader(is))-->Line_37 $$ line = reader.readLine()[ FD ]
