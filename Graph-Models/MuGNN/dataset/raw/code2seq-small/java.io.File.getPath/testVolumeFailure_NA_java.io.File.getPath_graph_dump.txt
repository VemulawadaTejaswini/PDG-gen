Line_2 $$ public void testVolumeFailure() throws Exception -->Line_26 $$ StorageBlockReport[] reports = new StorageBlockReport[perVolumeBlockLists.size()][ CD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_35 $$ System.out.println("creating file test1.txt")[ CD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_5 $$ System.out.println("Data dir: is " + dataDir.getPath())[ CD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_6 $$ String filename = "/test.txt"[ CD ]
Line_7 $$ Path filePath = new Path(filename)-->Line_9 $$ DFSTestUtil.createFile(fs, filePath, filesize, repl, 1L)[ FD ]
Line_24 $$ DatanodeRegistration dnR = dn.getDNRegistrationForBP(bpid)-->Line_33 $$ cluster.getNameNodeRpc().blockReport(dnR, bpid, reports)[ FD ]
Line_23 $$ String bpid = cluster.getNamesystem().getBlockPoolId()-->Line_33 $$ cluster.getNameNodeRpc().blockReport(dnR, bpid, reports)[ FD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_21 $$ triggerFailure(filename, filesize)[ CD ]
Line_6 $$ String filename = "/test.txt"-->Line_21 $$ triggerFailure(filename, filesize)[ FD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_33 $$ cluster.getNameNodeRpc().blockReport(dnR, bpid, reports)[ CD ]
Line_36 $$ Path fileName1 = new Path("/test1.txt")-->Line_39 $$ System.out.println("file " + fileName1.getName() + " is created and replicated")[ FD ]
Line_8 $$ int filesize = block_size * blocks_num-->Line_37 $$ DFSTestUtil.createFile(fs, fileName1, filesize, repl, 1L)[ FD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_23 $$ String bpid = cluster.getNamesystem().getBlockPoolId()[ CD ]
Line_28 $$ for (Map.Entry<DatanodeStorage, BlockListAsLongs> kvPair : perVolumeBlockLists.entrySet()) -->Line_30 $$ BlockListAsLongs blockList = kvPair.getValue()[ FD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_19 $$ failedDir.setReadOnly()[ CD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_22 $$ DataNode dn = cluster.getDataNodes().get(1)[ CD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_34 $$ verify(filename, filesize)[ CD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_37 $$ DFSTestUtil.createFile(fs, fileName1, filesize, repl, 1L)[ CD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_38 $$ DFSTestUtil.waitReplication(fs, fileName1, repl)[ CD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_9 $$ DFSTestUtil.createFile(fs, filePath, filesize, repl, 1L)[ CD ]
Line_8 $$ int filesize = block_size * blocks_num-->Line_21 $$ triggerFailure(filename, filesize)[ FD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_39 $$ System.out.println("file " + fileName1.getName() + " is created and replicated")[ CD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_14 $$ if (failedDir.exists() && !deteteBlocks(failedDir)) [ CD ]
Line_6 $$ String filename = "/test.txt"-->Line_34 $$ verify(filename, filesize)[ FD ]
Line_3 $$ FileSystem fs = cluster.getFileSystem()-->Line_10 $$ DFSTestUtil.waitReplication(fs, filePath, repl)[ FD ]
Line_25 $$ Map<DatanodeStorage, BlockListAsLongs> perVolumeBlockLists = dn.getFSDataset().getBlockReports(bpid)-->Line_26 $$ StorageBlockReport[] reports = new StorageBlockReport[perVolumeBlockLists.size()][ FD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_18 $$ data_fail.setReadOnly()[ CD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_11 $$ System.out.println("file " + filename + "(size " + filesize + ") is created and replicated")[ CD ]
Line_3 $$ FileSystem fs = cluster.getFileSystem()-->Line_38 $$ DFSTestUtil.waitReplication(fs, fileName1, repl)[ FD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_8 $$ int filesize = block_size * blocks_num[ CD ]
Line_23 $$ String bpid = cluster.getNamesystem().getBlockPoolId()-->Line_24 $$ DatanodeRegistration dnR = dn.getDNRegistrationForBP(bpid)[ FD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_25 $$ Map<DatanodeStorage, BlockListAsLongs> perVolumeBlockLists = dn.getFSDataset().getBlockReports(bpid)[ CD ]
Line_23 $$ String bpid = cluster.getNamesystem().getBlockPoolId()-->Line_25 $$ Map<DatanodeStorage, BlockListAsLongs> perVolumeBlockLists = dn.getFSDataset().getBlockReports(bpid)[ FD ]
Line_36 $$ Path fileName1 = new Path("/test1.txt")-->Line_38 $$ DFSTestUtil.waitReplication(fs, fileName1, repl)[ FD ]
Line_3 $$ FileSystem fs = cluster.getFileSystem()-->Line_9 $$ DFSTestUtil.createFile(fs, filePath, filesize, repl, 1L)[ FD ]
Line_30 $$ BlockListAsLongs blockList = kvPair.getValue()-->Line_31 $$ reports[reportIndex++] = new StorageBlockReport(dnStorage, blockList.getBlockListAsLongs())[ FD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_27 $$ int reportIndex = 0[ CD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_7 $$ Path filePath = new Path(filename)[ CD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_3 $$ FileSystem fs = cluster.getFileSystem()[ CD ]
Line_36 $$ Path fileName1 = new Path("/test1.txt")-->Line_37 $$ DFSTestUtil.createFile(fs, fileName1, filesize, repl, 1L)[ FD ]
Line_22 $$ DataNode dn = cluster.getDataNodes().get(1)-->Line_24 $$ DatanodeRegistration dnR = dn.getDNRegistrationForBP(bpid)[ FD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_20 $$ System.out.println("Deleteing " + failedDir.getPath() + "; exist=" + failedDir.exists())[ CD ]
Line_7 $$ Path filePath = new Path(filename)-->Line_10 $$ DFSTestUtil.waitReplication(fs, filePath, repl)[ FD ]
Line_25 $$ Map<DatanodeStorage, BlockListAsLongs> perVolumeBlockLists = dn.getFSDataset().getBlockReports(bpid)-->Line_28 $$ for (Map.Entry<DatanodeStorage, BlockListAsLongs> kvPair : perVolumeBlockLists.entrySet()) [ FD ]
Line_26 $$ StorageBlockReport[] reports = new StorageBlockReport[perVolumeBlockLists.size()]-->Line_33 $$ cluster.getNameNodeRpc().blockReport(dnR, bpid, reports)[ FD ]
Line_27 $$ int reportIndex = 0-->Line_31 $$ reports[reportIndex++] = new StorageBlockReport(dnStorage, blockList.getBlockListAsLongs())[ FD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_13 $$ failedDir = MiniDFSCluster.getFinalizedDir(dataDir, cluster.getNamesystem().getBlockPoolId())[ CD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_10 $$ DFSTestUtil.waitReplication(fs, filePath, repl)[ CD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_24 $$ DatanodeRegistration dnR = dn.getDNRegistrationForBP(bpid)[ CD ]
Line_8 $$ int filesize = block_size * blocks_num-->Line_9 $$ DFSTestUtil.createFile(fs, filePath, filesize, repl, 1L)[ FD ]
Line_28 $$ for (Map.Entry<DatanodeStorage, BlockListAsLongs> kvPair : perVolumeBlockLists.entrySet()) -->Line_29 $$ DatanodeStorage dnStorage = kvPair.getKey()[ FD ]
Line_8 $$ int filesize = block_size * blocks_num-->Line_34 $$ verify(filename, filesize)[ FD ]
Line_2 $$ public void testVolumeFailure() throws Exception -->Line_36 $$ Path fileName1 = new Path("/test1.txt")[ CD ]
Line_3 $$ FileSystem fs = cluster.getFileSystem()-->Line_37 $$ DFSTestUtil.createFile(fs, fileName1, filesize, repl, 1L)[ FD ]
Line_22 $$ DataNode dn = cluster.getDataNodes().get(1)-->Line_25 $$ Map<DatanodeStorage, BlockListAsLongs> perVolumeBlockLists = dn.getFSDataset().getBlockReports(bpid)[ FD ]
