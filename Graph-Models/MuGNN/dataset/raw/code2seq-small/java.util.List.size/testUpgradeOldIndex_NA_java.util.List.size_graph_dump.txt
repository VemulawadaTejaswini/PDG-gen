Line_38 $$ int numDocs = -1-->Line_44 $$ assertEquals(numDocs, searcher.reader().numDocs())[ FD ]
Line_39 $$ for (int i = 0; i < iters; i++) -->Line_43 $$ if (i > 0) [ FD ]
Line_57 $$ try (InternalEngine engine = createEngine(store, translog)) -->Line_59 $$ try (Searcher searcher = engine.acquireSearcher("test")) [ FD ]
Line_39 $$ for (int i = 0; i < iters; i++) -->Line_64 $$ for (int i = 0; i < numExtraDocs; i++) [ FD ]
Line_64 $$ for (int i = 0; i < numExtraDocs; i++) -->Line_66 $$ Engine.Index firstIndexRequest = new Engine.Index(newUid(Integer.toString(i)), doc, Versions.MATCH_DELETED, VersionType.INTERNAL, PRIMARY, System.nanoTime())[ CD ]
Line_26 $$ Path translog = list[0].resolve("nodes/0/indices/" + indexName).resolve("0").resolve("translog")-->Line_29 $$ Path[] tlogFiles = filterExtraFSFiles(FileSystemUtils.files(translog))[ FD ]
Line_42 $$ try (Searcher searcher = engine.acquireSearcher("test")) -->Line_44 $$ assertEquals(numDocs, searcher.reader().numDocs())[ FD ]
Line_3 $$ List<Path> indexes = new ArrayList()-->Line_10 $$ for (Path indexFile : indexes.subList(0, scaledRandomIntBetween(1, indexes.size() / 2))) [ FD ]
Line_57 $$ try (InternalEngine engine = createEngine(store, translog)) -->Line_67 $$ engine.index(firstIndexRequest)[ FD ]
Line_43 $$ if (i > 0) -->Line_44 $$ assertEquals(numDocs, searcher.reader().numDocs())[ CD ]
Line_42 $$ try (Searcher searcher = engine.acquireSearcher("test")) -->Line_46 $$ TopDocs search = searcher.searcher().search(new MatchAllDocsQuery(), 1)[ FD ]
Line_66 $$ Engine.Index firstIndexRequest = new Engine.Index(newUid(Integer.toString(i)), doc, Versions.MATCH_DELETED, VersionType.INTERNAL, PRIMARY, System.nanoTime())-->Line_67 $$ engine.index(firstIndexRequest)[ FD ]
Line_51 $$ Map<String, String> userData = commitStats.getUserData()-->Line_52 $$ assertTrue("userdata dosn't contain uuid", userData.containsKey(Translog.TRANSLOG_UUID_KEY))[ FD ]
Line_47 $$ numDocs = searcher.reader().numDocs()-->Line_60 $$ numDocs = searcher.reader().numDocs()[ FD ]
Line_42 $$ try (Searcher searcher = engine.acquireSearcher("test")) -->Line_72 $$ TopDocs topDocs = searcher.searcher().search(new MatchAllDocsQuery(), randomIntBetween(numDocs, numDocs + numExtraDocs))[ FD ]
Line_47 $$ numDocs = searcher.reader().numDocs()-->Line_44 $$ assertEquals(numDocs, searcher.reader().numDocs())[ FD ]
Line_3 $$ List<Path> indexes = new ArrayList()-->Line_9 $$ Collections.shuffle(indexes, random())[ FD ]
Line_11 $$ final String indexName = indexFile.getFileName().toString().replace(".zip", "").toLowerCase(Locale.ROOT)-->Line_34 $$ logger.debug("upgrading index [ FD ]
Line_59 $$ try (Searcher searcher = engine.acquireSearcher("test")) -->Line_72 $$ TopDocs topDocs = searcher.searcher().search(new MatchAllDocsQuery(), randomIntBetween(numDocs, numDocs + numExtraDocs))[ FD ]
Line_47 $$ numDocs = searcher.reader().numDocs()-->Line_58 $$ if (numDocs == -1) [ FD ]
Line_57 $$ try (InternalEngine engine = createEngine(store, translog)) -->Line_71 $$ try (Engine.Searcher searcher = engine.acquireSearcher("test")) [ FD ]
Line_64 $$ for (int i = 0; i < numExtraDocs; i++) -->Line_65 $$ ParsedDocument doc = testParsedDocument("extra" + Integer.toString(i), "extra" + Integer.toString(i), "test", null, -1, -1, testDocument(), new BytesArray("[ CD ]
Line_64 $$ for (int i = 0; i < numExtraDocs; i++) -->Line_65 $$ ParsedDocument doc = testParsedDocument("extra" + Integer.toString(i), "extra" + Integer.toString(i), "test", null, -1, -1, testDocument(), new BytesArray("[ FD ]
Line_66 $$ Engine.Index firstIndexRequest = new Engine.Index(newUid(Integer.toString(i)), doc, Versions.MATCH_DELETED, VersionType.INTERNAL, PRIMARY, System.nanoTime())-->Line_68 $$ assertThat(firstIndexRequest.version(), equalTo(1l))[ FD ]
Line_20 $$ Path[] list = filterExtraFSFiles(FileSystemUtils.files(unzipDataDir))-->Line_22 $$ throw new IllegalStateException("Backwards index must contain exactly one cluster but was " + list.length + " " + Arrays.toString(list))[ FD ]
Line_39 $$ for (int i = 0; i < iters; i++) -->Line_65 $$ ParsedDocument doc = testParsedDocument("extra" + Integer.toString(i), "extra" + Integer.toString(i), "test", null, -1, -1, testDocument(), new BytesArray("[ FD ]
Line_10 $$ for (Path indexFile : indexes.subList(0, scaledRandomIntBetween(1, indexes.size() / 2))) -->Line_11 $$ final String indexName = indexFile.getFileName().toString().replace(".zip", "").toLowerCase(Locale.ROOT)[ FD ]
Line_4 $$ try (DirectoryStream<Path> stream = Files.newDirectoryStream(getBwcIndicesPath(), "index-*.zip")) -->Line_16 $$ TestUtil.unzip(stream, unzipDir)[ FD ]
Line_2 $$ public void testUpgradeOldIndex() throws IOException -->Line_3 $$ List<Path> indexes = new ArrayList()[ CD ]
Line_51 $$ Map<String, String> userData = commitStats.getUserData()-->Line_53 $$ assertTrue("userdata doesn't contain generation key", userData.containsKey(Translog.TRANSLOG_GENERATION_KEY))[ FD ]
Line_12 $$ Path unzipDir = createTempDir()-->Line_13 $$ Path unzipDataDir = unzipDir.resolve("data")[ FD ]
Line_64 $$ for (int i = 0; i < numExtraDocs; i++) -->Line_68 $$ assertThat(firstIndexRequest.version(), equalTo(1l))[ CD ]
Line_63 $$ final int numExtraDocs = randomIntBetween(1, 10)-->Line_64 $$ for (int i = 0; i < numExtraDocs; i++) [ FD ]
Line_64 $$ for (int i = 0; i < numExtraDocs; i++) -->Line_66 $$ Engine.Index firstIndexRequest = new Engine.Index(newUid(Integer.toString(i)), doc, Versions.MATCH_DELETED, VersionType.INTERNAL, PRIMARY, System.nanoTime())[ FD ]
Line_36 $$ Store store = createStore(directory)-->Line_57 $$ try (InternalEngine engine = createEngine(store, translog)) [ FD ]
Line_42 $$ try (Searcher searcher = engine.acquireSearcher("test")) -->Line_60 $$ numDocs = searcher.reader().numDocs()[ FD ]
Line_57 $$ try (InternalEngine engine = createEngine(store, translog)) -->Line_70 $$ engine.refresh("test")[ FD ]
Line_47 $$ numDocs = searcher.reader().numDocs()-->Line_72 $$ TopDocs topDocs = searcher.searcher().search(new MatchAllDocsQuery(), randomIntBetween(numDocs, numDocs + numExtraDocs))[ FD ]
Line_26 $$ Path translog = list[0].resolve("nodes/0/indices/" + indexName).resolve("0").resolve("translog")-->Line_57 $$ try (InternalEngine engine = createEngine(store, translog)) [ FD ]
Line_26 $$ Path translog = list[0].resolve("nodes/0/indices/" + indexName).resolve("0").resolve("translog")-->Line_28 $$ assertTrue("[" + indexFile + "] missing translog dir: " + translog.toString(), Files.exists(translog))[ FD ]
Line_38 $$ int numDocs = -1-->Line_72 $$ TopDocs topDocs = searcher.searcher().search(new MatchAllDocsQuery(), randomIntBetween(numDocs, numDocs + numExtraDocs))[ FD ]
Line_35 $$ Directory directory = newFSDirectory(src.resolve("0").resolve("index"))-->Line_76 $$ IOUtils.close(store, directory)[ FD ]
Line_37 $$ final int iters = randomIntBetween(0, 2)-->Line_39 $$ for (int i = 0; i < iters; i++) [ FD ]
Line_35 $$ Directory directory = newFSDirectory(src.resolve("0").resolve("index"))-->Line_36 $$ Store store = createStore(directory)[ FD ]
Line_38 $$ int numDocs = -1-->Line_60 $$ numDocs = searcher.reader().numDocs()[ FD ]
Line_38 $$ int numDocs = -1-->Line_58 $$ if (numDocs == -1) [ FD ]
Line_38 $$ int numDocs = -1-->Line_47 $$ numDocs = searcher.reader().numDocs()[ FD ]
Line_3 $$ List<Path> indexes = new ArrayList()-->Line_6 $$ indexes.add(path)[ FD ]
Line_12 $$ Path unzipDir = createTempDir()-->Line_16 $$ TestUtil.unzip(stream, unzipDir)[ FD ]
Line_64 $$ for (int i = 0; i < numExtraDocs; i++) -->Line_67 $$ engine.index(firstIndexRequest)[ CD ]
Line_51 $$ Map<String, String> userData = commitStats.getUserData()-->Line_54 $$ assertFalse("userdata contains legacy marker", userData.containsKey("translog_id"))[ FD ]
Line_60 $$ numDocs = searcher.reader().numDocs()-->Line_72 $$ TopDocs topDocs = searcher.searcher().search(new MatchAllDocsQuery(), randomIntBetween(numDocs, numDocs + numExtraDocs))[ FD ]
Line_42 $$ try (Searcher searcher = engine.acquireSearcher("test")) -->Line_47 $$ numDocs = searcher.reader().numDocs()[ FD ]
Line_13 $$ Path unzipDataDir = unzipDir.resolve("data")-->Line_20 $$ Path[] list = filterExtraFSFiles(FileSystemUtils.files(unzipDataDir))[ FD ]
Line_33 $$ final long size = Files.size(tlogFiles[0])-->Line_34 $$ logger.debug("upgrading index [ FD ]
Line_59 $$ try (Searcher searcher = engine.acquireSearcher("test")) -->Line_60 $$ numDocs = searcher.reader().numDocs()[ FD ]
Line_39 $$ for (int i = 0; i < iters; i++) -->Line_66 $$ Engine.Index firstIndexRequest = new Engine.Index(newUid(Integer.toString(i)), doc, Versions.MATCH_DELETED, VersionType.INTERNAL, PRIMARY, System.nanoTime())[ FD ]
Line_36 $$ Store store = createStore(directory)-->Line_76 $$ IOUtils.close(store, directory)[ FD ]
Line_5 $$ for (Path path : stream) -->Line_6 $$ indexes.add(path)[ FD ]
Line_2 $$ public void testUpgradeOldIndex() throws IOException -->Line_9 $$ Collections.shuffle(indexes, random())[ CD ]
Line_50 $$ CommitStats commitStats = engine.commitStats()-->Line_51 $$ Map<String, String> userData = commitStats.getUserData()[ FD ]
