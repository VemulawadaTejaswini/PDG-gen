Line_23 $$ if (renameOutputs) -->Line_25 $$ localMapFiles.put(classicAttemptID, renamed)[ CD ]
Line_2 $$ private void runSubtask(org.apache.hadoop.mapred.Task task, final TaskType taskType, TaskAttemptId attemptID, final int numMapTasks, boolean renameOutputs, Map<TaskAttemptID, MapOutputFile> localMapFiles) throws RuntimeException, IOException -->Line_9 $$ conf.setInt(JobContext.TASK_PARTITION, task.getPartition())[ FD ]
Line_5 $$ JobConf conf = new JobConf(getConfig())-->Line_38 $$ conf.set(MRConfig.MASTER_ADDRESS, "local")[ FD ]
Line_54 $$ if (task != null) -->Line_55 $$ task.taskCleanup(umbilical)[ CD ]
Line_2 $$ private void runSubtask(org.apache.hadoop.mapred.Task task, final TaskType taskType, TaskAttemptId attemptID, final int numMapTasks, boolean renameOutputs, Map<TaskAttemptID, MapOutputFile> localMapFiles) throws RuntimeException, IOException -->Line_55 $$ task.taskCleanup(umbilical)[ FD ]
Line_5 $$ JobConf conf = new JobConf(getConfig())-->Line_12 $$ conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs)[ FD ]
Line_5 $$ JobConf conf = new JobConf(getConfig())-->Line_7 $$ conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString())[ FD ]
Line_3 $$ org.apache.hadoop.mapred.TaskAttemptID classicAttemptID = TypeConverter.fromYarn(attemptID)-->Line_60 $$ umbilical.reportDiagnosticInfo(classicAttemptID, StringUtils.stringifyException(exception))[ FD ]
Line_3 $$ org.apache.hadoop.mapred.TaskAttemptID classicAttemptID = TypeConverter.fromYarn(attemptID)-->Line_67 $$ umbilical.fatalError(classicAttemptID, cause)[ FD ]
Line_15 $$ if (taskType == TaskType.MAP) -->Line_20 $$ MapTask map = (MapTask) task[ CD ]
Line_15 $$ if (taskType == TaskType.MAP) -->Line_16 $$ if (doneWithMaps) [ CD ]
Line_64 $$ if (!ShutdownHookManager.get().isShutdownInProgress()) -->Line_67 $$ umbilical.fatalError(classicAttemptID, cause)[ CD ]
Line_5 $$ JobConf conf = new JobConf(getConfig())-->Line_9 $$ conf.setInt(JobContext.TASK_PARTITION, task.getPartition())[ FD ]
Line_5 $$ JobConf conf = new JobConf(getConfig())-->Line_22 $$ map.run(conf, umbilical)[ FD ]
Line_5 $$ JobConf conf = new JobConf(getConfig())-->Line_24 $$ MapOutputFile renamed = renameMapOutputForReduce(conf, attemptID, map.getMapOutputFile())[ FD ]
Line_2 $$ private void runSubtask(org.apache.hadoop.mapred.Task task, final TaskType taskType, TaskAttemptId attemptID, final int numMapTasks, boolean renameOutputs, Map<TaskAttemptID, MapOutputFile> localMapFiles) throws RuntimeException, IOException -->Line_25 $$ localMapFiles.put(classicAttemptID, renamed)[ FD ]
Line_15 $$ if (taskType == TaskType.MAP) -->Line_40 $$ reduce.setLocalMapFiles(localMapFiles)[ CD ]
Line_5 $$ JobConf conf = new JobConf(getConfig())-->Line_6 $$ conf.set(JobContext.TASK_ID, task.getTaskID().toString())[ FD ]
Line_5 $$ JobConf conf = new JobConf(getConfig())-->Line_14 $$ conf.setBoolean("mapreduce.task.uberized", true)[ FD ]
Line_15 $$ if (taskType == TaskType.MAP) -->Line_41 $$ reduce.setConf(conf)[ CD ]
Line_3 $$ org.apache.hadoop.mapred.TaskAttemptID classicAttemptID = TypeConverter.fromYarn(attemptID)-->Line_7 $$ conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString())[ FD ]
Line_15 $$ if (taskType == TaskType.MAP) -->Line_37 $$ conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME)[ CD ]
Line_2 $$ private void runSubtask(org.apache.hadoop.mapred.Task task, final TaskType taskType, TaskAttemptId attemptID, final int numMapTasks, boolean renameOutputs, Map<TaskAttemptID, MapOutputFile> localMapFiles) throws RuntimeException, IOException -->Line_28 $$ if (++finishedSubMaps == numMapTasks) [ FD ]
Line_15 $$ if (taskType == TaskType.MAP) -->Line_21 $$ map.setConf(conf)[ CD ]
Line_2 $$ private void runSubtask(org.apache.hadoop.mapred.Task task, final TaskType taskType, TaskAttemptId attemptID, final int numMapTasks, boolean renameOutputs, Map<TaskAttemptID, MapOutputFile> localMapFiles) throws RuntimeException, IOException -->Line_3 $$ org.apache.hadoop.mapred.TaskAttemptID classicAttemptID = TypeConverter.fromYarn(attemptID)[ FD ]
Line_20 $$ MapTask map = (MapTask) task-->Line_22 $$ map.run(conf, umbilical)[ FD ]
Line_5 $$ JobConf conf = new JobConf(getConfig())-->Line_42 $$ reduce.run(conf, umbilical)[ FD ]
Line_64 $$ if (!ShutdownHookManager.get().isShutdownInProgress()) -->Line_65 $$ Throwable tCause = throwable.getCause()[ CD ]
Line_64 $$ if (!ShutdownHookManager.get().isShutdownInProgress()) -->Line_66 $$ String cause = (tCause == null) ? throwable.getMessage() : StringUtils.stringifyException(tCause)[ CD ]
Line_39 $$ ReduceTask reduce = (ReduceTask) task-->Line_42 $$ reduce.run(conf, umbilical)[ FD ]
Line_15 $$ if (taskType == TaskType.MAP) -->Line_38 $$ conf.set(MRConfig.MASTER_ADDRESS, "local")[ CD ]
Line_15 $$ if (taskType == TaskType.MAP) -->Line_42 $$ reduce.run(conf, umbilical)[ CD ]
Line_2 $$ private void runSubtask(org.apache.hadoop.mapred.Task task, final TaskType taskType, TaskAttemptId attemptID, final int numMapTasks, boolean renameOutputs, Map<TaskAttemptID, MapOutputFile> localMapFiles) throws RuntimeException, IOException -->Line_15 $$ if (taskType == TaskType.MAP) [ FD ]
Line_33 $$ if (!doneWithMaps) -->Line_34 $$ LOG.error("CONTAINER_REMOTE_LAUNCH contains a reduce task (" + attemptID + "), but not yet finished with maps")[ CD ]
Line_15 $$ if (taskType == TaskType.MAP) -->Line_39 $$ ReduceTask reduce = (ReduceTask) task[ CD ]
Line_15 $$ if (taskType == TaskType.MAP) -->Line_43 $$ relocalize()[ CD ]
Line_5 $$ JobConf conf = new JobConf(getConfig())-->Line_10 $$ conf.set(JobContext.ID, task.getJobID().toString())[ FD ]
Line_47 $$ if (!ShutdownHookManager.get().isShutdownInProgress()) -->Line_48 $$ umbilical.fsError(classicAttemptID, e.getMessage())[ CD ]
Line_20 $$ MapTask map = (MapTask) task-->Line_21 $$ map.setConf(conf)[ FD ]
Line_11 $$ String[] localSysDirs = StringUtils.getTrimmedStrings(System.getenv(Environment.LOCAL_DIRS.name()))-->Line_12 $$ conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs)[ FD ]
Line_5 $$ JobConf conf = new JobConf(getConfig())-->Line_8 $$ conf.setBoolean(JobContext.TASK_ISMAP, (taskType == TaskType.MAP))[ FD ]
Line_65 $$ Throwable tCause = throwable.getCause()-->Line_66 $$ String cause = (tCause == null) ? throwable.getMessage() : StringUtils.stringifyException(tCause)[ FD ]
Line_66 $$ String cause = (tCause == null) ? throwable.getMessage() : StringUtils.stringifyException(tCause)-->Line_67 $$ umbilical.fatalError(classicAttemptID, cause)[ FD ]
Line_24 $$ MapOutputFile renamed = renameMapOutputForReduce(conf, attemptID, map.getMapOutputFile())-->Line_25 $$ localMapFiles.put(classicAttemptID, renamed)[ FD ]
Line_2 $$ private void runSubtask(org.apache.hadoop.mapred.Task task, final TaskType taskType, TaskAttemptId attemptID, final int numMapTasks, boolean renameOutputs, Map<TaskAttemptID, MapOutputFile> localMapFiles) throws RuntimeException, IOException -->Line_40 $$ reduce.setLocalMapFiles(localMapFiles)[ FD ]
Line_2 $$ private void runSubtask(org.apache.hadoop.mapred.Task task, final TaskType taskType, TaskAttemptId attemptID, final int numMapTasks, boolean renameOutputs, Map<TaskAttemptID, MapOutputFile> localMapFiles) throws RuntimeException, IOException -->Line_3 $$ org.apache.hadoop.mapred.TaskAttemptID classicAttemptID = TypeConverter.fromYarn(attemptID)[ CD ]
Line_5 $$ JobConf conf = new JobConf(getConfig())-->Line_41 $$ reduce.setConf(conf)[ FD ]
Line_15 $$ if (taskType == TaskType.MAP) -->Line_23 $$ if (renameOutputs) [ CD ]
Line_2 $$ private void runSubtask(org.apache.hadoop.mapred.Task task, final TaskType taskType, TaskAttemptId attemptID, final int numMapTasks, boolean renameOutputs, Map<TaskAttemptID, MapOutputFile> localMapFiles) throws RuntimeException, IOException -->Line_6 $$ conf.set(JobContext.TASK_ID, task.getTaskID().toString())[ FD ]
Line_2 $$ private void runSubtask(org.apache.hadoop.mapred.Task task, final TaskType taskType, TaskAttemptId attemptID, final int numMapTasks, boolean renameOutputs, Map<TaskAttemptID, MapOutputFile> localMapFiles) throws RuntimeException, IOException -->Line_10 $$ conf.set(JobContext.ID, task.getJobID().toString())[ FD ]
Line_15 $$ if (taskType == TaskType.MAP) -->Line_33 $$ if (!doneWithMaps) [ CD ]
Line_3 $$ org.apache.hadoop.mapred.TaskAttemptID classicAttemptID = TypeConverter.fromYarn(attemptID)-->Line_48 $$ umbilical.fsError(classicAttemptID, e.getMessage())[ FD ]
Line_2 $$ private void runSubtask(org.apache.hadoop.mapred.Task task, final TaskType taskType, TaskAttemptId attemptID, final int numMapTasks, boolean renameOutputs, Map<TaskAttemptID, MapOutputFile> localMapFiles) throws RuntimeException, IOException -->Line_54 $$ if (task != null) [ FD ]
Line_20 $$ MapTask map = (MapTask) task-->Line_24 $$ MapOutputFile renamed = renameMapOutputForReduce(conf, attemptID, map.getMapOutputFile())[ FD ]
Line_5 $$ JobConf conf = new JobConf(getConfig())-->Line_37 $$ conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME)[ FD ]
Line_5 $$ JobConf conf = new JobConf(getConfig())-->Line_21 $$ map.setConf(conf)[ FD ]
Line_5 $$ JobConf conf = new JobConf(getConfig())-->Line_13 $$ LOG.info(MRConfig.LOCAL_DIR + " for uber task: " + conf.get(MRConfig.LOCAL_DIR))[ FD ]
Line_3 $$ org.apache.hadoop.mapred.TaskAttemptID classicAttemptID = TypeConverter.fromYarn(attemptID)-->Line_25 $$ localMapFiles.put(classicAttemptID, renamed)[ FD ]
Line_39 $$ ReduceTask reduce = (ReduceTask) task-->Line_40 $$ reduce.setLocalMapFiles(localMapFiles)[ FD ]
Line_2 $$ private void runSubtask(org.apache.hadoop.mapred.Task task, final TaskType taskType, TaskAttemptId attemptID, final int numMapTasks, boolean renameOutputs, Map<TaskAttemptID, MapOutputFile> localMapFiles) throws RuntimeException, IOException -->Line_24 $$ MapOutputFile renamed = renameMapOutputForReduce(conf, attemptID, map.getMapOutputFile())[ FD ]
Line_15 $$ if (taskType == TaskType.MAP) -->Line_28 $$ if (++finishedSubMaps == numMapTasks) [ CD ]
Line_16 $$ if (doneWithMaps) -->Line_17 $$ LOG.error("CONTAINER_REMOTE_LAUNCH contains a map task (" + attemptID + "), but should be finished with maps")[ CD ]
Line_39 $$ ReduceTask reduce = (ReduceTask) task-->Line_41 $$ reduce.setConf(conf)[ FD ]
Line_15 $$ if (taskType == TaskType.MAP) -->Line_27 $$ relocalize()[ CD ]
Line_23 $$ if (renameOutputs) -->Line_24 $$ MapOutputFile renamed = renameMapOutputForReduce(conf, attemptID, map.getMapOutputFile())[ CD ]
Line_15 $$ if (taskType == TaskType.MAP) -->Line_22 $$ map.run(conf, umbilical)[ CD ]
