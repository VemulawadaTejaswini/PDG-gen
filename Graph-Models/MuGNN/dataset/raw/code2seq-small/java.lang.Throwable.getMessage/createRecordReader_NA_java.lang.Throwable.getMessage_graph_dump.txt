Line_2 $$ public static RecordReader<?, ?> createRecordReader(Configuration configuration, Path path, long start, long length, Properties schema, List<HiveColumnHandle> columns) -->Line_4 $$ List<Integer> readHiveColumnIndexes = ImmutableList.copyOf(transform(readColumns, HiveColumnHandle::<>getHiveColumnIndex))[ CD ]
Line_8 $$ FileSplit fileSplit = new FileSplit(path, start, length, (String[]) null)-->Line_11 $$ inputFormat.getRecordReader(fileSplit, jobConf, Reporter.NULL)[ FD ]
Line_7 $$ JobConf jobConf = new JobConf(configuration)-->Line_9 $$ jobConf.set(name, schema.getProperty(name))[ FD ]
Line_2 $$ public static RecordReader<?, ?> createRecordReader(Configuration configuration, Path path, long start, long length, Properties schema, List<HiveColumnHandle> columns) -->Line_5 $$ setReadColumns(configuration, readHiveColumnIndexes)[ CD ]
Line_2 $$ public static RecordReader<?, ?> createRecordReader(Configuration configuration, Path path, long start, long length, Properties schema, List<HiveColumnHandle> columns) -->Line_3 $$ List<HiveColumnHandle> readColumns = ImmutableList.copyOf(filter(columns, not(HiveColumnHandle::<>isPartitionKey)))[ FD ]
Line_2 $$ public static RecordReader<?, ?> createRecordReader(Configuration configuration, Path path, long start, long length, Properties schema, List<HiveColumnHandle> columns) -->Line_6 $$ InputFormat<?, ?> inputFormat = getInputFormat(configuration, schema, true)[ CD ]
Line_2 $$ public static RecordReader<?, ?> createRecordReader(Configuration configuration, Path path, long start, long length, Properties schema, List<HiveColumnHandle> columns) -->Line_9 $$ jobConf.set(name, schema.getProperty(name))[ FD ]
Line_2 $$ public static RecordReader<?, ?> createRecordReader(Configuration configuration, Path path, long start, long length, Properties schema, List<HiveColumnHandle> columns) -->Line_13 $$ throw new PrestoException(HIVE_CANNOT_OPEN_SPLIT, format("Error opening Hive split %s (offset=%s, length=%s) using %s: %s", path, start, length, getInputFormatName(schema), e.getMessage()), e)[ FD ]
Line_7 $$ JobConf jobConf = new JobConf(configuration)-->Line_11 $$ inputFormat.getRecordReader(fileSplit, jobConf, Reporter.NULL)[ FD ]
Line_2 $$ public static RecordReader<?, ?> createRecordReader(Configuration configuration, Path path, long start, long length, Properties schema, List<HiveColumnHandle> columns) -->Line_8 $$ FileSplit fileSplit = new FileSplit(path, start, length, (String[]) null)[ CD ]
Line_2 $$ public static RecordReader<?, ?> createRecordReader(Configuration configuration, Path path, long start, long length, Properties schema, List<HiveColumnHandle> columns) -->Line_9 $$ schema.stringPropertyNames().stream().filter( name -> name.startsWith("serialization.")).forEach( name -> jobConf.set(name, schema.getProperty(name)))[ FD ]
Line_2 $$ public static RecordReader<?, ?> createRecordReader(Configuration configuration, Path path, long start, long length, Properties schema, List<HiveColumnHandle> columns) -->Line_6 $$ InputFormat<?, ?> inputFormat = getInputFormat(configuration, schema, true)[ FD ]
Line_2 $$ public static RecordReader<?, ?> createRecordReader(Configuration configuration, Path path, long start, long length, Properties schema, List<HiveColumnHandle> columns) -->Line_3 $$ List<HiveColumnHandle> readColumns = ImmutableList.copyOf(filter(columns, not(HiveColumnHandle::<>isPartitionKey)))[ CD ]
Line_2 $$ public static RecordReader<?, ?> createRecordReader(Configuration configuration, Path path, long start, long length, Properties schema, List<HiveColumnHandle> columns) -->Line_7 $$ JobConf jobConf = new JobConf(configuration)[ CD ]
Line_2 $$ public static RecordReader<?, ?> createRecordReader(Configuration configuration, Path path, long start, long length, Properties schema, List<HiveColumnHandle> columns) -->Line_9 $$ schema.stringPropertyNames().stream().filter( name -> name.startsWith("serialization.")).forEach( name -> jobConf.set(name, schema.getProperty(name)))[ CD ]
Line_6 $$ InputFormat<?, ?> inputFormat = getInputFormat(configuration, schema, true)-->Line_11 $$ inputFormat.getRecordReader(fileSplit, jobConf, Reporter.NULL)[ FD ]
Line_4 $$ List<Integer> readHiveColumnIndexes = ImmutableList.copyOf(transform(readColumns, HiveColumnHandle::<>getHiveColumnIndex))-->Line_5 $$ setReadColumns(configuration, readHiveColumnIndexes)[ FD ]
Line_2 $$ public static RecordReader<?, ?> createRecordReader(Configuration configuration, Path path, long start, long length, Properties schema, List<HiveColumnHandle> columns) -->Line_5 $$ setReadColumns(configuration, readHiveColumnIndexes)[ FD ]
Line_3 $$ List<HiveColumnHandle> readColumns = ImmutableList.copyOf(filter(columns, not(HiveColumnHandle::<>isPartitionKey)))-->Line_4 $$ List<Integer> readHiveColumnIndexes = ImmutableList.copyOf(transform(readColumns, HiveColumnHandle::<>getHiveColumnIndex))[ FD ]
