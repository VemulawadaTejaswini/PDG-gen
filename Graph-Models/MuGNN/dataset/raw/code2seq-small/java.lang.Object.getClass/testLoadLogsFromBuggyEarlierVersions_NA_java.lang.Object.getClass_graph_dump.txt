Line_6 $$ File dfsDir = new File(testDir, "image-with-buggy-append")-->Line_7 $$ if (dfsDir.exists() && !FileUtil.fullyDelete(dfsDir)) [ FD ]
Line_16 $$ FileSystem fs = cluster.getFileSystem()-->Line_18 $$ assertEquals(2 * 1024 * 1024, fs.getFileStatus(testPath).getLen())[ FD ]
Line_2 $$ public void testLoadLogsFromBuggyEarlierVersions() throws IOException -->Line_7 $$ if (dfsDir.exists() && !FileUtil.fullyDelete(dfsDir)) [ CD ]
Line_2 $$ public void testLoadLogsFromBuggyEarlierVersions() throws IOException -->Line_6 $$ File dfsDir = new File(testDir, "image-with-buggy-append")[ CD ]
Line_14 $$ MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(0).format(false).manageDataDfsDirs(false).manageNameDfsDirs(false).numDataNodes(0).waitSafeMode(false).startupOption(StartupOption.UPGRADE).build()-->Line_20 $$ cluster.shutdown()[ FD ]
Line_2 $$ public void testLoadLogsFromBuggyEarlierVersions() throws IOException -->Line_3 $$ final Configuration conf = new HdfsConfiguration()[ CD ]
Line_2 $$ public void testLoadLogsFromBuggyEarlierVersions() throws IOException -->Line_13 $$ conf.set(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY, nameDir.getAbsolutePath())[ CD ]
Line_2 $$ public void testLoadLogsFromBuggyEarlierVersions() throws IOException -->Line_5 $$ String testDir = PathUtils.getTestDirName(getClass())[ CD ]
Line_2 $$ public void testLoadLogsFromBuggyEarlierVersions() throws IOException -->Line_11 $$ File nameDir = new File(dfsDir, "name")[ CD ]
Line_3 $$ final Configuration conf = new HdfsConfiguration()-->Line_13 $$ conf.set(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY, nameDir.getAbsolutePath())[ FD ]
Line_11 $$ File nameDir = new File(dfsDir, "name")-->Line_13 $$ conf.set(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY, nameDir.getAbsolutePath())[ FD ]
Line_2 $$ public void testLoadLogsFromBuggyEarlierVersions() throws IOException -->Line_14 $$ MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(0).format(false).manageDataDfsDirs(false).manageNameDfsDirs(false).numDataNodes(0).waitSafeMode(false).startupOption(StartupOption.UPGRADE).build()[ CD ]
Line_2 $$ public void testLoadLogsFromBuggyEarlierVersions() throws IOException -->Line_12 $$ GenericTestUtils.assertExists(nameDir)[ CD ]
Line_11 $$ File nameDir = new File(dfsDir, "name")-->Line_12 $$ GenericTestUtils.assertExists(nameDir)[ FD ]
Line_2 $$ public void testLoadLogsFromBuggyEarlierVersions() throws IOException -->Line_10 $$ FileUtil.unTar(new File(tarFile), new File(testDir))[ CD ]
Line_17 $$ Path testPath = new Path("/tmp/io_data/test_io_0")-->Line_18 $$ assertEquals(2 * 1024 * 1024, fs.getFileStatus(testPath).getLen())[ FD ]
Line_14 $$ MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(0).format(false).manageDataDfsDirs(false).manageNameDfsDirs(false).numDataNodes(0).waitSafeMode(false).startupOption(StartupOption.UPGRADE).build()-->Line_16 $$ FileSystem fs = cluster.getFileSystem()[ FD ]
Line_2 $$ public void testLoadLogsFromBuggyEarlierVersions() throws IOException -->Line_4 $$ String tarFile = System.getProperty("test.cache.data", "build/test/cache") + "/" + HADOOP_23_BROKEN_APPEND_TGZ[ CD ]
