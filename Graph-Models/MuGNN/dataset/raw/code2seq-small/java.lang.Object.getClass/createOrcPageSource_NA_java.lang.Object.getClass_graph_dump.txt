Line_2 $$ public static OrcPageSource createOrcPageSource(MetadataReader metadataReader, Configuration configuration, Path path, long start, long length, List<HiveColumnHandle> columns, List<HivePartitionKey> partitionKeys, TupleDomain<HiveColumnHandle> effectivePredicate, DateTimeZone hiveStorageTimeZone, TypeManager typeManager, DataSize maxMergeDistance, DataSize maxBufferSize, DataSize streamBufferSize) -->Line_13 $$ throw new PrestoException(HIVE_CANNOT_OPEN_SPLIT, splitError(e, path, start, length), e)[ FD ]
Line_18 $$ if (!column.isPartitionKey()) -->Line_21 $$ columnReferences.add(new ColumnReference(column, column.getHiveColumnIndex(), type))[ CD ]
Line_2 $$ public static OrcPageSource createOrcPageSource(MetadataReader metadataReader, Configuration configuration, Path path, long start, long length, List<HiveColumnHandle> columns, List<HivePartitionKey> partitionKeys, TupleDomain<HiveColumnHandle> effectivePredicate, DateTimeZone hiveStorageTimeZone, TypeManager typeManager, DataSize maxMergeDistance, DataSize maxBufferSize, DataSize streamBufferSize) -->Line_5 $$ FileSystem fileSystem = path.getFileSystem(configuration)[ FD ]
Line_2 $$ public static OrcPageSource createOrcPageSource(MetadataReader metadataReader, Configuration configuration, Path path, long start, long length, List<HiveColumnHandle> columns, List<HivePartitionKey> partitionKeys, TupleDomain<HiveColumnHandle> effectivePredicate, DateTimeZone hiveStorageTimeZone, TypeManager typeManager, DataSize maxMergeDistance, DataSize maxBufferSize, DataSize streamBufferSize) -->Line_25 $$ AggregatedMemoryContext systemMemoryUsage = new AggregatedMemoryContext()[ CD ]
Line_18 $$ if (!column.isPartitionKey()) -->Line_20 $$ includedColumns.put(column.getHiveColumnIndex(), type)[ CD ]
Line_2 $$ public static OrcPageSource createOrcPageSource(MetadataReader metadataReader, Configuration configuration, Path path, long start, long length, List<HiveColumnHandle> columns, List<HivePartitionKey> partitionKeys, TupleDomain<HiveColumnHandle> effectivePredicate, DateTimeZone hiveStorageTimeZone, TypeManager typeManager, DataSize maxMergeDistance, DataSize maxBufferSize, DataSize streamBufferSize) -->Line_3 $$ OrcDataSource orcDataSource[ CD ]
Line_5 $$ FileSystem fileSystem = path.getFileSystem(configuration)-->Line_7 $$ FSDataInputStream inputStream = fileSystem.open(path)[ FD ]
Line_3 $$ OrcDataSource orcDataSource-->Line_8 $$ orcDataSource = new HdfsOrcDataSource(path.toString(), size, maxMergeDistance, maxBufferSize, streamBufferSize, inputStream)[ FD ]
Line_19 $$ Type type = typeManager.getType(column.getTypeSignature())-->Line_20 $$ includedColumns.put(column.getHiveColumnIndex(), type)[ FD ]
Line_16 $$ ImmutableList.Builder<ColumnReference<HiveColumnHandle>> columnReferences = ImmutableList.builder()-->Line_24 $$ OrcPredicate predicate = new TupleDomainOrcPredicate(effectivePredicate, columnReferences.build())[ FD ]
Line_15 $$ ImmutableMap.Builder<Integer, Type> includedColumns = ImmutableMap.builder()-->Line_20 $$ includedColumns.put(column.getHiveColumnIndex(), type)[ FD ]
Line_17 $$ for (HiveColumnHandle column : columns) -->Line_20 $$ includedColumns.put(column.getHiveColumnIndex(), type)[ FD ]
Line_8 $$ orcDataSource = new HdfsOrcDataSource(path.toString(), size, maxMergeDistance, maxBufferSize, streamBufferSize, inputStream)-->Line_32 $$ orcDataSource.close()[ FD ]
Line_17 $$ for (HiveColumnHandle column : columns) -->Line_18 $$ if (!column.isPartitionKey()) [ FD ]
Line_17 $$ for (HiveColumnHandle column : columns) -->Line_19 $$ Type type = typeManager.getType(column.getTypeSignature())[ FD ]
Line_2 $$ public static OrcPageSource createOrcPageSource(MetadataReader metadataReader, Configuration configuration, Path path, long start, long length, List<HiveColumnHandle> columns, List<HivePartitionKey> partitionKeys, TupleDomain<HiveColumnHandle> effectivePredicate, DateTimeZone hiveStorageTimeZone, TypeManager typeManager, DataSize maxMergeDistance, DataSize maxBufferSize, DataSize streamBufferSize) -->Line_24 $$ OrcPredicate predicate = new TupleDomainOrcPredicate(effectivePredicate, columnReferences.build())[ CD ]
Line_2 $$ public static OrcPageSource createOrcPageSource(MetadataReader metadataReader, Configuration configuration, Path path, long start, long length, List<HiveColumnHandle> columns, List<HivePartitionKey> partitionKeys, TupleDomain<HiveColumnHandle> effectivePredicate, DateTimeZone hiveStorageTimeZone, TypeManager typeManager, DataSize maxMergeDistance, DataSize maxBufferSize, DataSize streamBufferSize) -->Line_8 $$ orcDataSource = new HdfsOrcDataSource(path.toString(), size, maxMergeDistance, maxBufferSize, streamBufferSize, inputStream)[ FD ]
Line_2 $$ public static OrcPageSource createOrcPageSource(MetadataReader metadataReader, Configuration configuration, Path path, long start, long length, List<HiveColumnHandle> columns, List<HivePartitionKey> partitionKeys, TupleDomain<HiveColumnHandle> effectivePredicate, DateTimeZone hiveStorageTimeZone, TypeManager typeManager, DataSize maxMergeDistance, DataSize maxBufferSize, DataSize streamBufferSize) -->Line_16 $$ ImmutableList.Builder<ColumnReference<HiveColumnHandle>> columnReferences = ImmutableList.builder()[ CD ]
Line_15 $$ ImmutableMap.Builder<Integer, Type> includedColumns = ImmutableMap.builder()-->Line_28 $$ OrcRecordReader recordReader = reader.createRecordReader(includedColumns.build(), predicate, start, length, hiveStorageTimeZone, systemMemoryUsage)[ FD ]
Line_2 $$ public static OrcPageSource createOrcPageSource(MetadataReader metadataReader, Configuration configuration, Path path, long start, long length, List<HiveColumnHandle> columns, List<HivePartitionKey> partitionKeys, TupleDomain<HiveColumnHandle> effectivePredicate, DateTimeZone hiveStorageTimeZone, TypeManager typeManager, DataSize maxMergeDistance, DataSize maxBufferSize, DataSize streamBufferSize) -->Line_6 $$ long size = fileSystem.getFileStatus(path).getLen()[ FD ]
Line_2 $$ public static OrcPageSource createOrcPageSource(MetadataReader metadataReader, Configuration configuration, Path path, long start, long length, List<HiveColumnHandle> columns, List<HivePartitionKey> partitionKeys, TupleDomain<HiveColumnHandle> effectivePredicate, DateTimeZone hiveStorageTimeZone, TypeManager typeManager, DataSize maxMergeDistance, DataSize maxBufferSize, DataSize streamBufferSize) -->Line_7 $$ FSDataInputStream inputStream = fileSystem.open(path)[ FD ]
Line_27 $$ OrcReader reader = new OrcReader(orcDataSource, metadataReader, maxMergeDistance, maxBufferSize)-->Line_28 $$ OrcRecordReader recordReader = reader.createRecordReader(includedColumns.build(), predicate, start, length, hiveStorageTimeZone, systemMemoryUsage)[ FD ]
Line_3 $$ OrcDataSource orcDataSource-->Line_32 $$ orcDataSource.close()[ FD ]
Line_2 $$ public static OrcPageSource createOrcPageSource(MetadataReader metadataReader, Configuration configuration, Path path, long start, long length, List<HiveColumnHandle> columns, List<HivePartitionKey> partitionKeys, TupleDomain<HiveColumnHandle> effectivePredicate, DateTimeZone hiveStorageTimeZone, TypeManager typeManager, DataSize maxMergeDistance, DataSize maxBufferSize, DataSize streamBufferSize) -->Line_19 $$ Type type = typeManager.getType(column.getTypeSignature())[ FD ]
Line_2 $$ public static OrcPageSource createOrcPageSource(MetadataReader metadataReader, Configuration configuration, Path path, long start, long length, List<HiveColumnHandle> columns, List<HivePartitionKey> partitionKeys, TupleDomain<HiveColumnHandle> effectivePredicate, DateTimeZone hiveStorageTimeZone, TypeManager typeManager, DataSize maxMergeDistance, DataSize maxBufferSize, DataSize streamBufferSize) -->Line_38 $$ String message = splitError(e, path, start, length)[ FD ]
Line_2 $$ public static OrcPageSource createOrcPageSource(MetadataReader metadataReader, Configuration configuration, Path path, long start, long length, List<HiveColumnHandle> columns, List<HivePartitionKey> partitionKeys, TupleDomain<HiveColumnHandle> effectivePredicate, DateTimeZone hiveStorageTimeZone, TypeManager typeManager, DataSize maxMergeDistance, DataSize maxBufferSize, DataSize streamBufferSize) -->Line_28 $$ OrcRecordReader recordReader = reader.createRecordReader(includedColumns.build(), predicate, start, length, hiveStorageTimeZone, systemMemoryUsage)[ FD ]
Line_17 $$ for (HiveColumnHandle column : columns) -->Line_21 $$ columnReferences.add(new ColumnReference(column, column.getHiveColumnIndex(), type))[ FD ]
Line_25 $$ AggregatedMemoryContext systemMemoryUsage = new AggregatedMemoryContext()-->Line_28 $$ OrcRecordReader recordReader = reader.createRecordReader(includedColumns.build(), predicate, start, length, hiveStorageTimeZone, systemMemoryUsage)[ FD ]
Line_24 $$ OrcPredicate predicate = new TupleDomainOrcPredicate(effectivePredicate, columnReferences.build())-->Line_28 $$ OrcRecordReader recordReader = reader.createRecordReader(includedColumns.build(), predicate, start, length, hiveStorageTimeZone, systemMemoryUsage)[ FD ]
Line_5 $$ FileSystem fileSystem = path.getFileSystem(configuration)-->Line_6 $$ long size = fileSystem.getFileStatus(path).getLen()[ FD ]
Line_18 $$ if (!column.isPartitionKey()) -->Line_19 $$ Type type = typeManager.getType(column.getTypeSignature())[ CD ]
Line_2 $$ public static OrcPageSource createOrcPageSource(MetadataReader metadataReader, Configuration configuration, Path path, long start, long length, List<HiveColumnHandle> columns, List<HivePartitionKey> partitionKeys, TupleDomain<HiveColumnHandle> effectivePredicate, DateTimeZone hiveStorageTimeZone, TypeManager typeManager, DataSize maxMergeDistance, DataSize maxBufferSize, DataSize streamBufferSize) -->Line_15 $$ ImmutableMap.Builder<Integer, Type> includedColumns = ImmutableMap.builder()[ CD ]
Line_16 $$ ImmutableList.Builder<ColumnReference<HiveColumnHandle>> columnReferences = ImmutableList.builder()-->Line_21 $$ columnReferences.add(new ColumnReference(column, column.getHiveColumnIndex(), type))[ FD ]
