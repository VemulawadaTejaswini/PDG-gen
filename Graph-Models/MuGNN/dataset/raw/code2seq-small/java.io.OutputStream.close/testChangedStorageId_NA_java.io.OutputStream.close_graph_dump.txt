Line_27 $$ newStorageId = getRegisteredDatanodeUid(cluster, 1)-->Line_25 $$ do [ FD ]
Line_5 $$ MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).nnTopology(MiniDFSNNTopology.simpleHATopology()).build()-->Line_16 $$ cluster.restartNameNode(1, false)[ FD ]
Line_5 $$ MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).nnTopology(MiniDFSNNTopology.simpleHATopology()).build()-->Line_31 $$ cluster.transitionToStandby(0)[ FD ]
Line_3 $$ HdfsConfiguration conf = new HdfsConfiguration()-->Line_8 $$ FileSystem fs = HATestUtil.configureFailoverFs(cluster, conf)[ FD ]
Line_5 $$ MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).nnTopology(MiniDFSNNTopology.simpleHATopology()).build()-->Line_18 $$ while (cluster.getNamesystem(1).getBlockManager().getPendingDataNodeMessageCount() < 1) [ FD ]
Line_5 $$ MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).nnTopology(MiniDFSNNTopology.simpleHATopology()).build()-->Line_27 $$ newStorageId = getRegisteredDatanodeUid(cluster, 1)[ FD ]
Line_8 $$ FileSystem fs = HATestUtil.configureFailoverFs(cluster, conf)-->Line_9 $$ OutputStream out = fs.create(filePath)[ FD ]
Line_13 $$ ExtendedBlock block = DFSTestUtil.getFirstBlock(fs, filePath)-->Line_14 $$ assertTrue(MiniDFSCluster.changeGenStampOfBlock(0, block, 900))[ FD ]
Line_5 $$ MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).nnTopology(MiniDFSNNTopology.simpleHATopology()).build()-->Line_17 $$ assertTrue(cluster.restartDataNode(dnProps, true))[ FD ]
Line_5 $$ MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).nnTopology(MiniDFSNNTopology.simpleHATopology()).build()-->Line_7 $$ cluster.transitionToActive(0)[ FD ]
Line_2 $$ public void testChangedStorageId() throws IOException, URISyntaxException, InterruptedException -->Line_5 $$ MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).nnTopology(MiniDFSNNTopology.simpleHATopology()).build()[ CD ]
Line_5 $$ MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).nnTopology(MiniDFSNNTopology.simpleHATopology()).build()-->Line_30 $$ assertEquals(0, cluster.getNamesystem(1).getBlockManager().getPendingDataNodeMessageCount())[ FD ]
Line_24 $$ String newStorageId = ""-->Line_27 $$ newStorageId = getRegisteredDatanodeUid(cluster, 1)[ FD ]
Line_24 $$ String newStorageId = ""-->Line_25 $$ do [ FD ]
Line_9 $$ OutputStream out = fs.create(filePath)-->Line_10 $$ out.write("foo bar baz".getBytes())[ FD ]
Line_5 $$ MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).nnTopology(MiniDFSNNTopology.simpleHATopology()).build()-->Line_21 $$ assertEquals(1, cluster.getNamesystem(1).getBlockManager().getPendingDataNodeMessageCount())[ FD ]
Line_5 $$ MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).nnTopology(MiniDFSNNTopology.simpleHATopology()).build()-->Line_8 $$ FileSystem fs = HATestUtil.configureFailoverFs(cluster, conf)[ FD ]
Line_8 $$ FileSystem fs = HATestUtil.configureFailoverFs(cluster, conf)-->Line_13 $$ ExtendedBlock block = DFSTestUtil.getFirstBlock(fs, filePath)[ FD ]
Line_25 $$ do -->Line_27 $$ newStorageId = getRegisteredDatanodeUid(cluster, 1)[ CD ]
Line_5 $$ MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).nnTopology(MiniDFSNNTopology.simpleHATopology()).build()-->Line_34 $$ cluster.shutdown()[ FD ]
Line_5 $$ MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).nnTopology(MiniDFSNNTopology.simpleHATopology()).build()-->Line_15 $$ DataNodeProperties dnProps = cluster.stopDataNode(0)[ FD ]
Line_9 $$ OutputStream out = fs.create(filePath)-->Line_11 $$ out.close()[ FD ]
Line_3 $$ HdfsConfiguration conf = new HdfsConfiguration()-->Line_4 $$ conf.setInt(DFSConfigKeys.DFS_HA_TAILEDITS_PERIOD_KEY, 1)[ FD ]
Line_18 $$ while (cluster.getNamesystem(1).getBlockManager().getPendingDataNodeMessageCount() < 1) -->Line_19 $$ ThreadUtil.sleepAtLeastIgnoreInterrupts(1000)[ CD ]
Line_22 $$ String oldStorageId = getRegisteredDatanodeUid(cluster, 1)-->Line_25 $$ do [ FD ]
Line_5 $$ MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).nnTopology(MiniDFSNNTopology.simpleHATopology()).build()-->Line_12 $$ HATestUtil.waitForStandbyToCatchUp(cluster.getNameNode(0), cluster.getNameNode(1))[ FD ]
Line_25 $$ do -->Line_28 $$ System.out.println("====> oldStorageId: " + oldStorageId + " newStorageId: " + newStorageId)[ CD ]
Line_5 $$ MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).nnTopology(MiniDFSNNTopology.simpleHATopology()).build()-->Line_32 $$ cluster.transitionToActive(1)[ FD ]
Line_15 $$ DataNodeProperties dnProps = cluster.stopDataNode(0)-->Line_17 $$ assertTrue(cluster.restartDataNode(dnProps, true))[ FD ]
Line_5 $$ MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).nnTopology(MiniDFSNNTopology.simpleHATopology()).build()-->Line_23 $$ assertTrue(wipeAndRestartDn(cluster, 0))[ FD ]
Line_5 $$ MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).nnTopology(MiniDFSNNTopology.simpleHATopology()).build()-->Line_22 $$ String oldStorageId = getRegisteredDatanodeUid(cluster, 1)[ FD ]
Line_25 $$ do -->Line_26 $$ ThreadUtil.sleepAtLeastIgnoreInterrupts(1000)[ CD ]
Line_2 $$ public void testChangedStorageId() throws IOException, URISyntaxException, InterruptedException -->Line_4 $$ conf.setInt(DFSConfigKeys.DFS_HA_TAILEDITS_PERIOD_KEY, 1)[ CD ]
Line_2 $$ public void testChangedStorageId() throws IOException, URISyntaxException, InterruptedException -->Line_3 $$ HdfsConfiguration conf = new HdfsConfiguration()[ CD ]
