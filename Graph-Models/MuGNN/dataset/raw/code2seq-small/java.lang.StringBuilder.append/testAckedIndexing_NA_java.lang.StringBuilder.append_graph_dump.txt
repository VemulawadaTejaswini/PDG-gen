Line_23 $$ Thread thread = new Thread(new Runnable() -->Line_25 $$ while (!stop.get()) [ CD ]
Line_9 $$ final AtomicBoolean stop = new AtomicBoolean(false)-->Line_103 $$ stop.set(true)[ FD ]
Line_6 $$ ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()-->Line_7 $$ logger.info("disruption scheme [[ FD ]
Line_33 $$ id = Integer.toString(idGenerator.incrementAndGet())-->Line_38 $$ ackedDocs.put(id, node)[ FD ]
Line_2 $$ public void testAckedIndexing() throws Exception -->Line_4 $$ assertAcked(prepareCreate("test").setSettings(Settings.builder().put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1 + randomInt(2)).put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(2))))[ CD ]
Line_23 $$ Thread thread = new Thread(new Runnable() -->Line_55 $$ thread.start()[ FD ]
Line_2 $$ public void testAckedIndexing() throws Exception -->Line_10 $$ List<Thread> indexers = new ArrayList(nodes.size())[ CD ]
Line_82 $$ for (String node : nodes) -->Line_86 $$ assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found", client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())[ FD ]
Line_2 $$ public void testAckedIndexing() throws Exception -->Line_12 $$ final AtomicInteger idGenerator = new AtomicInteger(0)[ CD ]
Line_33 $$ id = Integer.toString(idGenerator.incrementAndGet())-->Line_34 $$ int shard = Murmur3HashFunction.hash(id) % numPrimaries[ FD ]
Line_33 $$ id = Integer.toString(idGenerator.incrementAndGet())-->Line_42 $$ logger.trace("[[ FD ]
Line_23 $$ Thread thread = new Thread(new Runnable() -->Line_56 $$ indexers.add(thread)[ FD ]
Line_2 $$ public void testAckedIndexing() throws Exception -->Line_9 $$ final AtomicBoolean stop = new AtomicBoolean(false)[ CD ]
Line_33 $$ id = Integer.toString(idGenerator.incrementAndGet())-->Line_35 $$ logger.trace("[[ FD ]
Line_17 $$ for (final String node : nodes) -->Line_42 $$ logger.trace("[[ FD ]
Line_8 $$ final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap()-->Line_86 $$ assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found", client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())[ FD ]
Line_82 $$ for (String node : nodes) -->Line_84 $$ logger.debug("validating through node [[ FD ]
Line_10 $$ List<Thread> indexers = new ArrayList(nodes.size())-->Line_56 $$ indexers.add(thread)[ FD ]
Line_18 $$ final Semaphore semaphore = new Semaphore(0)-->Line_28 $$ if (!semaphore.tryAcquire(10, TimeUnit.SECONDS)) [ FD ]
Line_18 $$ final Semaphore semaphore = new Semaphore(0)-->Line_31 $$ logger.info("[[ FD ]
Line_17 $$ for (final String node : nodes) -->Line_35 $$ logger.trace("[[ FD ]
Line_3 $$ final List<String> nodes = startCluster(3)-->Line_10 $$ List<Thread> indexers = new ArrayList(nodes.size())[ FD ]
Line_72 $$ for (Semaphore semaphore : semaphores) -->Line_73 $$ assertThat(semaphore.availablePermits(), equalTo(0))[ FD ]
Line_13 $$ final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference()-->Line_70 $$ countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))[ FD ]
Line_2 $$ public void testAckedIndexing() throws Exception -->Line_14 $$ final List<Exception> exceptedExceptions = Collections.synchronizedList(new ArrayList<Exception>())[ CD ]
Line_23 $$ Thread thread = new Thread(new Runnable() -->Line_54 $$ thread.setName(name)[ FD ]
Line_13 $$ final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference()-->Line_60 $$ countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))[ FD ]
Line_18 $$ final Semaphore semaphore = new Semaphore(0)-->Line_19 $$ semaphores.add(semaphore)[ FD ]
Line_13 $$ final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference()-->Line_44 $$ countDownLatchRef.get().countDown()[ FD ]
Line_21 $$ final String name = "indexer_" + indexers.size()-->Line_42 $$ logger.trace("[[ FD ]
Line_65 $$ for (int iter = 1 + randomInt(2); iter > 0; iter--) -->Line_69 $$ logger.info("indexing " + docsPerIndexer + " docs per indexer during partition")[ CD ]
Line_21 $$ final String name = "indexer_" + indexers.size()-->Line_39 $$ logger.trace("[[ FD ]
Line_13 $$ final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference()-->Line_76 $$ assertTrue(countDownLatchRef.get().await(60000 + disruptionScheme.expectedTimeToHeal().millis() * (docsPerIndexer * indexers.size()), TimeUnit.MILLISECONDS))[ FD ]
Line_65 $$ for (int iter = 1 + randomInt(2); iter > 0; iter--) -->Line_66 $$ logger.info("starting disruptions & indexing (iteration [[ FD ]
Line_26 $$ String id = null-->Line_39 $$ logger.trace("[[ FD ]
Line_2 $$ public void testAckedIndexing() throws Exception -->Line_15 $$ logger.info("starting indexers")[ CD ]
Line_36 $$ IndexResponse response = client.prepareIndex("test", "type", id).setSource("-->Line_37 $$ assertThat(response.getVersion(), equalTo(1l))[ FD ]
Line_26 $$ String id = null-->Line_34 $$ int shard = Murmur3HashFunction.hash(id) % numPrimaries[ FD ]
Line_26 $$ String id = null-->Line_33 $$ id = Integer.toString(idGenerator.incrementAndGet())[ FD ]
Line_17 $$ for (final String node : nodes) -->Line_84 $$ logger.debug("validating through node [[ FD ]
Line_26 $$ String id = null-->Line_36 $$ IndexResponse response = client.prepareIndex("test", "type", id).setSource("[ FD ]
Line_65 $$ for (int iter = 1 + randomInt(2); iter > 0; iter--) -->Line_67 $$ disruptionScheme.startDisrupting()[ CD ]
Line_18 $$ final Semaphore semaphore = new Semaphore(0)-->Line_73 $$ assertThat(semaphore.availablePermits(), equalTo(0))[ FD ]
Line_17 $$ for (final String node : nodes) -->Line_39 $$ logger.trace("[[ FD ]
Line_20 $$ final Client client = client(node)-->Line_36 $$ IndexResponse response = client.prepareIndex("test", "type", id).setSource("[ FD ]
Line_17 $$ for (final String node : nodes) -->Line_20 $$ final Client client = client(node)[ FD ]
Line_85 $$ for (String id : ackedDocs.keySet()) -->Line_86 $$ assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found", client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())[ FD ]
Line_9 $$ final AtomicBoolean stop = new AtomicBoolean(false)-->Line_25 $$ while (!stop.get()) [ FD ]
Line_6 $$ ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()-->Line_76 $$ assertTrue(countDownLatchRef.get().await(60000 + disruptionScheme.expectedTimeToHeal().millis() * (docsPerIndexer * indexers.size()), TimeUnit.MILLISECONDS))[ FD ]
Line_2 $$ public void testAckedIndexing() throws Exception -->Line_13 $$ final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference()[ CD ]
Line_10 $$ List<Thread> indexers = new ArrayList(nodes.size())-->Line_60 $$ countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))[ FD ]
Line_17 $$ for (final String node : nodes) -->Line_49 $$ logger.info("unexpected exception in background thread of [[ FD ]
Line_17 $$ for (final String node : nodes) -->Line_86 $$ assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found", client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())[ FD ]
Line_21 $$ final String name = "indexer_" + indexers.size()-->Line_45 $$ logger.trace("[[ FD ]
Line_33 $$ id = Integer.toString(idGenerator.incrementAndGet())-->Line_36 $$ IndexResponse response = client.prepareIndex("test", "type", id).setSource("[ FD ]
Line_17 $$ for (final String node : nodes) -->Line_38 $$ ackedDocs.put(id, node)[ FD ]
Line_95 $$ if (exceptedExceptions.size() > 0) -->Line_100 $$ logger.debug(sb.toString())[ CD ]
Line_2 $$ public void testAckedIndexing() throws Exception -->Line_11 $$ List<Semaphore> semaphores = new ArrayList(nodes.size())[ CD ]
Line_10 $$ List<Thread> indexers = new ArrayList(nodes.size())-->Line_21 $$ final String name = "indexer_" + indexers.size()[ FD ]
Line_65 $$ for (int iter = 1 + randomInt(2); iter > 0; iter--) -->Line_81 $$ logger.info("validating successful docs")[ CD ]
Line_2 $$ public void testAckedIndexing() throws Exception -->Line_8 $$ final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap()[ CD ]
Line_18 $$ final Semaphore semaphore = new Semaphore(0)-->Line_62 $$ semaphore.release(docsPerIndexer)[ FD ]
Line_33 $$ id = Integer.toString(idGenerator.incrementAndGet())-->Line_39 $$ logger.trace("[[ FD ]
Line_72 $$ for (Semaphore semaphore : semaphores) -->Line_74 $$ semaphore.release(docsPerIndexer)[ FD ]
Line_2 $$ public void testAckedIndexing() throws Exception -->Line_3 $$ final List<String> nodes = startCluster(3)[ CD ]
Line_2 $$ public void testAckedIndexing() throws Exception -->Line_5 $$ ensureGreen()[ CD ]
Line_33 $$ id = Integer.toString(idGenerator.incrementAndGet())-->Line_86 $$ assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found", client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())[ FD ]
Line_10 $$ List<Thread> indexers = new ArrayList(nodes.size())-->Line_76 $$ assertTrue(countDownLatchRef.get().await(60000 + disruptionScheme.expectedTimeToHeal().millis() * (docsPerIndexer * indexers.size()), TimeUnit.MILLISECONDS))[ FD ]
Line_11 $$ List<Semaphore> semaphores = new ArrayList(nodes.size())-->Line_19 $$ semaphores.add(semaphore)[ FD ]
Line_13 $$ final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference()-->Line_64 $$ assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES))[ FD ]
Line_25 $$ while (!stop.get()) -->Line_26 $$ String id = null[ CD ]
Line_65 $$ for (int iter = 1 + randomInt(2); iter > 0; iter--) -->Line_76 $$ assertTrue(countDownLatchRef.get().await(60000 + disruptionScheme.expectedTimeToHeal().millis() * (docsPerIndexer * indexers.size()), TimeUnit.MILLISECONDS))[ CD ]
Line_18 $$ final Semaphore semaphore = new Semaphore(0)-->Line_74 $$ semaphore.release(docsPerIndexer)[ FD ]
Line_11 $$ List<Semaphore> semaphores = new ArrayList(nodes.size())-->Line_71 $$ Collections.shuffle(semaphores, random())[ FD ]
Line_21 $$ final String name = "indexer_" + indexers.size()-->Line_35 $$ logger.trace("[[ FD ]
Line_12 $$ final AtomicInteger idGenerator = new AtomicInteger(0)-->Line_33 $$ id = Integer.toString(idGenerator.incrementAndGet())[ FD ]
Line_6 $$ ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()-->Line_78 $$ disruptionScheme.stopDisrupting()[ FD ]
Line_34 $$ int shard = Murmur3HashFunction.hash(id) % numPrimaries-->Line_35 $$ logger.trace("[[ FD ]
Line_3 $$ final List<String> nodes = startCluster(3)-->Line_11 $$ List<Semaphore> semaphores = new ArrayList(nodes.size())[ FD ]
Line_65 $$ for (int iter = 1 + randomInt(2); iter > 0; iter--) -->Line_92 $$ logger.info("done validating (iteration [[ CD ]
Line_26 $$ String id = null-->Line_38 $$ ackedDocs.put(id, node)[ FD ]
Line_65 $$ for (int iter = 1 + randomInt(2); iter > 0; iter--) -->Line_79 $$ ensureStableCluster(3, TimeValue.timeValueMillis(disruptionScheme.expectedTimeToHeal().millis() + DISRUPTION_HEALING_OVERHEAD.millis()))[ CD ]
Line_8 $$ final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap()-->Line_85 $$ for (String id : ackedDocs.keySet()) [ FD ]
Line_13 $$ final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference()-->Line_45 $$ logger.trace("[[ FD ]
Line_6 $$ ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()-->Line_67 $$ disruptionScheme.startDisrupting()[ FD ]
Line_65 $$ for (int iter = 1 + randomInt(2); iter > 0; iter--) -->Line_77 $$ logger.info("stopping disruption")[ CD ]
Line_65 $$ for (int iter = 1 + randomInt(2); iter > 0; iter--) -->Line_78 $$ disruptionScheme.stopDisrupting()[ CD ]
Line_14 $$ final List<Exception> exceptedExceptions = Collections.synchronizedList(new ArrayList<Exception>())-->Line_41 $$ exceptedExceptions.add(e)[ FD ]
Line_2 $$ public void testAckedIndexing() throws Exception -->Line_7 $$ logger.info("disruption scheme [[ CD ]
Line_10 $$ List<Thread> indexers = new ArrayList(nodes.size())-->Line_70 $$ countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))[ FD ]
Line_8 $$ final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap()-->Line_38 $$ ackedDocs.put(id, node)[ FD ]
Line_21 $$ final String name = "indexer_" + indexers.size()-->Line_54 $$ thread.setName(name)[ FD ]
Line_65 $$ for (int iter = 1 + randomInt(2); iter > 0; iter--) -->Line_71 $$ Collections.shuffle(semaphores, random())[ CD ]
Line_26 $$ String id = null-->Line_35 $$ logger.trace("[[ FD ]
Line_2 $$ public void testAckedIndexing() throws Exception -->Line_6 $$ ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()[ CD ]
Line_21 $$ final String name = "indexer_" + indexers.size()-->Line_31 $$ logger.info("[[ FD ]
Line_65 $$ for (int iter = 1 + randomInt(2); iter > 0; iter--) -->Line_66 $$ logger.info("starting disruptions & indexing (iteration [[ CD ]
Line_14 $$ final List<Exception> exceptedExceptions = Collections.synchronizedList(new ArrayList<Exception>())-->Line_95 $$ if (exceptedExceptions.size() > 0) [ FD ]
Line_26 $$ String id = null-->Line_42 $$ logger.trace("[[ FD ]
Line_65 $$ for (int iter = 1 + randomInt(2); iter > 0; iter--) -->Line_92 $$ logger.info("done validating (iteration [[ FD ]
Line_65 $$ for (int iter = 1 + randomInt(2); iter > 0; iter--) -->Line_80 $$ ensureGreen("test")[ CD ]
Line_65 $$ for (int iter = 1 + randomInt(2); iter > 0; iter--) -->Line_70 $$ countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))[ CD ]
Line_26 $$ String id = null-->Line_86 $$ assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found", client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())[ FD ]
Line_6 $$ ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()-->Line_79 $$ ensureStableCluster(3, TimeValue.timeValueMillis(disruptionScheme.expectedTimeToHeal().millis() + DISRUPTION_HEALING_OVERHEAD.millis()))[ FD ]
