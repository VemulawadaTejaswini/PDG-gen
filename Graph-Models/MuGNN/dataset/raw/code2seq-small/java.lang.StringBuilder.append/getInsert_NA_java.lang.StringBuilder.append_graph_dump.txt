Line_14 $$ for (ColumnMetadata c : tableMetaData.getColumns()) -->Line_15 $$ if (keyColumns.contains(c)) [ FD ]
Line_53 $$ if (generator.maxRowCount > 100 * 1000 * 1000)-->Line_54 $$ System.err.printf("WARNING: You have defined a schema that permits very large partitions (%.0f max rows (>100M))%n", generator.maxRowCount)[ CD ]
Line_22 $$ if (firstCol)-->Line_25 $$ sb.append(",")[ CD ]
Line_5 $$ if (insertStatement == null) -->Line_53 $$ if (generator.maxRowCount > 100 * 1000 * 1000)[ CD ]
Line_16 $$ if (firstPred)-->Line_19 $$ pred.append(" AND ")[ CD ]
Line_2 $$ public SchemaInsert getInsert(Timer timer, PartitionGenerator generator, SeedManager seedManager, StressSettings settings) -->Line_65 $$ thriftInsertId = settings.getThriftClient().prepare_cql3_query(query, Compression.NONE)[ FD ]
Line_5 $$ if (insertStatement == null) -->Line_42 $$ lowerCase(insert)[ CD ]
Line_5 $$ if (insertStatement == null) -->Line_10 $$ StringBuilder pred = new StringBuilder()[ CD ]
Line_12 $$ boolean firstCol = true-->Line_23 $$ firstCol = false[ FD ]
Line_5 $$ if (insertStatement == null) -->Line_70 $$ insertStatement = client.prepare(query)[ CD ]
Line_14 $$ for (ColumnMetadata c : tableMetaData.getColumns()) -->Line_27 $$ switch(c.getType().getName()) [ FD ]
Line_8 $$ StringBuilder sb = new StringBuilder()-->Line_62 $$ String query = sb.toString()[ FD ]
Line_5 $$ if (insertStatement == null) -->Line_39 $$ sb.append(pred)[ CD ]
Line_5 $$ if (insertStatement == null) -->Line_49 $$ Distribution visits = settings.insert.visits.get()[ CD ]
Line_22 $$ if (firstCol)-->Line_23 $$ firstCol = false[ CD ]
Line_8 $$ StringBuilder sb = new StringBuilder()-->Line_31 $$ sb.append(c.getName()).append(" + ?")[ FD ]
Line_5 $$ if (insertStatement == null) -->Line_63 $$ if (settings.mode.api != ConnectionAPI.JAVA_DRIVER_NATIVE) [ CD ]
Line_14 $$ for (ColumnMetadata c : tableMetaData.getColumns()) -->Line_26 $$ sb.append(c.getName()).append(" = ")[ FD ]
Line_5 $$ if (insertStatement == null) -->Line_50 $$ double minBatchSize = selectchance.get().min() * partitions.get().minValue() * generator.minRowCount * (1d / visits.maxValue())[ CD ]
Line_5 $$ if (insertStatement == null) -->Line_47 $$ if (!insert.isEmpty())[ CD ]
Line_49 $$ Distribution visits = settings.insert.visits.get()-->Line_51 $$ double maxBatchSize = selectchance.get().max() * partitions.get().maxValue() * generator.maxRowCount * (1d / visits.minValue())[ FD ]
Line_62 $$ String query = sb.toString()-->Line_65 $$ thriftInsertId = settings.getThriftClient().prepare_cql3_query(query, Compression.NONE)[ FD ]
Line_51 $$ double maxBatchSize = selectchance.get().max() * partitions.get().maxValue() * generator.maxRowCount * (1d / visits.minValue())-->Line_52 $$ System.out.printf("Generating batches with [%d..%d] partitions and [%.0f..%.0f] rows (of [%.0f..%.0f] total rows in the partitions)%n", partitions.get().minValue(), partitions.get().maxValue(), minBatchSize, maxBatchSize, partitions.get().minValue() * generator.minRowCount, partitions.get().maxValue() * generator.maxRowCount)[ FD ]
Line_62 $$ String query = sb.toString()-->Line_70 $$ insertStatement = client.prepare(query)[ FD ]
Line_5 $$ if (insertStatement == null) -->Line_6 $$ maybeLoadSchemaInfo(settings)[ CD ]
Line_7 $$ Set<ColumnMetadata> keyColumns = com.google.common.collect.Sets.newHashSet(tableMetaData.getPrimaryKey())-->Line_15 $$ if (keyColumns.contains(c)) [ FD ]
Line_8 $$ StringBuilder sb = new StringBuilder()-->Line_26 $$ sb.append(c.getName()).append(" = ")[ FD ]
Line_2 $$ public SchemaInsert getInsert(Timer timer, PartitionGenerator generator, SeedManager seedManager, StressSettings settings) -->Line_61 $$ JavaDriverClient client = settings.getJavaDriverClient()[ FD ]
Line_49 $$ Distribution visits = settings.insert.visits.get()-->Line_50 $$ double minBatchSize = selectchance.get().min() * partitions.get().minValue() * generator.minRowCount * (1d / visits.maxValue())[ FD ]
Line_8 $$ StringBuilder sb = new StringBuilder()-->Line_34 $$ sb.append("?")[ FD ]
Line_5 $$ if (insertStatement == null) -->Line_44 $$ selectchance = select(settings.insert.selectRatio, "select", "fixed(1)/1", insert, OptionRatioDistribution.BUILDER)[ CD ]
Line_14 $$ for (ColumnMetadata c : tableMetaData.getColumns()) -->Line_31 $$ sb.append(c.getName()).append(" + ?")[ FD ]
Line_5 $$ if (insertStatement == null) -->Line_9 $$ sb.append("UPDATE \"").append(tableName).append("\" SET ")[ CD ]
Line_5 $$ if (insertStatement == null) -->Line_59 $$ if (maxBatchSize > 100000)[ CD ]
Line_5 $$ if (insertStatement == null) -->Line_8 $$ StringBuilder sb = new StringBuilder()[ CD ]
Line_8 $$ StringBuilder sb = new StringBuilder()-->Line_39 $$ sb.append(pred)[ FD ]
Line_10 $$ StringBuilder pred = new StringBuilder()-->Line_11 $$ pred.append(" WHERE ")[ FD ]
Line_5 $$ if (insertStatement == null) -->Line_61 $$ JavaDriverClient client = settings.getJavaDriverClient()[ CD ]
Line_5 $$ if (insertStatement == null) -->Line_62 $$ String query = sb.toString()[ CD ]
Line_10 $$ StringBuilder pred = new StringBuilder()-->Line_20 $$ pred.append(c.getName()).append(" = ?")[ FD ]
Line_5 $$ if (insertStatement == null) -->Line_40 $$ if (insert == null)[ CD ]
Line_2 $$ public SchemaInsert getInsert(Timer timer, PartitionGenerator generator, SeedManager seedManager, StressSettings settings) -->Line_6 $$ maybeLoadSchemaInfo(settings)[ FD ]
Line_59 $$ if (maxBatchSize > 100000)-->Line_60 $$ System.err.printf("WARNING: You have defined a schema that permits very large batches (%.0f max rows (>100K)). This may OOM this stress client, or the server.%n", selectchance.get().max() * partitions.get().maxValue() * generator.maxRowCount)[ CD ]
Line_5 $$ if (insertStatement == null) -->Line_43 $$ partitions = select(settings.insert.batchsize, "partitions", "fixed(1)", insert, OptionDistribution.BUILDER)[ CD ]
Line_5 $$ if (insertStatement == null) -->Line_51 $$ double maxBatchSize = selectchance.get().max() * partitions.get().maxValue() * generator.maxRowCount * (1d / visits.minValue())[ CD ]
Line_8 $$ StringBuilder sb = new StringBuilder()-->Line_25 $$ sb.append(",")[ FD ]
Line_5 $$ if (insertStatement == null) -->Line_55 $$ if (batchType == BatchStatement.Type.LOGGED && maxBatchSize > 65535) [ CD ]
Line_55 $$ if (batchType == BatchStatement.Type.LOGGED && maxBatchSize > 65535) -->Line_57 $$ System.exit(1)[ CD ]
Line_15 $$ if (keyColumns.contains(c)) -->Line_16 $$ if (firstPred)[ CD ]
Line_15 $$ if (keyColumns.contains(c)) -->Line_26 $$ sb.append(c.getName()).append(" = ")[ CD ]
Line_10 $$ StringBuilder pred = new StringBuilder()-->Line_19 $$ pred.append(" AND ")[ FD ]
Line_13 $$ boolean firstPred = true-->Line_17 $$ firstPred = false[ FD ]
Line_10 $$ StringBuilder pred = new StringBuilder()-->Line_39 $$ sb.append(pred)[ FD ]
Line_50 $$ double minBatchSize = selectchance.get().min() * partitions.get().minValue() * generator.minRowCount * (1d / visits.maxValue())-->Line_52 $$ System.out.printf("Generating batches with [%d..%d] partitions and [%.0f..%.0f] rows (of [%.0f..%.0f] total rows in the partitions)%n", partitions.get().minValue(), partitions.get().maxValue(), minBatchSize, maxBatchSize, partitions.get().minValue() * generator.minRowCount, partitions.get().maxValue() * generator.maxRowCount)[ FD ]
Line_15 $$ if (keyColumns.contains(c)) -->Line_22 $$ if (firstCol)[ CD ]
Line_5 $$ if (insertStatement == null) -->Line_11 $$ pred.append(" WHERE ")[ CD ]
Line_55 $$ if (batchType == BatchStatement.Type.LOGGED && maxBatchSize > 65535) -->Line_56 $$ System.err.printf("ERROR: You have defined a workload that generates batches with more than 65k rows (%.0f), but have required the use of LOGGED batches. There is a 65k row limit on a single batch.%n", selectchance.get().max() * partitions.get().maxValue() * generator.maxRowCount)[ CD ]
Line_5 $$ if (insertStatement == null) -->Line_52 $$ System.out.printf("Generating batches with [%d..%d] partitions and [%.0f..%.0f] rows (of [%.0f..%.0f] total rows in the partitions)%n", partitions.get().minValue(), partitions.get().maxValue(), minBatchSize, maxBatchSize, partitions.get().minValue() * generator.minRowCount, partitions.get().maxValue() * generator.maxRowCount)[ CD ]
Line_8 $$ StringBuilder sb = new StringBuilder()-->Line_9 $$ sb.append("UPDATE \"").append(tableName).append("\" SET ")[ FD ]
Line_2 $$ public SchemaInsert getInsert(Timer timer, PartitionGenerator generator, SeedManager seedManager, StressSettings settings) -->Line_3 $$ if (insertStatement == null) [ CD ]
Line_51 $$ double maxBatchSize = selectchance.get().max() * partitions.get().maxValue() * generator.maxRowCount * (1d / visits.minValue())-->Line_59 $$ if (maxBatchSize > 100000)[ FD ]
Line_5 $$ if (insertStatement == null) -->Line_13 $$ boolean firstPred = true[ CD ]
Line_5 $$ if (insertStatement == null) -->Line_45 $$ rowPopulation = select(settings.insert.rowPopulationRatio, "row-population", "fixed(1)/1", insert, OptionRatioDistribution.BUILDER)[ CD ]
Line_14 $$ for (ColumnMetadata c : tableMetaData.getColumns()) -->Line_20 $$ pred.append(c.getName()).append(" = ?")[ FD ]
Line_5 $$ if (insertStatement == null) -->Line_7 $$ Set<ColumnMetadata> keyColumns = com.google.common.collect.Sets.newHashSet(tableMetaData.getPrimaryKey())[ CD ]
Line_16 $$ if (firstPred)-->Line_17 $$ firstPred = false[ CD ]
Line_2 $$ public SchemaInsert getInsert(Timer timer, PartitionGenerator generator, SeedManager seedManager, StressSettings settings) -->Line_74 $$ return new SchemaInsert(timer, settings, generator, seedManager, partitions.get(), selectchance.get(), rowPopulation.get(), thriftInsertId, insertStatement, ThriftConversion.fromThrift(settings.command.consistencyLevel), batchType)[ CD ]
Line_5 $$ if (insertStatement == null) -->Line_12 $$ boolean firstCol = true[ CD ]
Line_61 $$ JavaDriverClient client = settings.getJavaDriverClient()-->Line_70 $$ insertStatement = client.prepare(query)[ FD ]
Line_15 $$ if (keyColumns.contains(c)) -->Line_20 $$ pred.append(c.getName()).append(" = ?")[ CD ]
