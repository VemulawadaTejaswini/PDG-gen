Line_17 $$ int effectiveIndexInterval = (int) Math.ceil((BASE_SAMPLING_LEVEL / (double) samplingLevel) * minIndexInterval)-->Line_19 $$ throw new IOException(String.format("Rebuilding index summary because the effective index interval (%d) is higher than" + " the current max index interval (%d)", effectiveIndexInterval, maxIndexInterval))[ FD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_9 $$ int samplingLevel, fullSamplingSummarySize[ CD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_21 $$ Memory offsets = Memory.allocate(offsetCount * 4)[ CD ]
Line_9 $$ int samplingLevel, fullSamplingSummarySize-->Line_14 $$ samplingLevel = BASE_SAMPLING_LEVEL[ FD ]
Line_3 $$ int minIndexInterval = in.readInt()-->Line_4 $$ if (minIndexInterval != expectedMinIndexInterval) [ FD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_12 $$ fullSamplingSummarySize = in.readInt()[ FD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_18 $$ if (effectiveIndexInterval > maxIndexInterval) [ CD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_22 $$ Memory entries = Memory.allocate(offheapSize - offsets.size())[ CD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_7 $$ int offsetCount = in.readInt()[ CD ]
Line_17 $$ int effectiveIndexInterval = (int) Math.ceil((BASE_SAMPLING_LEVEL / (double) samplingLevel) * minIndexInterval)-->Line_18 $$ if (effectiveIndexInterval > maxIndexInterval) [ FD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_8 $$ long offheapSize = in.readLong()[ FD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_4 $$ if (minIndexInterval != expectedMinIndexInterval) [ CD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_25 $$ FBUtilities.copy(in, new MemoryOutputStream(entries), entries.size())[ FD ]
Line_21 $$ Memory offsets = Memory.allocate(offsetCount * 4)-->Line_27 $$ offsets.free()[ FD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_3 $$ int minIndexInterval = in.readInt()[ CD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_18 $$ if (effectiveIndexInterval > maxIndexInterval) [ FD ]
Line_22 $$ Memory entries = Memory.allocate(offheapSize - offsets.size())-->Line_25 $$ FBUtilities.copy(in, new MemoryOutputStream(entries), entries.size())[ FD ]
Line_21 $$ Memory offsets = Memory.allocate(offsetCount * 4)-->Line_31 $$ offsets.setInt(i, (int) (offsets.getInt(i) - offsets.size()))[ FD ]
Line_22 $$ Memory entries = Memory.allocate(offheapSize - offsets.size())-->Line_32 $$ return new IndexSummary(partitioner, offsets, offsetCount, entries, entries.size(), fullSamplingSummarySize, minIndexInterval, samplingLevel)[ FD ]
Line_9 $$ int samplingLevel, fullSamplingSummarySize-->Line_12 $$ fullSamplingSummarySize = in.readInt()[ FD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_4 $$ if (minIndexInterval != expectedMinIndexInterval) [ FD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_19 $$ throw new IOException(String.format("Rebuilding index summary because the effective index interval (%d) is higher than" + " the current max index interval (%d)", effectiveIndexInterval, maxIndexInterval))[ FD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_17 $$ int effectiveIndexInterval = (int) Math.ceil((BASE_SAMPLING_LEVEL / (double) samplingLevel) * minIndexInterval)[ CD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_32 $$ return new IndexSummary(partitioner, offsets, offsetCount, entries, entries.size(), fullSamplingSummarySize, minIndexInterval, samplingLevel)[ CD ]
Line_21 $$ Memory offsets = Memory.allocate(offsetCount * 4)-->Line_22 $$ Memory entries = Memory.allocate(offheapSize - offsets.size())[ FD ]
Line_12 $$ fullSamplingSummarySize = in.readInt()-->Line_15 $$ fullSamplingSummarySize = offsetCount[ FD ]
Line_22 $$ Memory entries = Memory.allocate(offheapSize - offsets.size())-->Line_28 $$ entries.free()[ FD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_5 $$ throw new IOException(String.format("Cannot read index summary because min_index_interval changed from %d to %d.", minIndexInterval, expectedMinIndexInterval))[ FD ]
Line_21 $$ Memory offsets = Memory.allocate(offsetCount * 4)-->Line_31 $$ for (int i = 0; i < offsets.size(); i += 4) offsets.setInt(i, (int) (offsets.getInt(i) - offsets.size()))[ FD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_31 $$ for (int i = 0; i < offsets.size(); i += 4) offsets.setInt(i, (int) (offsets.getInt(i) - offsets.size()))[ CD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_11 $$ samplingLevel = in.readInt()[ FD ]
Line_3 $$ int minIndexInterval = in.readInt()-->Line_5 $$ throw new IOException(String.format("Cannot read index summary because min_index_interval changed from %d to %d.", minIndexInterval, expectedMinIndexInterval))[ FD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_8 $$ long offheapSize = in.readLong()[ CD ]
Line_9 $$ int samplingLevel, fullSamplingSummarySize-->Line_11 $$ samplingLevel = in.readInt()[ FD ]
Line_11 $$ samplingLevel = in.readInt()-->Line_14 $$ samplingLevel = BASE_SAMPLING_LEVEL[ FD ]
Line_10 $$ if (haveSamplingLevel) -->Line_11 $$ samplingLevel = in.readInt()[ CD ]
Line_21 $$ Memory offsets = Memory.allocate(offsetCount * 4)-->Line_24 $$ FBUtilities.copy(in, new MemoryOutputStream(offsets), offsets.size())[ FD ]
Line_10 $$ if (haveSamplingLevel) -->Line_14 $$ samplingLevel = BASE_SAMPLING_LEVEL[ CD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_7 $$ int offsetCount = in.readInt()[ FD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_3 $$ int minIndexInterval = in.readInt()[ FD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_24 $$ FBUtilities.copy(in, new MemoryOutputStream(offsets), offsets.size())[ FD ]
Line_10 $$ if (haveSamplingLevel) -->Line_15 $$ fullSamplingSummarySize = offsetCount[ CD ]
Line_2 $$ public IndexSummary deserialize(DataInputStream in, IPartitioner partitioner, boolean haveSamplingLevel, int expectedMinIndexInterval, int maxIndexInterval) throws IOException -->Line_10 $$ if (haveSamplingLevel) [ CD ]
Line_9 $$ int samplingLevel, fullSamplingSummarySize-->Line_15 $$ fullSamplingSummarySize = offsetCount[ FD ]
Line_10 $$ if (haveSamplingLevel) -->Line_12 $$ fullSamplingSummarySize = in.readInt()[ CD ]
Line_7 $$ int offsetCount = in.readInt()-->Line_15 $$ fullSamplingSummarySize = offsetCount[ FD ]
