{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu101\n",
      "10.1\n",
      "3.8.18\n",
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import glob\n",
    "import tqdm\n",
    "from torch import nn\n",
    "import random\n",
    "import torch\n",
    "import platform\n",
    "from typing import Callable, List, Optional, Dict\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import (\n",
    "    Data,\n",
    "    InMemoryDataset,\n",
    "    Batch\n",
    "    )\n",
    "import torch_geometric.datasets as datasets\n",
    "import torch_geometric.transforms as transforms\n",
    "from torch_geometric.data import Data\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "\n",
    "# Helper function for visualization.\n",
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, silhouette_score\n",
    "\n",
    "# To ensure determinism\n",
    "seed = 1234\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(seed)\n",
    "\n",
    "# Check versions\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(platform.python_version())\n",
    "print(torch_geometric.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the Graph Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def get_nodes_edges(inTextFile, add_reverse_edges = False, api_name = None):\n",
    "  # FD = 0, CD = 1\n",
    "  # to support the hetero data object as suggested by the documentation \n",
    "  nodes_dict = OrderedDict()\n",
    "  edge_indices_CD = []\n",
    "  edge_indices_FD = []\n",
    "\n",
    "  #to support the Data object as used by the Entities dat object as used in RGAT source code\n",
    "  edge_indices = []\n",
    "  edge_type = []\n",
    "  \n",
    "  # nodes_dict is an index_map\n",
    "  node_count=0\n",
    "  fp = open(inTextFile, \"r\")\n",
    "    \n",
    "  file_name = inTextFile.split(\"/\")[-1].strip()\n",
    "  Lines = fp.readlines()\n",
    "  \n",
    "  # Capture the API nodes first\n",
    "  number_of_api_nodes = 0\n",
    "  if api_name != None:\n",
    "    api_name = api_name[api_name.find(\".\"):] + \"(\"\n",
    "    for line in Lines:\n",
    "      nodes = line.split('-->')\n",
    "      nodes[0], nodes[1] = nodes[0].strip(), nodes[1].strip()\n",
    "      \n",
    "      src = nodes[0]  \n",
    "      if src not in nodes_dict.keys() and api_name in src:\n",
    "        nodes_dict[src] = node_count\n",
    "        node_count += 1\n",
    "        number_of_api_nodes += 1\n",
    "        \n",
    "      right_idx = nodes[1].rfind('[')\n",
    "      dst = nodes[1][:right_idx].strip()\n",
    "      if dst not in nodes_dict.keys() and api_name in dst:\n",
    "        nodes_dict[dst] = node_count\n",
    "        node_count += 1\n",
    "        number_of_api_nodes += 1\n",
    "    if number_of_api_nodes == 0:\n",
    "      print(\"No API Nodes found!!!!\")\n",
    "    \n",
    "  # Process each edge\n",
    "  for line in Lines:\n",
    "\n",
    "      N = line.split('-->')\n",
    "      N[0], N[1] = N[0].strip(), N[1].strip()\n",
    "      \n",
    "      #t1 = N[0].split('$$')   \n",
    "      src = N[0].strip()   \n",
    "      if src not in nodes_dict.keys():\n",
    "        nodes_dict[src] = node_count\n",
    "        node_count+=1\n",
    "        \n",
    "      #t2 = N[1].split('$$')\n",
    "      right_idx = N[1].rfind('[')\n",
    "      dst = N[1][:right_idx].strip()\n",
    "      if dst not in nodes_dict.keys():\n",
    "        nodes_dict[dst] = node_count\n",
    "        node_count+=1\n",
    "\n",
    "      x = N[1].strip()[right_idx + 1 : -1].strip()\n",
    "      if(x == 'FD'):\n",
    "        y=0\n",
    "        edge_type.append(y)\n",
    "        edge_indices.append([nodes_dict[src], nodes_dict[dst]])\n",
    "        if add_reverse_edges:\n",
    "          edge_type.append(y)\n",
    "          edge_indices.append([nodes_dict[dst], nodes_dict[src]])\n",
    "        edge_indices_FD.append([nodes_dict[src], nodes_dict[dst]])\n",
    "      else: \n",
    "        y=1\n",
    "        edge_type.append(y)\n",
    "        edge_indices.append([nodes_dict[src], nodes_dict[dst]])\n",
    "        if add_reverse_edges:\n",
    "          edge_type.append(y)\n",
    "          edge_indices.append([nodes_dict[dst], nodes_dict[src]])\n",
    "        edge_indices_CD.append([nodes_dict[src], nodes_dict[dst]])\n",
    "     \n",
    "  return nodes_dict, edge_indices_FD, edge_indices_CD, edge_indices, edge_type, file_name, number_of_api_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "#Set GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the models\n",
    "codebert_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "codebert_model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "codebert_model = codebert_model.to(device)\n",
    "\n",
    "def get_node_embedding_from_codebert(nodes):\n",
    "    list_of_embeddings = []\n",
    "    for code_line in nodes.keys():\n",
    "        code_line = code_line.split(\"$$\")[1].strip()\n",
    "        code_tokens = codebert_tokenizer.tokenize(code_line, truncation=True, max_length=510)\n",
    "        tokens = [codebert_tokenizer.cls_token]+code_tokens+[codebert_tokenizer.eos_token]\n",
    "        tokens_ids = torch.tensor(codebert_tokenizer.convert_tokens_to_ids(tokens))\n",
    "        tokens_ids = tokens_ids.to(device)\n",
    "        context_embeddings = codebert_model(tokens_ids[None,:])\n",
    "        cls_token_embedding = context_embeddings.last_hidden_state[0,0,:]\n",
    "        list_of_embeddings.append(cls_token_embedding.to(\"cpu\"))\n",
    "        del tokens_ids\n",
    "        del context_embeddings\n",
    "        del cls_token_embedding\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return torch.stack(list_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_dataset(folders, add_reverse_edges = False, track_api_nodes = False):\n",
    "  dataset =[]\n",
    "  for label, folder in tqdm.tqdm(enumerate(folders)):\n",
    "    print(\"\\nProcessing: {}\\n\".format(folder))\n",
    "    files = glob.glob(os.path.join(folder, '*.txt'))\n",
    "    print(\"\\nNumber of files: {}\\n\".format(len(files)))\n",
    "    count = 0\n",
    "    for file in files:\n",
    "\n",
    "      if(count % 5 == 0):\n",
    "          print(\"\\nAt file: {}\\n\".format(count))\n",
    "                        \n",
    "      try:\n",
    "          if track_api_nodes:\n",
    "              api_name = folder.split(\"/\")[-1].strip()\n",
    "          else:\n",
    "              api_name = None\n",
    "          nodes_dict, edge_indices_FD, edge_indices_CD, edge_indices, edge_type, file_name, number_of_api_nodes = get_nodes_edges(file, add_reverse_edges = add_reverse_edges, api_name = api_name)\n",
    "      except Exception as e:\n",
    "          print(\"\\nError: \", e)\n",
    "          continue\n",
    "                    \n",
    "      if(len(nodes_dict) == 0):\n",
    "          print(\"\\nNo Data: \", file)\n",
    "          continue\n",
    "      #print(nodes_dict, edge_indices_CD, edge_indices_FD, edge_type)\n",
    "\n",
    "      # Node feature matrix with shape [num_nodes, num_node_features]=(N, 768).\n",
    "      try:\n",
    "          with torch.no_grad():\n",
    "            CodeEmbedding = get_node_embedding_from_codebert(nodes_dict)\n",
    "      except Exception as e :\n",
    "          print(\"\\nError: \", e)\n",
    "          print(nodes_dict)\n",
    "          continue\n",
    "      #print(CodeEmbedding.shape)\n",
    "\n",
    "      # FIXING DATA FOTMATS AND SHAPE\n",
    "      x = torch.tensor(CodeEmbedding)\n",
    "      # print(x.shape)\n",
    "  \n",
    "      # data.y: Target to train against (may have arbitrary shape),\n",
    "      # graph-level targets of shape [1, *]\n",
    "      label = 1\n",
    "      y = torch.tensor([label], dtype=torch.long)\n",
    "      #print(type(y))\n",
    "\n",
    "      # edge_index (LongTensor, optional) â€“ Graph connectivity in COO format with shape [2, num_edges]\n",
    "      edge_index_CD = torch.tensor(edge_indices_CD, dtype=torch.long).t().contiguous()\n",
    "      edge_index_FD = torch.tensor(edge_indices_FD, dtype=torch.long).t().contiguous()\n",
    "      edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "      edge_attr = torch.tensor(edge_type, dtype=torch.long).t().contiguous()\n",
    "      #print(edge_index_CD, edge_index_FD, edge_index, edge_type)\n",
    "  \n",
    "      data = Data(edge_index=edge_index, edge_attr=edge_attr, x=x)\n",
    "      data.id = torch.tensor([count])\n",
    "      data.y = y\n",
    "      data.number_of_api_nodes = number_of_api_nodes\n",
    "      data.api = file_name\n",
    "      dataset.append(data)\n",
    "      count += 1\n",
    "    \n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('Line_5 $$ String actual = new SimpleDateFormat(format).format(c.getTime())',\n",
       "               0),\n",
       "              ('Line_2 $$ public void matches(Object object)', 1),\n",
       "              ('Line_3 $$ if (object instanceof Calendar)', 2),\n",
       "              ('Line_4 $$ Calendar c = (Calendar) object', 3),\n",
       "              ('Line_6 $$ return value.equals(actual)', 4)]),\n",
       " [[1, 2], [3, 0], [0, 4]],\n",
       " [[1, 2], [2, 3], [2, 0], [2, 4]],\n",
       " [[1, 2], [1, 2], [2, 3], [2, 0], [3, 0], [2, 4], [0, 4]],\n",
       " [0, 1, 1, 1, 0, 1, 0],\n",
       " '0_sample-11_Calendar.getTime_graph_dump.txt',\n",
       " 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_1 = \"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_pruning/NEW/BufferedReader.read/0_sample-0_BufferedReader.read_graph_dump.txt\"\n",
    "file_2 = \"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_pruning/NEW/Calendar.getTime/0_sample-11_Calendar.getTime_graph_dump.txt\"\n",
    "\n",
    "get_nodes_edges(file_2, add_reverse_edges = False, api_name = \"Calendar.getTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: /home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_pruning/NEW/BufferedReader.read\n",
      "\n",
      "\n",
      "Number of files: 467\n",
      "\n",
      "\n",
      "At file: 0\n",
      "\n",
      "\n",
      "At file: 5\n",
      "\n",
      "\n",
      "At file: 10\n",
      "\n",
      "\n",
      "At file: 15\n",
      "\n",
      "\n",
      "At file: 20\n",
      "\n",
      "\n",
      "At file: 25\n",
      "\n",
      "\n",
      "At file: 30\n",
      "\n",
      "\n",
      "At file: 35\n",
      "\n",
      "\n",
      "At file: 40\n",
      "\n",
      "\n",
      "At file: 45\n",
      "\n",
      "\n",
      "At file: 50\n",
      "\n",
      "\n",
      "At file: 55\n",
      "\n",
      "\n",
      "At file: 60\n",
      "\n",
      "\n",
      "At file: 65\n",
      "\n",
      "\n",
      "At file: 70\n",
      "\n",
      "\n",
      "At file: 75\n",
      "\n",
      "\n",
      "At file: 80\n",
      "\n",
      "\n",
      "At file: 85\n",
      "\n",
      "\n",
      "At file: 90\n",
      "\n",
      "\n",
      "At file: 95\n",
      "\n",
      "\n",
      "At file: 100\n",
      "\n",
      "\n",
      "At file: 105\n",
      "\n",
      "\n",
      "At file: 110\n",
      "\n",
      "\n",
      "At file: 115\n",
      "\n",
      "\n",
      "At file: 120\n",
      "\n",
      "\n",
      "At file: 125\n",
      "\n",
      "\n",
      "At file: 130\n",
      "\n",
      "\n",
      "At file: 135\n",
      "\n",
      "\n",
      "At file: 140\n",
      "\n",
      "\n",
      "At file: 145\n",
      "\n",
      "\n",
      "At file: 150\n",
      "\n",
      "\n",
      "At file: 155\n",
      "\n",
      "\n",
      "At file: 160\n",
      "\n",
      "\n",
      "At file: 165\n",
      "\n",
      "\n",
      "At file: 170\n",
      "\n",
      "\n",
      "At file: 175\n",
      "\n",
      "\n",
      "At file: 180\n",
      "\n",
      "\n",
      "At file: 185\n",
      "\n",
      "\n",
      "At file: 190\n",
      "\n",
      "\n",
      "At file: 195\n",
      "\n",
      "\n",
      "At file: 200\n",
      "\n",
      "\n",
      "At file: 205\n",
      "\n",
      "\n",
      "At file: 210\n",
      "\n",
      "\n",
      "At file: 215\n",
      "\n",
      "\n",
      "At file: 220\n",
      "\n",
      "\n",
      "At file: 225\n",
      "\n",
      "\n",
      "At file: 230\n",
      "\n",
      "\n",
      "At file: 235\n",
      "\n",
      "\n",
      "At file: 240\n",
      "\n",
      "\n",
      "At file: 245\n",
      "\n",
      "\n",
      "At file: 250\n",
      "\n",
      "\n",
      "At file: 255\n",
      "\n",
      "\n",
      "At file: 260\n",
      "\n",
      "\n",
      "At file: 265\n",
      "\n",
      "\n",
      "At file: 270\n",
      "\n",
      "\n",
      "At file: 275\n",
      "\n",
      "\n",
      "At file: 280\n",
      "\n",
      "\n",
      "At file: 285\n",
      "\n",
      "\n",
      "At file: 290\n",
      "\n",
      "\n",
      "At file: 295\n",
      "\n",
      "\n",
      "At file: 300\n",
      "\n",
      "\n",
      "At file: 305\n",
      "\n",
      "\n",
      "At file: 310\n",
      "\n",
      "\n",
      "At file: 315\n",
      "\n",
      "\n",
      "At file: 320\n",
      "\n",
      "\n",
      "At file: 325\n",
      "\n",
      "\n",
      "At file: 330\n",
      "\n",
      "\n",
      "At file: 335\n",
      "\n",
      "\n",
      "At file: 340\n",
      "\n",
      "\n",
      "At file: 345\n",
      "\n",
      "\n",
      "At file: 350\n",
      "\n",
      "\n",
      "At file: 355\n",
      "\n",
      "\n",
      "At file: 360\n",
      "\n",
      "\n",
      "At file: 365\n",
      "\n",
      "\n",
      "At file: 370\n",
      "\n",
      "\n",
      "At file: 375\n",
      "\n",
      "\n",
      "At file: 380\n",
      "\n",
      "\n",
      "At file: 385\n",
      "\n",
      "\n",
      "At file: 390\n",
      "\n",
      "\n",
      "At file: 395\n",
      "\n",
      "\n",
      "At file: 400\n",
      "\n",
      "\n",
      "At file: 405\n",
      "\n",
      "\n",
      "At file: 410\n",
      "\n",
      "\n",
      "At file: 415\n",
      "\n",
      "\n",
      "At file: 420\n",
      "\n",
      "\n",
      "At file: 425\n",
      "\n",
      "\n",
      "At file: 430\n",
      "\n",
      "\n",
      "At file: 435\n",
      "\n",
      "\n",
      "At file: 440\n",
      "\n",
      "\n",
      "At file: 445\n",
      "\n",
      "\n",
      "At file: 450\n",
      "\n",
      "\n",
      "At file: 455\n",
      "\n",
      "\n",
      "At file: 460\n",
      "\n",
      "\n",
      "At file: 465\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:52, 112.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: /home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_pruning/NEW/Calendar.getTime\n",
      "\n",
      "\n",
      "Number of files: 534\n",
      "\n",
      "\n",
      "At file: 0\n",
      "\n",
      "\n",
      "At file: 5\n",
      "\n",
      "\n",
      "At file: 10\n",
      "\n",
      "\n",
      "At file: 15\n",
      "\n",
      "\n",
      "At file: 20\n",
      "\n",
      "\n",
      "At file: 25\n",
      "\n",
      "\n",
      "At file: 30\n",
      "\n",
      "\n",
      "At file: 35\n",
      "\n",
      "\n",
      "At file: 40\n",
      "\n",
      "\n",
      "At file: 45\n",
      "\n",
      "\n",
      "At file: 50\n",
      "\n",
      "\n",
      "At file: 55\n",
      "\n",
      "\n",
      "At file: 60\n",
      "\n",
      "\n",
      "At file: 65\n",
      "\n",
      "\n",
      "At file: 70\n",
      "\n",
      "\n",
      "At file: 75\n",
      "\n",
      "\n",
      "At file: 80\n",
      "\n",
      "\n",
      "At file: 85\n",
      "\n",
      "\n",
      "At file: 90\n",
      "\n",
      "\n",
      "At file: 95\n",
      "\n",
      "\n",
      "At file: 100\n",
      "\n",
      "\n",
      "At file: 105\n",
      "\n",
      "\n",
      "At file: 110\n",
      "\n",
      "\n",
      "At file: 115\n",
      "\n",
      "\n",
      "At file: 120\n",
      "\n",
      "\n",
      "At file: 125\n",
      "\n",
      "\n",
      "At file: 130\n",
      "\n",
      "\n",
      "At file: 135\n",
      "\n",
      "\n",
      "At file: 140\n",
      "\n",
      "\n",
      "At file: 145\n",
      "\n",
      "\n",
      "At file: 150\n",
      "\n",
      "\n",
      "At file: 155\n",
      "\n",
      "\n",
      "At file: 160\n",
      "\n",
      "\n",
      "At file: 165\n",
      "\n",
      "\n",
      "At file: 170\n",
      "\n",
      "\n",
      "At file: 175\n",
      "\n",
      "\n",
      "At file: 180\n",
      "\n",
      "\n",
      "At file: 185\n",
      "\n",
      "\n",
      "At file: 190\n",
      "\n",
      "\n",
      "At file: 195\n",
      "\n",
      "\n",
      "At file: 200\n",
      "\n",
      "\n",
      "At file: 205\n",
      "\n",
      "\n",
      "At file: 210\n",
      "\n",
      "\n",
      "At file: 215\n",
      "\n",
      "\n",
      "At file: 220\n",
      "\n",
      "\n",
      "At file: 225\n",
      "\n",
      "\n",
      "At file: 230\n",
      "\n",
      "\n",
      "At file: 235\n",
      "\n",
      "\n",
      "At file: 240\n",
      "\n",
      "\n",
      "At file: 245\n",
      "\n",
      "\n",
      "At file: 250\n",
      "\n",
      "\n",
      "At file: 255\n",
      "\n",
      "\n",
      "At file: 260\n",
      "\n",
      "\n",
      "At file: 265\n",
      "\n",
      "\n",
      "At file: 270\n",
      "\n",
      "\n",
      "At file: 275\n",
      "\n",
      "\n",
      "At file: 280\n",
      "\n",
      "\n",
      "At file: 285\n",
      "\n",
      "\n",
      "At file: 290\n",
      "\n",
      "\n",
      "At file: 295\n",
      "\n",
      "\n",
      "At file: 300\n",
      "\n",
      "\n",
      "At file: 305\n",
      "\n",
      "\n",
      "At file: 310\n",
      "\n",
      "\n",
      "At file: 315\n",
      "\n",
      "\n",
      "At file: 320\n",
      "\n",
      "\n",
      "At file: 325\n",
      "\n",
      "\n",
      "At file: 330\n",
      "\n",
      "\n",
      "At file: 335\n",
      "\n",
      "\n",
      "At file: 340\n",
      "\n",
      "\n",
      "At file: 345\n",
      "\n",
      "\n",
      "At file: 350\n",
      "\n",
      "\n",
      "At file: 355\n",
      "\n",
      "\n",
      "At file: 360\n",
      "\n",
      "\n",
      "At file: 365\n",
      "\n",
      "\n",
      "At file: 370\n",
      "\n",
      "\n",
      "At file: 375\n",
      "\n",
      "\n",
      "At file: 380\n",
      "\n",
      "\n",
      "At file: 385\n",
      "\n",
      "\n",
      "At file: 390\n",
      "\n",
      "\n",
      "At file: 395\n",
      "\n",
      "\n",
      "At file: 400\n",
      "\n",
      "\n",
      "At file: 405\n",
      "\n",
      "\n",
      "At file: 410\n",
      "\n",
      "\n",
      "At file: 415\n",
      "\n",
      "\n",
      "At file: 420\n",
      "\n",
      "\n",
      "At file: 425\n",
      "\n",
      "\n",
      "At file: 430\n",
      "\n",
      "\n",
      "At file: 435\n",
      "\n",
      "\n",
      "At file: 440\n",
      "\n",
      "\n",
      "At file: 445\n",
      "\n",
      "\n",
      "At file: 450\n",
      "\n",
      "\n",
      "At file: 455\n",
      "\n",
      "\n",
      "At file: 460\n",
      "\n",
      "\n",
      "At file: 465\n",
      "\n",
      "\n",
      "At file: 470\n",
      "\n",
      "\n",
      "At file: 475\n",
      "\n",
      "\n",
      "At file: 480\n",
      "\n",
      "\n",
      "At file: 485\n",
      "\n",
      "\n",
      "At file: 490\n",
      "\n",
      "\n",
      "At file: 495\n",
      "\n",
      "\n",
      "At file: 500\n",
      "\n",
      "\n",
      "At file: 505\n",
      "\n",
      "\n",
      "At file: 510\n",
      "\n",
      "\n",
      "At file: 515\n",
      "\n",
      "\n",
      "At file: 520\n",
      "\n",
      "\n",
      "At file: 525\n",
      "\n",
      "\n",
      "At file: 530\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:52, 117.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: /home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_pruning/NEW/ClassLoader.getResource\n",
      "\n",
      "\n",
      "Number of files: 92\n",
      "\n",
      "\n",
      "At file: 0\n",
      "\n",
      "\n",
      "At file: 5\n",
      "\n",
      "\n",
      "At file: 10\n",
      "\n",
      "\n",
      "At file: 15\n",
      "\n",
      "\n",
      "At file: 20\n",
      "\n",
      "\n",
      "At file: 25\n",
      "\n",
      "\n",
      "At file: 30\n",
      "\n",
      "\n",
      "At file: 35\n",
      "\n",
      "\n",
      "At file: 40\n",
      "\n",
      "\n",
      "At file: 45\n",
      "\n",
      "\n",
      "At file: 50\n",
      "\n",
      "\n",
      "At file: 55\n",
      "\n",
      "\n",
      "At file: 60\n",
      "\n",
      "\n",
      "At file: 65\n",
      "\n",
      "\n",
      "At file: 70\n",
      "\n",
      "\n",
      "At file: 75\n",
      "\n",
      "\n",
      "At file: 80\n",
      "\n",
      "\n",
      "At file: 85\n",
      "\n",
      "\n",
      "At file: 90\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [04:14, 73.68s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: /home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_pruning/NEW/DateFormat.format\n",
      "\n",
      "\n",
      "Number of files: 534\n",
      "\n",
      "\n",
      "At file: 0\n",
      "\n",
      "\n",
      "At file: 5\n",
      "\n",
      "\n",
      "At file: 10\n",
      "\n",
      "\n",
      "At file: 15\n",
      "\n",
      "\n",
      "At file: 20\n",
      "\n",
      "\n",
      "At file: 25\n",
      "\n",
      "\n",
      "At file: 30\n",
      "\n",
      "\n",
      "At file: 35\n",
      "\n",
      "\n",
      "At file: 40\n",
      "\n",
      "\n",
      "At file: 45\n",
      "\n",
      "\n",
      "At file: 50\n",
      "\n",
      "\n",
      "At file: 55\n",
      "\n",
      "\n",
      "At file: 60\n",
      "\n",
      "\n",
      "At file: 65\n",
      "\n",
      "\n",
      "At file: 70\n",
      "\n",
      "\n",
      "At file: 75\n",
      "\n",
      "\n",
      "At file: 80\n",
      "\n",
      "\n",
      "At file: 85\n",
      "\n",
      "\n",
      "At file: 90\n",
      "\n",
      "\n",
      "At file: 95\n",
      "\n",
      "\n",
      "At file: 100\n",
      "\n",
      "\n",
      "At file: 105\n",
      "\n",
      "\n",
      "At file: 110\n",
      "\n",
      "\n",
      "At file: 115\n",
      "\n",
      "\n",
      "At file: 120\n",
      "\n",
      "\n",
      "At file: 125\n",
      "\n",
      "\n",
      "At file: 130\n",
      "\n",
      "\n",
      "At file: 135\n",
      "\n",
      "\n",
      "At file: 140\n",
      "\n",
      "\n",
      "At file: 145\n",
      "\n",
      "\n",
      "At file: 150\n",
      "\n",
      "\n",
      "At file: 155\n",
      "\n",
      "\n",
      "At file: 160\n",
      "\n",
      "\n",
      "At file: 165\n",
      "\n",
      "\n",
      "At file: 170\n",
      "\n",
      "\n",
      "At file: 175\n",
      "\n",
      "\n",
      "At file: 180\n",
      "\n",
      "\n",
      "At file: 185\n",
      "\n",
      "\n",
      "At file: 190\n",
      "\n",
      "\n",
      "At file: 195\n",
      "\n",
      "\n",
      "At file: 200\n",
      "\n",
      "\n",
      "At file: 205\n",
      "\n",
      "\n",
      "At file: 210\n",
      "\n",
      "\n",
      "At file: 215\n",
      "\n",
      "\n",
      "At file: 220\n",
      "\n",
      "\n",
      "At file: 225\n",
      "\n",
      "\n",
      "At file: 230\n",
      "\n",
      "\n",
      "At file: 235\n",
      "\n",
      "\n",
      "At file: 240\n",
      "\n",
      "\n",
      "At file: 245\n",
      "\n",
      "\n",
      "At file: 250\n",
      "\n",
      "\n",
      "At file: 255\n",
      "\n",
      "\n",
      "At file: 260\n",
      "\n",
      "\n",
      "At file: 265\n",
      "\n",
      "\n",
      "At file: 270\n",
      "\n",
      "\n",
      "At file: 275\n",
      "\n",
      "\n",
      "At file: 280\n",
      "\n",
      "\n",
      "At file: 285\n",
      "\n",
      "\n",
      "At file: 290\n",
      "\n",
      "\n",
      "At file: 295\n",
      "\n",
      "\n",
      "At file: 300\n",
      "\n",
      "\n",
      "At file: 305\n",
      "\n",
      "\n",
      "At file: 310\n",
      "\n",
      "\n",
      "At file: 315\n",
      "\n",
      "\n",
      "At file: 320\n",
      "\n",
      "\n",
      "At file: 325\n",
      "\n",
      "\n",
      "At file: 330\n",
      "\n",
      "\n",
      "At file: 335\n",
      "\n",
      "\n",
      "At file: 340\n",
      "\n",
      "\n",
      "At file: 345\n",
      "\n",
      "\n",
      "At file: 350\n",
      "\n",
      "\n",
      "At file: 355\n",
      "\n",
      "\n",
      "At file: 360\n",
      "\n",
      "\n",
      "At file: 365\n",
      "\n",
      "\n",
      "At file: 370\n",
      "\n",
      "\n",
      "At file: 375\n",
      "\n",
      "\n",
      "At file: 380\n",
      "\n",
      "\n",
      "At file: 385\n",
      "\n",
      "\n",
      "At file: 390\n",
      "\n",
      "\n",
      "At file: 395\n",
      "\n",
      "\n",
      "At file: 400\n",
      "\n",
      "\n",
      "At file: 405\n",
      "\n",
      "\n",
      "At file: 410\n",
      "\n",
      "\n",
      "At file: 415\n",
      "\n",
      "\n",
      "At file: 420\n",
      "\n",
      "\n",
      "At file: 425\n",
      "\n",
      "\n",
      "At file: 430\n",
      "\n",
      "\n",
      "At file: 435\n",
      "\n",
      "\n",
      "At file: 440\n",
      "\n",
      "\n",
      "At file: 445\n",
      "\n",
      "\n",
      "At file: 450\n",
      "\n",
      "\n",
      "At file: 455\n",
      "\n",
      "\n",
      "At file: 460\n",
      "\n",
      "\n",
      "At file: 465\n",
      "\n",
      "\n",
      "At file: 470\n",
      "\n",
      "\n",
      "At file: 475\n",
      "\n",
      "\n",
      "At file: 480\n",
      "\n",
      "\n",
      "At file: 485\n",
      "\n",
      "\n",
      "At file: 490\n",
      "\n",
      "\n",
      "At file: 495\n",
      "\n",
      "\n",
      "At file: 500\n",
      "\n",
      "\n",
      "At file: 505\n",
      "\n",
      "\n",
      "At file: 510\n",
      "\n",
      "\n",
      "At file: 515\n",
      "\n",
      "\n",
      "At file: 520\n",
      "\n",
      "\n",
      "At file: 525\n",
      "\n",
      "\n",
      "At file: 530\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [06:18, 93.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: /home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_pruning/NEW/ExecutorService.submit\n",
      "\n",
      "\n",
      "Number of files: 19\n",
      "\n",
      "\n",
      "At file: 0\n",
      "\n",
      "\n",
      "At file: 5\n",
      "\n",
      "\n",
      "At file: 10\n",
      "\n",
      "\n",
      "At file: 15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [06:22, 76.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length of the dataset:  1646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "project_folders_2 = [\"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_pruning/NEW/BufferedReader.read\",\n",
    "                   \"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_pruning/NEW/Calendar.getTime\"]\n",
    "\n",
    "project_folders_5 = [\"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_pruning/NEW/BufferedReader.read\",\n",
    "                   \"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_pruning/NEW/Calendar.getTime\",\n",
    "                   \"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_pruning/NEW/ClassLoader.getResource\",\n",
    "                   \"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_pruning/NEW/DateFormat.format\",\n",
    "                   \"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_pruning/NEW/ExecutorService.submit\"]\n",
    "\n",
    "gnn_dataset = create_graph_dataset(project_folders_5, add_reverse_edges = True, track_api_nodes = True)\n",
    "print(\"\\nLength of the dataset: \", len(gnn_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build/Load the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context-Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the model!!\n"
     ]
    }
   ],
   "source": [
    "from model import GNN, GNN_graphpred\n",
    "\n",
    "#set up model\n",
    "num_layer = 3\n",
    "emb_dim = 768\n",
    "gnn_type = \"gcn\"\n",
    "num_tasks = 1\n",
    "JK = \"last\"\n",
    "dropout_ratio = 0.5\n",
    "graph_pooling = \"mean\"\n",
    "input_model_file = \"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Graph-Models/MuGNN/output/saved_models/gcn_1_3_5_e100_model_ck_code2seq.pth\"\n",
    "\n",
    "gnn_graphpred_model = GNN_graphpred(num_layer, emb_dim, num_tasks, JK = JK, drop_ratio = dropout_ratio, graph_pooling = graph_pooling, gnn_type = gnn_type)\n",
    "gnn_graphpred_model.from_pretrained(input_model_file)\n",
    "\n",
    "gnn_model = GNN(num_layer, emb_dim, JK, drop_ratio = dropout_ratio, gnn_type = gnn_type)\n",
    "gnn_model.load_state_dict(torch.load(input_model_file))\n",
    "\n",
    "print(\"Loaded the model!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone-Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the model!!\n"
     ]
    }
   ],
   "source": [
    "class CustomGCN_Basic(torch.nn.Module):\n",
    "    def __init__(self, num_node_features = 768):\n",
    "        super(CustomGCN_Basic, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 100)\n",
    "        self.conv2 = GCNConv(100, 64)\n",
    "        self.conv3 = GCNConv(64, 32)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "input_model_file = \"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Graph-Models/MuGNN/output/saved_models/clone_detection_GCN_L3_e10_850k_model.pth\"\n",
    "gnn_model = CustomGCN_Basic(num_node_features= 768)\n",
    "gnn_model.load_state_dict(torch.load(input_model_file))\n",
    "\n",
    "print(\"Loaded the model!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pool over all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_embeddings = []\n",
    "model_name = \"context-prediction\" # \"context-prediction\" or \"clone-detection\"\n",
    "for i in range(len(gnn_dataset)):\n",
    "    if model_name == \"clone-detection\":\n",
    "        node_representation = gnn_model(gnn_dataset[i].x, gnn_dataset[i].edge_index)\n",
    "    else:\n",
    "        node_representation = gnn_model(gnn_dataset[i].x, gnn_dataset[i].edge_index, gnn_dataset[i].edge_attr)\n",
    "    graph_representation = global_mean_pool(x = node_representation, batch = torch.tensor([0]*(len(node_representation))))[0]\n",
    "    gnn_dataset[i].embedding = graph_representation.detach().numpy()\n",
    "    api_name = gnn_dataset[i].api.split(\"_\")[2].strip()\n",
    "    gnn_embeddings.append([gnn_dataset[i].api, api_name, gnn_dataset[i].embedding])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pool over only API nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_embeddings = []\n",
    "model_name = \"clone-detection\" # \"context-prediction\" or \"clone-detection\"\n",
    "for i in range(len(gnn_dataset)):\n",
    "    number_of_api_nodes = gnn_dataset[i].number_of_api_nodes\n",
    "    if model_name == \"clone-detection\":\n",
    "        node_representation = gnn_model(gnn_dataset[i].x, gnn_dataset[i].edge_index)\n",
    "    else:\n",
    "        node_representation = gnn_model(gnn_dataset[i].x, gnn_dataset[i].edge_index, gnn_dataset[i].edge_attr)\n",
    "    graph_representation = global_mean_pool(x = node_representation[:number_of_api_nodes], batch = torch.tensor([0]*(number_of_api_nodes)))[0]\n",
    "    gnn_dataset[i].embedding = graph_representation.detach().numpy()\n",
    "    api_name = gnn_dataset[i].api.split(\"_\")[2].strip()\n",
    "    gnn_embeddings.append([gnn_dataset[i].api, api_name, gnn_dataset[i].embedding])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "def cluster_and_compare(embeddings, ground_truth_cluster_number, clustering_algorithm = \"Birch\"):\n",
    "    \n",
    "    if(clustering_algorithm == \"Birch\"):\n",
    "        birch_model = Birch(n_clusters = ground_truth_cluster_number)\n",
    "        clusters_result = birch_model.fit_predict([emb[2] for emb in embeddings])\n",
    "    elif(clustering_algorithm == \"Agglomerative\"):\n",
    "        agglomerative_model = AgglomerativeClustering(n_clusters = ground_truth_cluster_number)\n",
    "        clusters_result = agglomerative_model.fit_predict([emb[2] for emb in embeddings])\n",
    "    elif(clustering_algorithm == \"KMeans\"):\n",
    "        kmeans_model = KMeans(n_clusters = ground_truth_cluster_number)\n",
    "        clusters_result = kmeans_model.fit_predict([emb[2] for emb in embeddings])\n",
    "    elif(clustering_algorithm == \"GM\"):\n",
    "        gaussian_model = GaussianMixture(n_components = ground_truth_cluster_number)\n",
    "        clusters_result = gaussian_model.fit_predict([emb[2] for emb in embeddings])\n",
    "        \n",
    "    cluster_count = {}\n",
    "    \n",
    "    project_names = list(set([emb[1] for emb in embeddings]))\n",
    "    cluster_mapping = {}\n",
    "    for cluster_no in list(set(clusters_result)):\n",
    "        cluster_mapping[cluster_no] = {}\n",
    "        \n",
    "    for i in range(len(clusters_result)):\n",
    "        try:\n",
    "            cluster_count[clusters_result[i]] += 1\n",
    "        except:\n",
    "            cluster_count[clusters_result[i]] = 1\n",
    "            \n",
    "        try:\n",
    "            cluster_mapping[clusters_result[i]][embeddings[i][1]] += 1\n",
    "        except:\n",
    "            cluster_mapping[clusters_result[i]][embeddings[i][1]] = 1\n",
    "    print(\"Cluster Counts: \", cluster_count)\n",
    "    print(\"Project Names: \", project_names)\n",
    "    print(\"Cluster Mapping: \", cluster_mapping)\n",
    "    \n",
    "    total_count, currect_count, wrong_count = 0, 0, 0\n",
    "    both_right, both_wrong = 0, 0\n",
    "    confusion_matrix = {\"TP\": 0, \"TN\": 0, \"FP\": 0, \"FN\": 0}\n",
    "\n",
    "    original_one_final_two = []\n",
    "    original_two_final_one = []\n",
    "    \n",
    "    for i in tqdm.tqdm(range(len(embeddings))):\n",
    "        for j in range(i+1, len(embeddings)):\n",
    "            total_count += 1\n",
    "            if (embeddings[i][1] == embeddings[j][1]):\n",
    "                if (clusters_result[i] == clusters_result[j]):\n",
    "                    both_right += 1\n",
    "                    currect_count += 1\n",
    "                    confusion_matrix[\"TP\"] += 1\n",
    "                else:\n",
    "                    #original_one_final_two.append([embeddings[i][0], embeddings[j][0], embeddings[i][1], clusters_result[i], clusters_result[j]])\n",
    "                    wrong_count += 1\n",
    "                    confusion_matrix[\"FN\"] += 1\n",
    "            else:\n",
    "                if (clusters_result[i] != clusters_result[j]):\n",
    "                    both_wrong += 1\n",
    "                    currect_count += 1\n",
    "                    confusion_matrix[\"TN\"] += 1\n",
    "                else:\n",
    "                    #original_two_final_one.append([embeddings[i][0], embeddings[j][0], embeddings[i][1], embeddings[j][1], clusters_result[i]])\n",
    "                    wrong_count += 1\n",
    "                    confusion_matrix[\"FP\"] += 1\n",
    "                    \n",
    "    print(\"total_count = {}, currect_count = {}, wrong_count = {}, both_right = {}, both_wrong = {}\".format(total_count, currect_count, wrong_count, both_right, both_wrong))\n",
    "    print(confusion_matrix)\n",
    "    precision = float(format(confusion_matrix[\"TP\"] / (confusion_matrix[\"TP\"] + confusion_matrix[\"FP\"]), \".3f\"))\n",
    "    recall = float(format(confusion_matrix[\"TP\"] / (confusion_matrix[\"TP\"] + confusion_matrix[\"FN\"]), \".3f\"))\n",
    "    f1_score = float(format(2 * (precision * recall) / (precision + recall), \".3f\"))\n",
    "    accuracy = float(format(currect_count/total_count, \".3f\"))\n",
    "    print(\"Precision: {}, Recall: {} and F1-Score: {}\".format(precision, recall, f1_score))\n",
    "    print(\"Accuracy: {}\".format(accuracy))\n",
    "    \n",
    "    return precision, recall, f1_score, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Counts:  {1: 1563, 0: 38, 2: 41, 3: 3, 4: 1}\n",
      "Project Names:  ['Calendar.getTime', 'ClassLoader.getResource', 'DateFormat.format', 'BufferedReader.read', 'ExecutorService.submit']\n",
      "Cluster Mapping:  {0: {'BufferedReader.read': 31, 'Calendar.getTime': 1, 'DateFormat.format': 6}, 1: {'BufferedReader.read': 392, 'Calendar.getTime': 533, 'ClassLoader.getResource': 91, 'DateFormat.format': 528, 'ExecutorService.submit': 19}, 2: {'BufferedReader.read': 40, 'ClassLoader.getResource': 1}, 3: {'BufferedReader.read': 3}, 4: {'BufferedReader.read': 1}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1646/1646 [00:01<00:00, 902.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count = 1353835, currect_count = 459958, wrong_count = 893877, both_right = 363071, both_wrong = 96887\n",
      "{'TP': 363071, 'TN': 96887, 'FP': 859158, 'FN': 34719}\n",
      "Precision: 0.297, Recall: 0.913 and F1-Score: 0.448\n",
      "Accuracy: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1_score, accuracy = cluster_and_compare(gnn_embeddings, ground_truth_cluster_number = 5, clustering_algorithm = \"Birch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalute Using CodeBERT/UnixCoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "#Set GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "\n",
    "# Initialize the models\n",
    "codebert_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "codebert_model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "codebert_model = codebert_model.to(device)\n",
    "max_source_length= 512\n",
    "\n",
    "def get_code_embeddings_from_codebert(codelines):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    code = \" \".join(codelines)\n",
    "    source_tokens = codebert_tokenizer.tokenize(code)[:max_source_length-2]\n",
    "    source_tokens = [codebert_tokenizer.cls_token]+source_tokens+[codebert_tokenizer.sep_token]\n",
    "    source_ids =  codebert_tokenizer.convert_tokens_to_ids(source_tokens) \n",
    "    padding_length = max_source_length - len(source_ids)\n",
    "    source_ids+=[codebert_tokenizer.pad_token_id]*padding_length\n",
    "    source_ids = torch.tensor(source_ids)\n",
    "    \n",
    "    # tokens = []\n",
    "    # for code_line in codelines:\n",
    "    #     code_tokens = codebert_tokenizer.tokenize(code_line, truncation=True, max_length=510)\n",
    "    #     if tokens == []:\n",
    "    #         tokens = [codebert_tokenizer.cls_token] + code_tokens\n",
    "    #     else:\n",
    "    #         tokens = tokens + [codebert_tokenizer.sep_token] + code_tokens\n",
    "    # tokens = tokens + [codebert_tokenizer.eos_token]\n",
    "    # tokens_ids = torch.tensor(codebert_tokenizer.convert_tokens_to_ids(tokens))\n",
    "    source_ids = source_ids.to(device)\n",
    "    context_embeddings = codebert_model(source_ids[None,:])\n",
    "    cls_token_embedding = context_embeddings.last_hidden_state[0,0,:]\n",
    "    return cls_token_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from unixcoder import UniXcoder\n",
    "\n",
    "#Set GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "\n",
    "# Initialize the models\n",
    "unixcoder_model = UniXcoder(\"microsoft/unixcoder-base\")\n",
    "unixcoder_model = unixcoder_model.to(device)\n",
    "max_source_length= 512\n",
    "\n",
    "def get_code_embeddings_from_unixcoder(codelines):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    code = \" \".join(codelines)\n",
    "    tokens_ids = unixcoder_model.tokenize([code], max_length=512, mode=\"<encoder-only>\")\n",
    "    source_ids = torch.tensor(tokens_ids).to(device)\n",
    "    tokens_embeddings, code_embedding = unixcoder_model(source_ids)\n",
    "    return torch.flatten(code_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_from_llms(folders, model):\n",
    "  embeddings = []\n",
    "  for label, folder in tqdm.tqdm(enumerate(folders)):\n",
    "    folder_name = folder.strip().split(\"/\")[-1]\n",
    "    print(\"\\nProcessing: {}\\n\".format(folder_name))\n",
    "    files = glob.glob(os.path.join(folder, '*/*.java'))\n",
    "    print(\"\\nNumber of files: {}\\n\".format(len(files)))\n",
    "    count = 1\n",
    "    for file in files:\n",
    "      sample_name = file.split(\"/\")[-2].strip()\n",
    "      file_name = file.split(\"/\")[-1].strip()\n",
    "      if(count % 5 == 0):\n",
    "          print(\"\\nAt file: {}\\n\".format(count))\n",
    "                        \n",
    "      fp = open(file,'r')\n",
    "      lines = fp.readlines()\n",
    "      lines = [line for line in lines if not line.startswith(\"import\") and not len(line.strip('\\n')) == 0]\n",
    "      lines = [line.strip('\\n').strip(\"\\t\").strip(\" \") for line in lines]\n",
    "      if model == \"codebert\":\n",
    "        embedding = get_code_embeddings_from_codebert(lines)\n",
    "      elif model == \"unixcoder\":\n",
    "        embedding = get_code_embeddings_from_unixcoder(lines)\n",
    "      embedding = embedding.detach().cpu().numpy()\n",
    "      embeddings.append([file_name, folder_name, embedding])\n",
    "      count += 1\n",
    "    \n",
    "  return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folders_2 = [\"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_preprocessing/FINAL/BufferedReader.read\",\n",
    "                   \"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_preprocessing/FINAL/Calendar.getTime\"]\n",
    "\n",
    "project_folders_5 = [\"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_preprocessing/FINAL/BufferedReader.read\",\n",
    "                   \"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_preprocessing/FINAL/Calendar.getTime\",\n",
    "                   \"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_preprocessing/FINAL/ClassLoader.getResource\",\n",
    "                   \"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_preprocessing/FINAL/DateFormat.format\",\n",
    "                   \"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_preprocessing/FINAL/ExecutorService.submit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: BufferedReader.read\n",
      "\n",
      "\n",
      "Number of files: 472\n",
      "\n",
      "\n",
      "At file: 5\n",
      "\n",
      "\n",
      "At file: 10\n",
      "\n",
      "\n",
      "At file: 15\n",
      "\n",
      "\n",
      "At file: 20\n",
      "\n",
      "\n",
      "At file: 25\n",
      "\n",
      "\n",
      "At file: 30\n",
      "\n",
      "\n",
      "At file: 35\n",
      "\n",
      "\n",
      "At file: 40\n",
      "\n",
      "\n",
      "At file: 45\n",
      "\n",
      "\n",
      "At file: 50\n",
      "\n",
      "\n",
      "At file: 55\n",
      "\n",
      "\n",
      "At file: 60\n",
      "\n",
      "\n",
      "At file: 65\n",
      "\n",
      "\n",
      "At file: 70\n",
      "\n",
      "\n",
      "At file: 75\n",
      "\n",
      "\n",
      "At file: 80\n",
      "\n",
      "\n",
      "At file: 85\n",
      "\n",
      "\n",
      "At file: 90\n",
      "\n",
      "\n",
      "At file: 95\n",
      "\n",
      "\n",
      "At file: 100\n",
      "\n",
      "\n",
      "At file: 105\n",
      "\n",
      "\n",
      "At file: 110\n",
      "\n",
      "\n",
      "At file: 115\n",
      "\n",
      "\n",
      "At file: 120\n",
      "\n",
      "\n",
      "At file: 125\n",
      "\n",
      "\n",
      "At file: 130\n",
      "\n",
      "\n",
      "At file: 135\n",
      "\n",
      "\n",
      "At file: 140\n",
      "\n",
      "\n",
      "At file: 145\n",
      "\n",
      "\n",
      "At file: 150\n",
      "\n",
      "\n",
      "At file: 155\n",
      "\n",
      "\n",
      "At file: 160\n",
      "\n",
      "\n",
      "At file: 165\n",
      "\n",
      "\n",
      "At file: 170\n",
      "\n",
      "\n",
      "At file: 175\n",
      "\n",
      "\n",
      "At file: 180\n",
      "\n",
      "\n",
      "At file: 185\n",
      "\n",
      "\n",
      "At file: 190\n",
      "\n",
      "\n",
      "At file: 195\n",
      "\n",
      "\n",
      "At file: 200\n",
      "\n",
      "\n",
      "At file: 205\n",
      "\n",
      "\n",
      "At file: 210\n",
      "\n",
      "\n",
      "At file: 215\n",
      "\n",
      "\n",
      "At file: 220\n",
      "\n",
      "\n",
      "At file: 225\n",
      "\n",
      "\n",
      "At file: 230\n",
      "\n",
      "\n",
      "At file: 235\n",
      "\n",
      "\n",
      "At file: 240\n",
      "\n",
      "\n",
      "At file: 245\n",
      "\n",
      "\n",
      "At file: 250\n",
      "\n",
      "\n",
      "At file: 255\n",
      "\n",
      "\n",
      "At file: 260\n",
      "\n",
      "\n",
      "At file: 265\n",
      "\n",
      "\n",
      "At file: 270\n",
      "\n",
      "\n",
      "At file: 275\n",
      "\n",
      "\n",
      "At file: 280\n",
      "\n",
      "\n",
      "At file: 285\n",
      "\n",
      "\n",
      "At file: 290\n",
      "\n",
      "\n",
      "At file: 295\n",
      "\n",
      "\n",
      "At file: 300\n",
      "\n",
      "\n",
      "At file: 305\n",
      "\n",
      "\n",
      "At file: 310\n",
      "\n",
      "\n",
      "At file: 315\n",
      "\n",
      "\n",
      "At file: 320\n",
      "\n",
      "\n",
      "At file: 325\n",
      "\n",
      "\n",
      "At file: 330\n",
      "\n",
      "\n",
      "At file: 335\n",
      "\n",
      "\n",
      "At file: 340\n",
      "\n",
      "\n",
      "At file: 345\n",
      "\n",
      "\n",
      "At file: 350\n",
      "\n",
      "\n",
      "At file: 355\n",
      "\n",
      "\n",
      "At file: 360\n",
      "\n",
      "\n",
      "At file: 365\n",
      "\n",
      "\n",
      "At file: 370\n",
      "\n",
      "\n",
      "At file: 375\n",
      "\n",
      "\n",
      "At file: 380\n",
      "\n",
      "\n",
      "At file: 385\n",
      "\n",
      "\n",
      "At file: 390\n",
      "\n",
      "\n",
      "At file: 395\n",
      "\n",
      "\n",
      "At file: 400\n",
      "\n",
      "\n",
      "At file: 405\n",
      "\n",
      "\n",
      "At file: 410\n",
      "\n",
      "\n",
      "At file: 415\n",
      "\n",
      "\n",
      "At file: 420\n",
      "\n",
      "\n",
      "At file: 425\n",
      "\n",
      "\n",
      "At file: 430\n",
      "\n",
      "\n",
      "At file: 435\n",
      "\n",
      "\n",
      "At file: 440\n",
      "\n",
      "\n",
      "At file: 445\n",
      "\n",
      "\n",
      "At file: 450\n",
      "\n",
      "\n",
      "At file: 455\n",
      "\n",
      "\n",
      "At file: 460\n",
      "\n",
      "\n",
      "At file: 465\n",
      "\n",
      "\n",
      "At file: 470\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [02:12, 132.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Calendar.getTime\n",
      "\n",
      "\n",
      "Number of files: 557\n",
      "\n",
      "\n",
      "At file: 5\n",
      "\n",
      "\n",
      "At file: 10\n",
      "\n",
      "\n",
      "At file: 15\n",
      "\n",
      "\n",
      "At file: 20\n",
      "\n",
      "\n",
      "At file: 25\n",
      "\n",
      "\n",
      "At file: 30\n",
      "\n",
      "\n",
      "At file: 35\n",
      "\n",
      "\n",
      "At file: 40\n",
      "\n",
      "\n",
      "At file: 45\n",
      "\n",
      "\n",
      "At file: 50\n",
      "\n",
      "\n",
      "At file: 55\n",
      "\n",
      "\n",
      "At file: 60\n",
      "\n",
      "\n",
      "At file: 65\n",
      "\n",
      "\n",
      "At file: 70\n",
      "\n",
      "\n",
      "At file: 75\n",
      "\n",
      "\n",
      "At file: 80\n",
      "\n",
      "\n",
      "At file: 85\n",
      "\n",
      "\n",
      "At file: 90\n",
      "\n",
      "\n",
      "At file: 95\n",
      "\n",
      "\n",
      "At file: 100\n",
      "\n",
      "\n",
      "At file: 105\n",
      "\n",
      "\n",
      "At file: 110\n",
      "\n",
      "\n",
      "At file: 115\n",
      "\n",
      "\n",
      "At file: 120\n",
      "\n",
      "\n",
      "At file: 125\n",
      "\n",
      "\n",
      "At file: 130\n",
      "\n",
      "\n",
      "At file: 135\n",
      "\n",
      "\n",
      "At file: 140\n",
      "\n",
      "\n",
      "At file: 145\n",
      "\n",
      "\n",
      "At file: 150\n",
      "\n",
      "\n",
      "At file: 155\n",
      "\n",
      "\n",
      "At file: 160\n",
      "\n",
      "\n",
      "At file: 165\n",
      "\n",
      "\n",
      "At file: 170\n",
      "\n",
      "\n",
      "At file: 175\n",
      "\n",
      "\n",
      "At file: 180\n",
      "\n",
      "\n",
      "At file: 185\n",
      "\n",
      "\n",
      "At file: 190\n",
      "\n",
      "\n",
      "At file: 195\n",
      "\n",
      "\n",
      "At file: 200\n",
      "\n",
      "\n",
      "At file: 205\n",
      "\n",
      "\n",
      "At file: 210\n",
      "\n",
      "\n",
      "At file: 215\n",
      "\n",
      "\n",
      "At file: 220\n",
      "\n",
      "\n",
      "At file: 225\n",
      "\n",
      "\n",
      "At file: 230\n",
      "\n",
      "\n",
      "At file: 235\n",
      "\n",
      "\n",
      "At file: 240\n",
      "\n",
      "\n",
      "At file: 245\n",
      "\n",
      "\n",
      "At file: 250\n",
      "\n",
      "\n",
      "At file: 255\n",
      "\n",
      "\n",
      "At file: 260\n",
      "\n",
      "\n",
      "At file: 265\n",
      "\n",
      "\n",
      "At file: 270\n",
      "\n",
      "\n",
      "At file: 275\n",
      "\n",
      "\n",
      "At file: 280\n",
      "\n",
      "\n",
      "At file: 285\n",
      "\n",
      "\n",
      "At file: 290\n",
      "\n",
      "\n",
      "At file: 295\n",
      "\n",
      "\n",
      "At file: 300\n",
      "\n",
      "\n",
      "At file: 305\n",
      "\n",
      "\n",
      "At file: 310\n",
      "\n",
      "\n",
      "At file: 315\n",
      "\n",
      "\n",
      "At file: 320\n",
      "\n",
      "\n",
      "At file: 325\n",
      "\n",
      "\n",
      "At file: 330\n",
      "\n",
      "\n",
      "At file: 335\n",
      "\n",
      "\n",
      "At file: 340\n",
      "\n",
      "\n",
      "At file: 345\n",
      "\n",
      "\n",
      "At file: 350\n",
      "\n",
      "\n",
      "At file: 355\n",
      "\n",
      "\n",
      "At file: 360\n",
      "\n",
      "\n",
      "At file: 365\n",
      "\n",
      "\n",
      "At file: 370\n",
      "\n",
      "\n",
      "At file: 375\n",
      "\n",
      "\n",
      "At file: 380\n",
      "\n",
      "\n",
      "At file: 385\n",
      "\n",
      "\n",
      "At file: 390\n",
      "\n",
      "\n",
      "At file: 395\n",
      "\n",
      "\n",
      "At file: 400\n",
      "\n",
      "\n",
      "At file: 405\n",
      "\n",
      "\n",
      "At file: 410\n",
      "\n",
      "\n",
      "At file: 415\n",
      "\n",
      "\n",
      "At file: 420\n",
      "\n",
      "\n",
      "At file: 425\n",
      "\n",
      "\n",
      "At file: 430\n",
      "\n",
      "\n",
      "At file: 435\n",
      "\n",
      "\n",
      "At file: 440\n",
      "\n",
      "\n",
      "At file: 445\n",
      "\n",
      "\n",
      "At file: 450\n",
      "\n",
      "\n",
      "At file: 455\n",
      "\n",
      "\n",
      "At file: 460\n",
      "\n",
      "\n",
      "At file: 465\n",
      "\n",
      "\n",
      "At file: 470\n",
      "\n",
      "\n",
      "At file: 475\n",
      "\n",
      "\n",
      "At file: 480\n",
      "\n",
      "\n",
      "At file: 485\n",
      "\n",
      "\n",
      "At file: 490\n",
      "\n",
      "\n",
      "At file: 495\n",
      "\n",
      "\n",
      "At file: 500\n",
      "\n",
      "\n",
      "At file: 505\n",
      "\n",
      "\n",
      "At file: 510\n",
      "\n",
      "\n",
      "At file: 515\n",
      "\n",
      "\n",
      "At file: 520\n",
      "\n",
      "\n",
      "At file: 525\n",
      "\n",
      "\n",
      "At file: 530\n",
      "\n",
      "\n",
      "At file: 535\n",
      "\n",
      "\n",
      "At file: 540\n",
      "\n",
      "\n",
      "At file: 545\n",
      "\n",
      "\n",
      "At file: 550\n",
      "\n",
      "\n",
      "At file: 555\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [04:49, 146.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: ClassLoader.getResource\n",
      "\n",
      "\n",
      "Number of files: 103\n",
      "\n",
      "\n",
      "At file: 5\n",
      "\n",
      "\n",
      "At file: 10\n",
      "\n",
      "\n",
      "At file: 15\n",
      "\n",
      "\n",
      "At file: 20\n",
      "\n",
      "\n",
      "At file: 25\n",
      "\n",
      "\n",
      "At file: 30\n",
      "\n",
      "\n",
      "At file: 35\n",
      "\n",
      "\n",
      "At file: 40\n",
      "\n",
      "\n",
      "At file: 45\n",
      "\n",
      "\n",
      "At file: 50\n",
      "\n",
      "\n",
      "At file: 55\n",
      "\n",
      "\n",
      "At file: 60\n",
      "\n",
      "\n",
      "At file: 65\n",
      "\n",
      "\n",
      "At file: 70\n",
      "\n",
      "\n",
      "At file: 75\n",
      "\n",
      "\n",
      "At file: 80\n",
      "\n",
      "\n",
      "At file: 85\n",
      "\n",
      "\n",
      "At file: 90\n",
      "\n",
      "\n",
      "At file: 95\n",
      "\n",
      "\n",
      "At file: 100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [05:22, 94.93s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: DateFormat.format\n",
      "\n",
      "\n",
      "Number of files: 562\n",
      "\n",
      "\n",
      "At file: 5\n",
      "\n",
      "\n",
      "At file: 10\n",
      "\n",
      "\n",
      "At file: 15\n",
      "\n",
      "\n",
      "At file: 20\n",
      "\n",
      "\n",
      "At file: 25\n",
      "\n",
      "\n",
      "At file: 30\n",
      "\n",
      "\n",
      "At file: 35\n",
      "\n",
      "\n",
      "At file: 40\n",
      "\n",
      "\n",
      "At file: 45\n",
      "\n",
      "\n",
      "At file: 50\n",
      "\n",
      "\n",
      "At file: 55\n",
      "\n",
      "\n",
      "At file: 60\n",
      "\n",
      "\n",
      "At file: 65\n",
      "\n",
      "\n",
      "At file: 70\n",
      "\n",
      "\n",
      "At file: 75\n",
      "\n",
      "\n",
      "At file: 80\n",
      "\n",
      "\n",
      "At file: 85\n",
      "\n",
      "\n",
      "At file: 90\n",
      "\n",
      "\n",
      "At file: 95\n",
      "\n",
      "\n",
      "At file: 100\n",
      "\n",
      "\n",
      "At file: 105\n",
      "\n",
      "\n",
      "At file: 110\n",
      "\n",
      "\n",
      "At file: 115\n",
      "\n",
      "\n",
      "At file: 120\n",
      "\n",
      "\n",
      "At file: 125\n",
      "\n",
      "\n",
      "At file: 130\n",
      "\n",
      "\n",
      "At file: 135\n",
      "\n",
      "\n",
      "At file: 140\n",
      "\n",
      "\n",
      "At file: 145\n",
      "\n",
      "\n",
      "At file: 150\n",
      "\n",
      "\n",
      "At file: 155\n",
      "\n",
      "\n",
      "At file: 160\n",
      "\n",
      "\n",
      "At file: 165\n",
      "\n",
      "\n",
      "At file: 170\n",
      "\n",
      "\n",
      "At file: 175\n",
      "\n",
      "\n",
      "At file: 180\n",
      "\n",
      "\n",
      "At file: 185\n",
      "\n",
      "\n",
      "At file: 190\n",
      "\n",
      "\n",
      "At file: 195\n",
      "\n",
      "\n",
      "At file: 200\n",
      "\n",
      "\n",
      "At file: 205\n",
      "\n",
      "\n",
      "At file: 210\n",
      "\n",
      "\n",
      "At file: 215\n",
      "\n",
      "\n",
      "At file: 220\n",
      "\n",
      "\n",
      "At file: 225\n",
      "\n",
      "\n",
      "At file: 230\n",
      "\n",
      "\n",
      "At file: 235\n",
      "\n",
      "\n",
      "At file: 240\n",
      "\n",
      "\n",
      "At file: 245\n",
      "\n",
      "\n",
      "At file: 250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (913 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At file: 255\n",
      "\n",
      "\n",
      "At file: 260\n",
      "\n",
      "\n",
      "At file: 265\n",
      "\n",
      "\n",
      "At file: 270\n",
      "\n",
      "\n",
      "At file: 275\n",
      "\n",
      "\n",
      "At file: 280\n",
      "\n",
      "\n",
      "At file: 285\n",
      "\n",
      "\n",
      "At file: 290\n",
      "\n",
      "\n",
      "At file: 295\n",
      "\n",
      "\n",
      "At file: 300\n",
      "\n",
      "\n",
      "At file: 305\n",
      "\n",
      "\n",
      "At file: 310\n",
      "\n",
      "\n",
      "At file: 315\n",
      "\n",
      "\n",
      "At file: 320\n",
      "\n",
      "\n",
      "At file: 325\n",
      "\n",
      "\n",
      "At file: 330\n",
      "\n",
      "\n",
      "At file: 335\n",
      "\n",
      "\n",
      "At file: 340\n",
      "\n",
      "\n",
      "At file: 345\n",
      "\n",
      "\n",
      "At file: 350\n",
      "\n",
      "\n",
      "At file: 355\n",
      "\n",
      "\n",
      "At file: 360\n",
      "\n",
      "\n",
      "At file: 365\n",
      "\n",
      "\n",
      "At file: 370\n",
      "\n",
      "\n",
      "At file: 375\n",
      "\n",
      "\n",
      "At file: 380\n",
      "\n",
      "\n",
      "At file: 385\n",
      "\n",
      "\n",
      "At file: 390\n",
      "\n",
      "\n",
      "At file: 395\n",
      "\n",
      "\n",
      "At file: 400\n",
      "\n",
      "\n",
      "At file: 405\n",
      "\n",
      "\n",
      "At file: 410\n",
      "\n",
      "\n",
      "At file: 415\n",
      "\n",
      "\n",
      "At file: 420\n",
      "\n",
      "\n",
      "At file: 425\n",
      "\n",
      "\n",
      "At file: 430\n",
      "\n",
      "\n",
      "At file: 435\n",
      "\n",
      "\n",
      "At file: 440\n",
      "\n",
      "\n",
      "At file: 445\n",
      "\n",
      "\n",
      "At file: 450\n",
      "\n",
      "\n",
      "At file: 455\n",
      "\n",
      "\n",
      "At file: 460\n",
      "\n",
      "\n",
      "At file: 465\n",
      "\n",
      "\n",
      "At file: 470\n",
      "\n",
      "\n",
      "At file: 475\n",
      "\n",
      "\n",
      "At file: 480\n",
      "\n",
      "\n",
      "At file: 485\n",
      "\n",
      "\n",
      "At file: 490\n",
      "\n",
      "\n",
      "At file: 495\n",
      "\n",
      "\n",
      "At file: 500\n",
      "\n",
      "\n",
      "At file: 505\n",
      "\n",
      "\n",
      "At file: 510\n",
      "\n",
      "\n",
      "At file: 515\n",
      "\n",
      "\n",
      "At file: 520\n",
      "\n",
      "\n",
      "At file: 525\n",
      "\n",
      "\n",
      "At file: 530\n",
      "\n",
      "\n",
      "At file: 535\n",
      "\n",
      "\n",
      "At file: 540\n",
      "\n",
      "\n",
      "At file: 545\n",
      "\n",
      "\n",
      "At file: 550\n",
      "\n",
      "\n",
      "At file: 555\n",
      "\n",
      "\n",
      "At file: 560\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [08:20, 127.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: ExecutorService.submit\n",
      "\n",
      "\n",
      "Number of files: 21\n",
      "\n",
      "\n",
      "At file: 5\n",
      "\n",
      "\n",
      "At file: 10\n",
      "\n",
      "\n",
      "At file: 15\n",
      "\n",
      "\n",
      "At file: 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [08:27, 101.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Counts:  {0: 528, 4: 498, 3: 84, 2: 18, 1: 587}\n",
      "Project Names:  ['ExecutorService.submit', 'BufferedReader.read', 'ClassLoader.getResource', 'DateFormat.format', 'Calendar.getTime']\n",
      "Cluster Mapping:  {0: {'BufferedReader.read': 252, 'Calendar.getTime': 135, 'ClassLoader.getResource': 47, 'DateFormat.format': 89, 'ExecutorService.submit': 5}, 1: {'BufferedReader.read': 14, 'Calendar.getTime': 201, 'ClassLoader.getResource': 23, 'DateFormat.format': 342, 'ExecutorService.submit': 7}, 2: {'BufferedReader.read': 17, 'DateFormat.format': 1}, 3: {'BufferedReader.read': 65, 'Calendar.getTime': 5, 'ClassLoader.getResource': 3, 'DateFormat.format': 10, 'ExecutorService.submit': 1}, 4: {'BufferedReader.read': 124, 'Calendar.getTime': 216, 'ClassLoader.getResource': 30, 'DateFormat.format': 120, 'ExecutorService.submit': 8}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1715/1715 [00:01<00:00, 964.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count = 1469755, currect_count = 932492, wrong_count = 537263, both_right = 165177, both_wrong = 767315\n",
      "{'TP': 165177, 'TN': 767315, 'FP': 273334, 'FN': 263929}\n",
      "Precision: 0.377, Recall: 0.385 and F1-Score: 0.381\n",
      "Accuracy: 0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    codebert_embeddings = get_embeddings_from_llms(project_folders_5, \"codebert\")\n",
    "\n",
    "precision, recall, f1_score, accuracy = cluster_and_compare(codebert_embeddings, ground_truth_cluster_number = 5, clustering_algorithm = \"Birch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: BufferedReader.read\n",
      "\n",
      "\n",
      "Number of files: 472\n",
      "\n",
      "\n",
      "At file: 5\n",
      "\n",
      "\n",
      "At file: 10\n",
      "\n",
      "\n",
      "At file: 15\n",
      "\n",
      "\n",
      "At file: 20\n",
      "\n",
      "\n",
      "At file: 25\n",
      "\n",
      "\n",
      "At file: 30\n",
      "\n",
      "\n",
      "At file: 35\n",
      "\n",
      "\n",
      "At file: 40\n",
      "\n",
      "\n",
      "At file: 45\n",
      "\n",
      "\n",
      "At file: 50\n",
      "\n",
      "\n",
      "At file: 55\n",
      "\n",
      "\n",
      "At file: 60\n",
      "\n",
      "\n",
      "At file: 65\n",
      "\n",
      "\n",
      "At file: 70\n",
      "\n",
      "\n",
      "At file: 75\n",
      "\n",
      "\n",
      "At file: 80\n",
      "\n",
      "\n",
      "At file: 85\n",
      "\n",
      "\n",
      "At file: 90\n",
      "\n",
      "\n",
      "At file: 95\n",
      "\n",
      "\n",
      "At file: 100\n",
      "\n",
      "\n",
      "At file: 105\n",
      "\n",
      "\n",
      "At file: 110\n",
      "\n",
      "\n",
      "At file: 115\n",
      "\n",
      "\n",
      "At file: 120\n",
      "\n",
      "\n",
      "At file: 125\n",
      "\n",
      "\n",
      "At file: 130\n",
      "\n",
      "\n",
      "At file: 135\n",
      "\n",
      "\n",
      "At file: 140\n",
      "\n",
      "\n",
      "At file: 145\n",
      "\n",
      "\n",
      "At file: 150\n",
      "\n",
      "\n",
      "At file: 155\n",
      "\n",
      "\n",
      "At file: 160\n",
      "\n",
      "\n",
      "At file: 165\n",
      "\n",
      "\n",
      "At file: 170\n",
      "\n",
      "\n",
      "At file: 175\n",
      "\n",
      "\n",
      "At file: 180\n",
      "\n",
      "\n",
      "At file: 185\n",
      "\n",
      "\n",
      "At file: 190\n",
      "\n",
      "\n",
      "At file: 195\n",
      "\n",
      "\n",
      "At file: 200\n",
      "\n",
      "\n",
      "At file: 205\n",
      "\n",
      "\n",
      "At file: 210\n",
      "\n",
      "\n",
      "At file: 215\n",
      "\n",
      "\n",
      "At file: 220\n",
      "\n",
      "\n",
      "At file: 225\n",
      "\n",
      "\n",
      "At file: 230\n",
      "\n",
      "\n",
      "At file: 235\n",
      "\n",
      "\n",
      "At file: 240\n",
      "\n",
      "\n",
      "At file: 245\n",
      "\n",
      "\n",
      "At file: 250\n",
      "\n",
      "\n",
      "At file: 255\n",
      "\n",
      "\n",
      "At file: 260\n",
      "\n",
      "\n",
      "At file: 265\n",
      "\n",
      "\n",
      "At file: 270\n",
      "\n",
      "\n",
      "At file: 275\n",
      "\n",
      "\n",
      "At file: 280\n",
      "\n",
      "\n",
      "At file: 285\n",
      "\n",
      "\n",
      "At file: 290\n",
      "\n",
      "\n",
      "At file: 295\n",
      "\n",
      "\n",
      "At file: 300\n",
      "\n",
      "\n",
      "At file: 305\n",
      "\n",
      "\n",
      "At file: 310\n",
      "\n",
      "\n",
      "At file: 315\n",
      "\n",
      "\n",
      "At file: 320\n",
      "\n",
      "\n",
      "At file: 325\n",
      "\n",
      "\n",
      "At file: 330\n",
      "\n",
      "\n",
      "At file: 335\n",
      "\n",
      "\n",
      "At file: 340\n",
      "\n",
      "\n",
      "At file: 345\n",
      "\n",
      "\n",
      "At file: 350\n",
      "\n",
      "\n",
      "At file: 355\n",
      "\n",
      "\n",
      "At file: 360\n",
      "\n",
      "\n",
      "At file: 365\n",
      "\n",
      "\n",
      "At file: 370\n",
      "\n",
      "\n",
      "At file: 375\n",
      "\n",
      "\n",
      "At file: 380\n",
      "\n",
      "\n",
      "At file: 385\n",
      "\n",
      "\n",
      "At file: 390\n",
      "\n",
      "\n",
      "At file: 395\n",
      "\n",
      "\n",
      "At file: 400\n",
      "\n",
      "\n",
      "At file: 405\n",
      "\n",
      "\n",
      "At file: 410\n",
      "\n",
      "\n",
      "At file: 415\n",
      "\n",
      "\n",
      "At file: 420\n",
      "\n",
      "\n",
      "At file: 425\n",
      "\n",
      "\n",
      "At file: 430\n",
      "\n",
      "\n",
      "At file: 435\n",
      "\n",
      "\n",
      "At file: 440\n",
      "\n",
      "\n",
      "At file: 445\n",
      "\n",
      "\n",
      "At file: 450\n",
      "\n",
      "\n",
      "At file: 455\n",
      "\n",
      "\n",
      "At file: 460\n",
      "\n",
      "\n",
      "At file: 465\n",
      "\n",
      "\n",
      "At file: 470\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:51, 111.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Calendar.getTime\n",
      "\n",
      "\n",
      "Number of files: 557\n",
      "\n",
      "\n",
      "At file: 5\n",
      "\n",
      "\n",
      "At file: 10\n",
      "\n",
      "\n",
      "At file: 15\n",
      "\n",
      "\n",
      "At file: 20\n",
      "\n",
      "\n",
      "At file: 25\n",
      "\n",
      "\n",
      "At file: 30\n",
      "\n",
      "\n",
      "At file: 35\n",
      "\n",
      "\n",
      "At file: 40\n",
      "\n",
      "\n",
      "At file: 45\n",
      "\n",
      "\n",
      "At file: 50\n",
      "\n",
      "\n",
      "At file: 55\n",
      "\n",
      "\n",
      "At file: 60\n",
      "\n",
      "\n",
      "At file: 65\n",
      "\n",
      "\n",
      "At file: 70\n",
      "\n",
      "\n",
      "At file: 75\n",
      "\n",
      "\n",
      "At file: 80\n",
      "\n",
      "\n",
      "At file: 85\n",
      "\n",
      "\n",
      "At file: 90\n",
      "\n",
      "\n",
      "At file: 95\n",
      "\n",
      "\n",
      "At file: 100\n",
      "\n",
      "\n",
      "At file: 105\n",
      "\n",
      "\n",
      "At file: 110\n",
      "\n",
      "\n",
      "At file: 115\n",
      "\n",
      "\n",
      "At file: 120\n",
      "\n",
      "\n",
      "At file: 125\n",
      "\n",
      "\n",
      "At file: 130\n",
      "\n",
      "\n",
      "At file: 135\n",
      "\n",
      "\n",
      "At file: 140\n",
      "\n",
      "\n",
      "At file: 145\n",
      "\n",
      "\n",
      "At file: 150\n",
      "\n",
      "\n",
      "At file: 155\n",
      "\n",
      "\n",
      "At file: 160\n",
      "\n",
      "\n",
      "At file: 165\n",
      "\n",
      "\n",
      "At file: 170\n",
      "\n",
      "\n",
      "At file: 175\n",
      "\n",
      "\n",
      "At file: 180\n",
      "\n",
      "\n",
      "At file: 185\n",
      "\n",
      "\n",
      "At file: 190\n",
      "\n",
      "\n",
      "At file: 195\n",
      "\n",
      "\n",
      "At file: 200\n",
      "\n",
      "\n",
      "At file: 205\n",
      "\n",
      "\n",
      "At file: 210\n",
      "\n",
      "\n",
      "At file: 215\n",
      "\n",
      "\n",
      "At file: 220\n",
      "\n",
      "\n",
      "At file: 225\n",
      "\n",
      "\n",
      "At file: 230\n",
      "\n",
      "\n",
      "At file: 235\n",
      "\n",
      "\n",
      "At file: 240\n",
      "\n",
      "\n",
      "At file: 245\n",
      "\n",
      "\n",
      "At file: 250\n",
      "\n",
      "\n",
      "At file: 255\n",
      "\n",
      "\n",
      "At file: 260\n",
      "\n",
      "\n",
      "At file: 265\n",
      "\n",
      "\n",
      "At file: 270\n",
      "\n",
      "\n",
      "At file: 275\n",
      "\n",
      "\n",
      "At file: 280\n",
      "\n",
      "\n",
      "At file: 285\n",
      "\n",
      "\n",
      "At file: 290\n",
      "\n",
      "\n",
      "At file: 295\n",
      "\n",
      "\n",
      "At file: 300\n",
      "\n",
      "\n",
      "At file: 305\n",
      "\n",
      "\n",
      "At file: 310\n",
      "\n",
      "\n",
      "At file: 315\n",
      "\n",
      "\n",
      "At file: 320\n",
      "\n",
      "\n",
      "At file: 325\n",
      "\n",
      "\n",
      "At file: 330\n",
      "\n",
      "\n",
      "At file: 335\n",
      "\n",
      "\n",
      "At file: 340\n",
      "\n",
      "\n",
      "At file: 345\n",
      "\n",
      "\n",
      "At file: 350\n",
      "\n",
      "\n",
      "At file: 355\n",
      "\n",
      "\n",
      "At file: 360\n",
      "\n",
      "\n",
      "At file: 365\n",
      "\n",
      "\n",
      "At file: 370\n",
      "\n",
      "\n",
      "At file: 375\n",
      "\n",
      "\n",
      "At file: 380\n",
      "\n",
      "\n",
      "At file: 385\n",
      "\n",
      "\n",
      "At file: 390\n",
      "\n",
      "\n",
      "At file: 395\n",
      "\n",
      "\n",
      "At file: 400\n",
      "\n",
      "\n",
      "At file: 405\n",
      "\n",
      "\n",
      "At file: 410\n",
      "\n",
      "\n",
      "At file: 415\n",
      "\n",
      "\n",
      "At file: 420\n",
      "\n",
      "\n",
      "At file: 425\n",
      "\n",
      "\n",
      "At file: 430\n",
      "\n",
      "\n",
      "At file: 435\n",
      "\n",
      "\n",
      "At file: 440\n",
      "\n",
      "\n",
      "At file: 445\n",
      "\n",
      "\n",
      "At file: 450\n",
      "\n",
      "\n",
      "At file: 455\n",
      "\n",
      "\n",
      "At file: 460\n",
      "\n",
      "\n",
      "At file: 465\n",
      "\n",
      "\n",
      "At file: 470\n",
      "\n",
      "\n",
      "At file: 475\n",
      "\n",
      "\n",
      "At file: 480\n",
      "\n",
      "\n",
      "At file: 485\n",
      "\n",
      "\n",
      "At file: 490\n",
      "\n",
      "\n",
      "At file: 495\n",
      "\n",
      "\n",
      "At file: 500\n",
      "\n",
      "\n",
      "At file: 505\n",
      "\n",
      "\n",
      "At file: 510\n",
      "\n",
      "\n",
      "At file: 515\n",
      "\n",
      "\n",
      "At file: 520\n",
      "\n",
      "\n",
      "At file: 525\n",
      "\n",
      "\n",
      "At file: 530\n",
      "\n",
      "\n",
      "At file: 535\n",
      "\n",
      "\n",
      "At file: 540\n",
      "\n",
      "\n",
      "At file: 545\n",
      "\n",
      "\n",
      "At file: 550\n",
      "\n",
      "\n",
      "At file: 555\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [04:00, 121.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: ClassLoader.getResource\n",
      "\n",
      "\n",
      "Number of files: 103\n",
      "\n",
      "\n",
      "At file: 5\n",
      "\n",
      "\n",
      "At file: 10\n",
      "\n",
      "\n",
      "At file: 15\n",
      "\n",
      "\n",
      "At file: 20\n",
      "\n",
      "\n",
      "At file: 25\n",
      "\n",
      "\n",
      "At file: 30\n",
      "\n",
      "\n",
      "At file: 35\n",
      "\n",
      "\n",
      "At file: 40\n",
      "\n",
      "\n",
      "At file: 45\n",
      "\n",
      "\n",
      "At file: 50\n",
      "\n",
      "\n",
      "At file: 55\n",
      "\n",
      "\n",
      "At file: 60\n",
      "\n",
      "\n",
      "At file: 65\n",
      "\n",
      "\n",
      "At file: 70\n",
      "\n",
      "\n",
      "At file: 75\n",
      "\n",
      "\n",
      "At file: 80\n",
      "\n",
      "\n",
      "At file: 85\n",
      "\n",
      "\n",
      "At file: 90\n",
      "\n",
      "\n",
      "At file: 95\n",
      "\n",
      "\n",
      "At file: 100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [04:24, 77.28s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: DateFormat.format\n",
      "\n",
      "\n",
      "Number of files: 562\n",
      "\n",
      "\n",
      "At file: 5\n",
      "\n",
      "\n",
      "At file: 10\n",
      "\n",
      "\n",
      "At file: 15\n",
      "\n",
      "\n",
      "At file: 20\n",
      "\n",
      "\n",
      "At file: 25\n",
      "\n",
      "\n",
      "At file: 30\n",
      "\n",
      "\n",
      "At file: 35\n",
      "\n",
      "\n",
      "At file: 40\n",
      "\n",
      "\n",
      "At file: 45\n",
      "\n",
      "\n",
      "At file: 50\n",
      "\n",
      "\n",
      "At file: 55\n",
      "\n",
      "\n",
      "At file: 60\n",
      "\n",
      "\n",
      "At file: 65\n",
      "\n",
      "\n",
      "At file: 70\n",
      "\n",
      "\n",
      "At file: 75\n",
      "\n",
      "\n",
      "At file: 80\n",
      "\n",
      "\n",
      "At file: 85\n",
      "\n",
      "\n",
      "At file: 90\n",
      "\n",
      "\n",
      "At file: 95\n",
      "\n",
      "\n",
      "At file: 100\n",
      "\n",
      "\n",
      "At file: 105\n",
      "\n",
      "\n",
      "At file: 110\n",
      "\n",
      "\n",
      "At file: 115\n",
      "\n",
      "\n",
      "At file: 120\n",
      "\n",
      "\n",
      "At file: 125\n",
      "\n",
      "\n",
      "At file: 130\n",
      "\n",
      "\n",
      "At file: 135\n",
      "\n",
      "\n",
      "At file: 140\n",
      "\n",
      "\n",
      "At file: 145\n",
      "\n",
      "\n",
      "At file: 150\n",
      "\n",
      "\n",
      "At file: 155\n",
      "\n",
      "\n",
      "At file: 160\n",
      "\n",
      "\n",
      "At file: 165\n",
      "\n",
      "\n",
      "At file: 170\n",
      "\n",
      "\n",
      "At file: 175\n",
      "\n",
      "\n",
      "At file: 180\n",
      "\n",
      "\n",
      "At file: 185\n",
      "\n",
      "\n",
      "At file: 190\n",
      "\n",
      "\n",
      "At file: 195\n",
      "\n",
      "\n",
      "At file: 200\n",
      "\n",
      "\n",
      "At file: 205\n",
      "\n",
      "\n",
      "At file: 210\n",
      "\n",
      "\n",
      "At file: 215\n",
      "\n",
      "\n",
      "At file: 220\n",
      "\n",
      "\n",
      "At file: 225\n",
      "\n",
      "\n",
      "At file: 230\n",
      "\n",
      "\n",
      "At file: 235\n",
      "\n",
      "\n",
      "At file: 240\n",
      "\n",
      "\n",
      "At file: 245\n",
      "\n",
      "\n",
      "At file: 250\n",
      "\n",
      "\n",
      "At file: 255\n",
      "\n",
      "\n",
      "At file: 260\n",
      "\n",
      "\n",
      "At file: 265\n",
      "\n",
      "\n",
      "At file: 270\n",
      "\n",
      "\n",
      "At file: 275\n",
      "\n",
      "\n",
      "At file: 280\n",
      "\n",
      "\n",
      "At file: 285\n",
      "\n",
      "\n",
      "At file: 290\n",
      "\n",
      "\n",
      "At file: 295\n",
      "\n",
      "\n",
      "At file: 300\n",
      "\n",
      "\n",
      "At file: 305\n",
      "\n",
      "\n",
      "At file: 310\n",
      "\n",
      "\n",
      "At file: 315\n",
      "\n",
      "\n",
      "At file: 320\n",
      "\n",
      "\n",
      "At file: 325\n",
      "\n",
      "\n",
      "At file: 330\n",
      "\n",
      "\n",
      "At file: 335\n",
      "\n",
      "\n",
      "At file: 340\n",
      "\n",
      "\n",
      "At file: 345\n",
      "\n",
      "\n",
      "At file: 350\n",
      "\n",
      "\n",
      "At file: 355\n",
      "\n",
      "\n",
      "At file: 360\n",
      "\n",
      "\n",
      "At file: 365\n",
      "\n",
      "\n",
      "At file: 370\n",
      "\n",
      "\n",
      "At file: 375\n",
      "\n",
      "\n",
      "At file: 380\n",
      "\n",
      "\n",
      "At file: 385\n",
      "\n",
      "\n",
      "At file: 390\n",
      "\n",
      "\n",
      "At file: 395\n",
      "\n",
      "\n",
      "At file: 400\n",
      "\n",
      "\n",
      "At file: 405\n",
      "\n",
      "\n",
      "At file: 410\n",
      "\n",
      "\n",
      "At file: 415\n",
      "\n",
      "\n",
      "At file: 420\n",
      "\n",
      "\n",
      "At file: 425\n",
      "\n",
      "\n",
      "At file: 430\n",
      "\n",
      "\n",
      "At file: 435\n",
      "\n",
      "\n",
      "At file: 440\n",
      "\n",
      "\n",
      "At file: 445\n",
      "\n",
      "\n",
      "At file: 450\n",
      "\n",
      "\n",
      "At file: 455\n",
      "\n",
      "\n",
      "At file: 460\n",
      "\n",
      "\n",
      "At file: 465\n",
      "\n",
      "\n",
      "At file: 470\n",
      "\n",
      "\n",
      "At file: 475\n",
      "\n",
      "\n",
      "At file: 480\n",
      "\n",
      "\n",
      "At file: 485\n",
      "\n",
      "\n",
      "At file: 490\n",
      "\n",
      "\n",
      "At file: 495\n",
      "\n",
      "\n",
      "At file: 500\n",
      "\n",
      "\n",
      "At file: 505\n",
      "\n",
      "\n",
      "At file: 510\n",
      "\n",
      "\n",
      "At file: 515\n",
      "\n",
      "\n",
      "At file: 520\n",
      "\n",
      "\n",
      "At file: 525\n",
      "\n",
      "\n",
      "At file: 530\n",
      "\n",
      "\n",
      "At file: 535\n",
      "\n",
      "\n",
      "At file: 540\n",
      "\n",
      "\n",
      "At file: 545\n",
      "\n",
      "\n",
      "At file: 550\n",
      "\n",
      "\n",
      "At file: 555\n",
      "\n",
      "\n",
      "At file: 560\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [06:40, 100.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: ExecutorService.submit\n",
      "\n",
      "\n",
      "Number of files: 21\n",
      "\n",
      "\n",
      "At file: 5\n",
      "\n",
      "\n",
      "At file: 10\n",
      "\n",
      "\n",
      "At file: 15\n",
      "\n",
      "\n",
      "At file: 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [06:46, 81.24s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Counts:  {4: 245, 1: 287, 0: 675, 2: 436, 3: 72}\n",
      "Project Names:  ['ExecutorService.submit', 'BufferedReader.read', 'ClassLoader.getResource', 'DateFormat.format', 'Calendar.getTime']\n",
      "Cluster Mapping:  {0: {'BufferedReader.read': 2, 'Calendar.getTime': 470, 'ClassLoader.getResource': 3, 'DateFormat.format': 199, 'ExecutorService.submit': 1}, 1: {'BufferedReader.read': 225, 'Calendar.getTime': 2, 'ClassLoader.getResource': 28, 'DateFormat.format': 12, 'ExecutorService.submit': 20}, 2: {'Calendar.getTime': 85, 'DateFormat.format': 351}, 3: {'ClassLoader.getResource': 72}, 4: {'BufferedReader.read': 245}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1715/1715 [00:01<00:00, 971.17it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count = 1469755, currect_count = 1151249, wrong_count = 318506, both_right = 253196, both_wrong = 898053\n",
      "{'TP': 253196, 'TN': 898053, 'FP': 142596, 'FN': 175910}\n",
      "Precision: 0.64, Recall: 0.59 and F1-Score: 0.614\n",
      "Accuracy: 0.783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    unixcoder_embeddings = get_embeddings_from_llms(project_folders_5, \"unixcoder\")\n",
    "\n",
    "precision, recall, f1_score, accuracy = cluster_and_compare(unixcoder_embeddings, ground_truth_cluster_number = 5, clustering_algorithm = \"Birch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MuGNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
