{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddharthsa/.local/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu101\n",
      "10.1\n",
      "3.8.18\n",
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import glob\n",
    "import tqdm\n",
    "from torch import nn\n",
    "import random\n",
    "import torch\n",
    "import platform\n",
    "from typing import Callable, List, Optional, Dict\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import (\n",
    "    Data,\n",
    "    InMemoryDataset,\n",
    "    Batch\n",
    "    )\n",
    "import torch_geometric.datasets as datasets\n",
    "import torch_geometric.transforms as transforms\n",
    "from torch_geometric.data import Data\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "# Helper function for visualization.\n",
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, silhouette_score\n",
    "\n",
    "# To ensure determinism\n",
    "seed = 1234\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(seed)\n",
    "\n",
    "# Check versions\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(platform.python_version())\n",
    "print(torch_geometric.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalute Using CodeBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "#Set GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3,4,5\"\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Initialize the models\n",
    "codebert_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "codebert_model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "codebert_model = codebert_model.to(device)\n",
    "max_source_length= 512\n",
    "\n",
    "def get_code_embeddings_from_codebert(codelines):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    code = \" \".join(codelines)\n",
    "    source_tokens = codebert_tokenizer.tokenize(code)[:max_source_length-2]\n",
    "    source_tokens = [codebert_tokenizer.cls_token]+source_tokens+[codebert_tokenizer.sep_token]\n",
    "    source_ids =  codebert_tokenizer.convert_tokens_to_ids(source_tokens) \n",
    "    padding_length = max_source_length - len(source_ids)\n",
    "    source_ids+=[codebert_tokenizer.pad_token_id]*padding_length\n",
    "    source_ids = torch.tensor(source_ids)\n",
    "    \n",
    "    # tokens = []\n",
    "    # for code_line in codelines:\n",
    "    #     code_tokens = codebert_tokenizer.tokenize(code_line, truncation=True, max_length=510)\n",
    "    #     if tokens == []:\n",
    "    #         tokens = [codebert_tokenizer.cls_token] + code_tokens\n",
    "    #     else:\n",
    "    #         tokens = tokens + [codebert_tokenizer.sep_token] + code_tokens\n",
    "    # tokens = tokens + [codebert_tokenizer.eos_token]\n",
    "    # tokens_ids = torch.tensor(codebert_tokenizer.convert_tokens_to_ids(tokens))\n",
    "    source_ids = source_ids.to(device)\n",
    "    context_embeddings = codebert_model(source_ids[None,:])\n",
    "    cls_token_embedding = context_embeddings.last_hidden_state[0,0,:]\n",
    "    return cls_token_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from unixcoder import UniXcoder\n",
    "\n",
    "#Set GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3,4,5\"\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Initialize the models\n",
    "unixcoder_model = UniXcoder(\"microsoft/unixcoder-base\")\n",
    "unixcoder_model = unixcoder_model.to(device)\n",
    "max_source_length= 512\n",
    "\n",
    "def get_code_embeddings_from_unixcoder(codelines):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    code = \" \".join(codelines)\n",
    "    tokens_ids = unixcoder_model.tokenize([code], max_length=512, mode=\"<encoder-only>\")\n",
    "    source_ids = torch.tensor(tokens_ids).to(device)\n",
    "    tokens_embeddings, code_embedding = unixcoder_model(source_ids)\n",
    "    return torch.flatten(code_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_from_llms(folders, model):\n",
    "  embeddings = {}\n",
    "  for label, folder in tqdm.tqdm(enumerate(folders)):\n",
    "    folder_name = folder.strip().split(\"/\")[-1]\n",
    "    print(\"\\nProcessing: {}\\n\".format(folder_name))\n",
    "    embeddings[folder_name] = []\n",
    "    files = glob.glob(os.path.join(folder, '*/*.java'))\n",
    "    print(\"\\nNumber of files: {}\\n\".format(len(files)))\n",
    "    count = 1\n",
    "    for file in files:\n",
    "      sample_name = file.split(\"/\")[-2].strip()\n",
    "      file_name = file.split(\"/\")[-1].strip()\n",
    "      if(count % 5 == 0):\n",
    "          print(\"\\nAt file: {}\\n\".format(count))\n",
    "                        \n",
    "      fp = open(file,'r')\n",
    "      lines = fp.readlines()\n",
    "      lines = [line for line in lines if not line.startswith(\"import\") and not len(line.strip('\\n')) == 0]\n",
    "      lines = [line.strip('\\n').strip(\" \") for line in lines]\n",
    "      if model == \"codebert\":\n",
    "        embedding = get_code_embeddings_from_codebert(lines)\n",
    "      elif model == \"unixcoder\":\n",
    "        embedding = get_code_embeddings_from_unixcoder(lines)\n",
    "      embedding = embedding.detach().numpy()\n",
    "      embeddings[folder_name].append([file_name, sample_name, embedding])\n",
    "      count += 1\n",
    "    \n",
    "  return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Lock.lock\n",
      "\n",
      "\n",
      "Number of files: 6\n",
      "\n",
      "\n",
      "At file: 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: ExecutorService.submit\n",
      "\n",
      "\n",
      "Number of files: 26\n",
      "\n",
      "\n",
      "At file: 5\n",
      "\n",
      "\n",
      "At file: 10\n",
      "\n",
      "\n",
      "At file: 15\n",
      "\n",
      "\n",
      "At file: 20\n",
      "\n",
      "\n",
      "At file: 25\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:11,  5.81s/it]\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_FOLDER_LOCATION = \"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_relabeling\"\n",
    "project_folders = [os.path.join(OUTPUT_FOLDER_LOCATION, name) for name in os.listdir(OUTPUT_FOLDER_LOCATION) if os.path.isdir(os.path.join(OUTPUT_FOLDER_LOCATION, name))]\n",
    "\n",
    "embeddings = get_embeddings_from_llms(project_folders, \"codebert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lock.lock': 2, 'ExecutorService.submit': 6}\n"
     ]
    }
   ],
   "source": [
    "ground_truth_cluster_numbers = {}\n",
    "for folder in project_folders:\n",
    "    folder_name = folder.strip().split(\"/\")[-1]\n",
    "    ground_truth_cluster_numbers[folder_name] = len([name for name in os.listdir(folder) if os.path.isdir(os.path.join(folder, name))])\n",
    "print(ground_truth_cluster_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import Birch\n",
    "\n",
    "def cluster_and_compare(embeddings, ground_truth_cluster_number):\n",
    "    \n",
    "    birch_model = Birch(n_clusters = ground_truth_cluster_number)\n",
    "    clusters_birch = birch_model.fit_predict([emb[2] for emb in embeddings])\n",
    "    \n",
    "    total_count, currect_count, wrong_count = 0, 0, 0\n",
    "    both_right, both_wrong = 0, 0\n",
    "    confusion_matrix = {\"TP\": 0, \"TN\": 0, \"FP\": 0, \"FN\": 0}\n",
    "\n",
    "    original_one_final_two = []\n",
    "    original_two_final_one = []\n",
    "    \n",
    "    for i in tqdm.tqdm(range(len(embeddings))):\n",
    "        for j in range(i+1, len(embeddings)):\n",
    "            total_count += 1\n",
    "            if (embeddings[i][1] == embeddings[j][1]):\n",
    "                if (clusters_birch[i] == clusters_birch[j]):\n",
    "                    both_right += 1\n",
    "                    currect_count += 1\n",
    "                    confusion_matrix[\"TP\"] += 1\n",
    "                else:\n",
    "                    #original_one_final_two.append([embeddings[i][0], embeddings[j][0], embeddings[i][1], clusters_birch[i], clusters_birch[j]])\n",
    "                    wrong_count += 1\n",
    "                    confusion_matrix[\"FN\"] += 1\n",
    "            else:\n",
    "                if (clusters_birch[i] != clusters_birch[j]):\n",
    "                    both_wrong += 1\n",
    "                    currect_count += 1\n",
    "                    confusion_matrix[\"TN\"] += 1\n",
    "                else:\n",
    "                    #original_two_final_one.append([embeddings[i][0], embeddings[j][0], embeddings[i][1], embeddings[j][1], clusters_birch[i]])\n",
    "                    wrong_count += 1\n",
    "                    confusion_matrix[\"FP\"] += 1\n",
    "                    \n",
    "    print(\"total_count = {}, currect_count = {}, wrong_count = {}, both_right = {}, both_wrong = {}\".format(total_count, currect_count, wrong_count, both_right, both_wrong))\n",
    "    print(confusion_matrix)\n",
    "    precision = float(format(confusion_matrix[\"TP\"] / (confusion_matrix[\"TP\"] + confusion_matrix[\"FP\"]), \".3f\"))\n",
    "    recall = float(format(confusion_matrix[\"TP\"] / (confusion_matrix[\"TP\"] + confusion_matrix[\"FN\"]), \".3f\"))\n",
    "    f1_score = float(format(2 * (precision * recall) / (precision + recall), \".3f\"))\n",
    "    accuracy = float(format(currect_count/total_count, \".3f\"))\n",
    "    print(\"Precision: {}, Recall: {} and F1-Score: {}\".format(precision, recall, f1_score))\n",
    "    print(\"Accuracy: {}\".format(accuracy))\n",
    "    \n",
    "    return precision, recall, f1_score, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Analyzing:  Lock.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 35246.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count = 15, currect_count = 10, wrong_count = 5, both_right = 10, both_wrong = 0\n",
      "{'TP': 10, 'TN': 0, 'FP': 5, 'FN': 0}\n",
      "Precision: 0.667, Recall: 1.0 and F1-Score: 0.8\n",
      "Accuracy: 0.667\n",
      "\n",
      "\n",
      "Analyzing:  ExecutorService.submit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 13895.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count = 325, currect_count = 230, wrong_count = 95, both_right = 12, both_wrong = 218\n",
      "{'TP': 12, 'TN': 218, 'FP': 46, 'FN': 49}\n",
      "Precision: 0.207, Recall: 0.197 and F1-Score: 0.202\n",
      "Accuracy: 0.708\n",
      "\n",
      "\n",
      "Average Precision: 0.437, Recall: 0.5985 and F1-Score: 0.501 and Accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_precision, total_recall, total_f1_score, total_accuracy = 0, 0, 0, 0\n",
    "\n",
    "for folder in project_folders:\n",
    "    folder_name = folder.strip().split(\"/\")[-1]\n",
    "    print(\"\\n\\nAnalyzing: \", folder_name)\n",
    "    precision, recall, f1_score, accuracy = cluster_and_compare(embeddings[folder_name], ground_truth_cluster_numbers[folder_name])\n",
    "    total_precision += precision\n",
    "    total_recall += recall\n",
    "    total_f1_score += f1_score\n",
    "    total_accuracy += accuracy\n",
    "    \n",
    "print(\"\\n\\nAverage Precision: {}, Recall: {} and F1-Score: {} and Accuracy: {}\".format(total_precision/len(project_folders), total_recall/len(project_folders), total_f1_score/len(project_folders), total_accuracy/len(project_folders)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate with UnixCoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Lock.lock\n",
      "\n",
      "\n",
      "Number of files: 6\n",
      "\n",
      "\n",
      "At file: 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: ExecutorService.submit\n",
      "\n",
      "\n",
      "Number of files: 26\n",
      "\n",
      "\n",
      "At file: 5\n",
      "\n",
      "\n",
      "At file: 10\n",
      "\n",
      "\n",
      "At file: 15\n",
      "\n",
      "\n",
      "At file: 20\n",
      "\n",
      "\n",
      "At file: 25\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:08,  4.04s/it]\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_FOLDER_LOCATION = \"/home/siddharthsa/cs21mtech12001-Tamal/API-Misuse-Prediction/PDG-gen/Repository/Code_kernel_data/after_relabeling\"\n",
    "project_folders = [os.path.join(OUTPUT_FOLDER_LOCATION, name) for name in os.listdir(OUTPUT_FOLDER_LOCATION) if os.path.isdir(os.path.join(OUTPUT_FOLDER_LOCATION, name))]\n",
    "\n",
    "embeddings = get_embeddings_from_llms(project_folders, \"unixcoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lock.lock': 2, 'ExecutorService.submit': 6}\n"
     ]
    }
   ],
   "source": [
    "ground_truth_cluster_numbers = {}\n",
    "for folder in project_folders:\n",
    "    folder_name = folder.strip().split(\"/\")[-1]\n",
    "    ground_truth_cluster_numbers[folder_name] = len([name for name in os.listdir(folder) if os.path.isdir(os.path.join(folder, name))])\n",
    "print(ground_truth_cluster_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Analyzing:  Lock.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 41803.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count = 15, currect_count = 6, wrong_count = 9, both_right = 4, both_wrong = 2\n",
      "{'TP': 4, 'TN': 2, 'FP': 3, 'FN': 6}\n",
      "Precision: 0.571, Recall: 0.4 and F1-Score: 0.47\n",
      "Accuracy: 0.4\n",
      "\n",
      "\n",
      "Analyzing:  ExecutorService.submit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 96591.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count = 325, currect_count = 236, wrong_count = 89, both_right = 17, both_wrong = 219\n",
      "{'TP': 17, 'TN': 219, 'FP': 45, 'FN': 44}\n",
      "Precision: 0.274, Recall: 0.279 and F1-Score: 0.276\n",
      "Accuracy: 0.726\n",
      "\n",
      "\n",
      "Average Precision: 0.4225, Recall: 0.3395 and F1-Score: 0.373 and Accuracy: 0.563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_precision, total_recall, total_f1_score, total_accuracy = 0, 0, 0, 0\n",
    "\n",
    "for folder in project_folders:\n",
    "    folder_name = folder.strip().split(\"/\")[-1]\n",
    "    print(\"\\n\\nAnalyzing: \", folder_name)\n",
    "    precision, recall, f1_score, accuracy = cluster_and_compare(embeddings[folder_name], ground_truth_cluster_numbers[folder_name])\n",
    "    total_precision += precision\n",
    "    total_recall += recall\n",
    "    total_f1_score += f1_score\n",
    "    total_accuracy += accuracy\n",
    "    \n",
    "print(\"\\n\\nAverage Precision: {}, Recall: {} and F1-Score: {} and Accuracy: {}\".format(total_precision/len(project_folders), total_recall/len(project_folders), total_f1_score/len(project_folders), total_accuracy/len(project_folders)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MuGNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
